
<!doctype html>
<html lang="fi" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../../mallinnus/kaytannot/">
      
      
        <link rel="next" href="../../siirtovaikutus/pretrained/">
      
      
        
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.2">
    
    
      
        <title>Konvoluutioverkot - Syväoppiminen I</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#konvoluutioverkot" class="md-skip">
          Hyppää sisältöön
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Ylätunniste">
    <a href="../.." title="Syväoppiminen I" class="md-header__button md-logo" aria-label="Syväoppiminen I" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Syväoppiminen I
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Konvoluutioverkot
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Hae" placeholder="Hae" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Haku">
        
        <button type="reset" class="md-search__icon md-icon" title="Tyhjää" aria-label="Tyhjää" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Aloitetaan hakua
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigaatio" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Syväoppiminen I" class="md-nav__button md-logo" aria-label="Syväoppiminen I" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Syväoppiminen I
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Tervetuloa kurssille
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    1. Neuroverkot
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    1. Neuroverkot
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../neuroverkot/neuroverkot_101/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Neuroverkot
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../neuroverkot/syvaoppiminen_FC/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Syvät neuroverkot
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    2. Tensorit
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    2. Tensorit
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tensorit/vektorointi/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Vektorointi
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tensorit/pytorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    PyTorch
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    3. Vastavirta
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    3. Vastavirta
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../vastavirta/backpropagation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Vastavirta (Backprop)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    4. Mallinnus
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    4. Mallinnus
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../mallinnus/yleiskatsaus/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Yleiskatsaus
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../mallinnus/datanlataus/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Datan lataus
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../mallinnus/kaytannot/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Kouluttamisen käytännöt
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" checked>
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    5. Konvoluutio
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            
  
    5. Konvoluutio
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    Konvoluutioverkot
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    Konvoluutioverkot
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Sisällysluettelo">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Sisällysluettelo
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#perusteet" class="md-nav__link">
    <span class="md-ellipsis">
      
        Perusteet
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Perusteet">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parametritehokkuus" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parametritehokkuus
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#miten-paljon-muistia-saastyy" class="md-nav__link">
    <span class="md-ellipsis">
      
        Miten paljon muistia säästyy?
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lyhyt-historia" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lyhyt historia
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#piirrevektorit-kasin" class="md-nav__link">
    <span class="md-ellipsis">
      
        Piirrevektorit käsin
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Piirrevektorit käsin">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lbp" class="md-nav__link">
    <span class="md-ellipsis">
      
        LBP
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hog" class="md-nav__link">
    <span class="md-ellipsis">
      
        HOG
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fast-ja-sift" class="md-nav__link">
    <span class="md-ellipsis">
      
        FAST ja SIFT
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#piirrevektorit-konvoluutioverkoissa" class="md-nav__link">
    <span class="md-ellipsis">
      
        Piirrevektorit konvoluutioverkoissa
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Piirrevektorit konvoluutioverkoissa">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#arkkitehtuuri" class="md-nav__link">
    <span class="md-ellipsis">
      
        Arkkitehtuuri
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#konvoluutiokerros" class="md-nav__link">
    <span class="md-ellipsis">
      
        Konvoluutiokerros
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#koontikerros" class="md-nav__link">
    <span class="md-ellipsis">
      
        Koontikerros
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#case-study-fractional-max-pooling-graham-2014" class="md-nav__link">
    <span class="md-ellipsis">
      
        Case Study: Fractional Max-Pooling (Graham, 2014)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Case Study: Fractional Max-Pooling (Graham, 2014)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#arkkitehtuurin-filosofia-ja-suotimien-kasvu" class="md-nav__link">
    <span class="md-ellipsis">
      
        Arkkitehtuurin filosofia ja suotimien kasvu
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fractional-max-pooling-mekanismi" class="md-nav__link">
    <span class="md-ellipsis">
      
        Fractional Max-Pooling -mekanismi
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#moderni-head-rakenne" class="md-nav__link">
    <span class="md-ellipsis">
      
        Moderni "Head" -rakenne
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#regularisointi-ja-koulutuksen-erikoisuudet" class="md-nav__link">
    <span class="md-ellipsis">
      
        Regularisointi ja koulutuksen erikoisuudet
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inferenssi-verkko-on-itsessaan-ensemble" class="md-nav__link">
    <span class="md-ellipsis">
      
        Inferenssi: Verkko on itsessään ensemble
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tehtavat" class="md-nav__link">
    <span class="md-ellipsis">
      
        Tehtävät
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lahteet" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lähteet
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    6. Siirtovaikutus
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            
  
    6. Siirtovaikutus
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../siirtovaikutus/pretrained/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Koulutetun mallin käyttö
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../siirtovaikutus/transferlearning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Siirtovaikutus
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8" >
        
          
          <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    7. Kieli
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8">
            <span class="md-nav__icon md-icon"></span>
            
  
    7. Kieli
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../kieli/nlp/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Luonnollinen kieli
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../kieli/rnn/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    RNN ja jälkeläiset
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../kieli/transformers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Transformers
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_9" >
        
          
          <label class="md-nav__link" for="__nav_9" id="__nav_9_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    8. Aikasarjat
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_9">
            <span class="md-nav__icon md-icon"></span>
            
  
    8. Aikasarjat
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../aikasarjat/ideat/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Aikasarjat
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../exercises/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Tehtäväkooste
  

    
  </span>
  
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Sisällysluettelo">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Sisällysluettelo
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#perusteet" class="md-nav__link">
    <span class="md-ellipsis">
      
        Perusteet
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Perusteet">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parametritehokkuus" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parametritehokkuus
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#miten-paljon-muistia-saastyy" class="md-nav__link">
    <span class="md-ellipsis">
      
        Miten paljon muistia säästyy?
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lyhyt-historia" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lyhyt historia
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#piirrevektorit-kasin" class="md-nav__link">
    <span class="md-ellipsis">
      
        Piirrevektorit käsin
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Piirrevektorit käsin">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lbp" class="md-nav__link">
    <span class="md-ellipsis">
      
        LBP
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hog" class="md-nav__link">
    <span class="md-ellipsis">
      
        HOG
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fast-ja-sift" class="md-nav__link">
    <span class="md-ellipsis">
      
        FAST ja SIFT
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#piirrevektorit-konvoluutioverkoissa" class="md-nav__link">
    <span class="md-ellipsis">
      
        Piirrevektorit konvoluutioverkoissa
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Piirrevektorit konvoluutioverkoissa">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#arkkitehtuuri" class="md-nav__link">
    <span class="md-ellipsis">
      
        Arkkitehtuuri
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#konvoluutiokerros" class="md-nav__link">
    <span class="md-ellipsis">
      
        Konvoluutiokerros
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#koontikerros" class="md-nav__link">
    <span class="md-ellipsis">
      
        Koontikerros
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#case-study-fractional-max-pooling-graham-2014" class="md-nav__link">
    <span class="md-ellipsis">
      
        Case Study: Fractional Max-Pooling (Graham, 2014)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Case Study: Fractional Max-Pooling (Graham, 2014)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#arkkitehtuurin-filosofia-ja-suotimien-kasvu" class="md-nav__link">
    <span class="md-ellipsis">
      
        Arkkitehtuurin filosofia ja suotimien kasvu
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fractional-max-pooling-mekanismi" class="md-nav__link">
    <span class="md-ellipsis">
      
        Fractional Max-Pooling -mekanismi
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#moderni-head-rakenne" class="md-nav__link">
    <span class="md-ellipsis">
      
        Moderni "Head" -rakenne
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#regularisointi-ja-koulutuksen-erikoisuudet" class="md-nav__link">
    <span class="md-ellipsis">
      
        Regularisointi ja koulutuksen erikoisuudet
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inferenssi-verkko-on-itsessaan-ensemble" class="md-nav__link">
    <span class="md-ellipsis">
      
        Inferenssi: Verkko on itsessään ensemble
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tehtavat" class="md-nav__link">
    <span class="md-ellipsis">
      
        Tehtävät
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lahteet" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lähteet
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="konvoluutioverkot">Konvoluutioverkot</h1>
<h2 id="perusteet">Perusteet</h2>
<p>Töksäytetään heti alkuun kolme merkittävintä hyötyä konvoluutioverkoista (CNN) verrattuna perinteisiin täysin kytkettyihin verkkoihin (FCNN):</p>
<ol>
<li><strong>Parametritehokkuus</strong>. Konvoluutioverkot jakavat painot paikallisesti. Tämä <em>shared weights</em> käsite tulee myöhemmin tutuksi myös kielimalleissa. <sup id="fnref2:geronpytorch"><a class="footnote-ref" href="#fn:geronpytorch">1</a></sup></li>
<li><strong>Paikallisuus</strong>. Konvoluutioverkot säilyttävät kuvan 2D-rakenteen. FCNN:n kohdalla kuva litistettiin pitkäksi vektoriksi, mikä tuhosi spatiaalisen informaation. <sup id="fnref3:geronpytorch"><a class="footnote-ref" href="#fn:geronpytorch">1</a></sup></li>
<li><strong>Hierarkiset piirteet</strong>. Monimutkainenkin visuaalinen tuotos koostuu pohjimmiltaan yksinkertaisista piirteistä (reunat, kulmat, tekstuurit). Tämä malli on CNN:n ydin. <sup id="fnref4:geronpytorch"><a class="footnote-ref" href="#fn:geronpytorch">1</a></sup></li>
</ol>
<h3 id="parametritehokkuus">Parametritehokkuus</h3>
<p>Olet tutustunut kurssilla FCNN-verkkoihin, ja niiden rajat alkoivat löytyä Cifar10-datasetin kohdalla. Edellisen luvun tehtävässä koulutit FCNN-verkon – kenties arkkitehtuurilla <code>3072-1024-512-10</code> –, ja pääsit noin 55% tarkkuuteen. Tutustuessasi wikipedian <a href="https://en.wikipedia.org/wiki/CIFAR-10">Cifar10</a>-sivuun huomasit, että jo 2010-luvun alkupuolella verkot kykenivät yli 95 % tarkkuuteen. On hyvä muistaa, että 95 % on jo merkittävän suuri tarkkuus. Graham lainaa Karpathyä, että: <em>"For comparison, human performance on CIFAR-10 is estimated to be 6%."</em> <sup id="fnref:fractionalmp"><a class="footnote-ref" href="#fn:fractionalmp">2</a></sup> Lukema on siis <em>error rate</em>, ei <em>accuracy</em>.</p>
<p>Miten tämä on mahdollista? Lienee selvää, että 2010-luvun alussa ratkaisu tuskin oli kasvattaa verkkoa ilman arkkitehtuurimuutoksia. Alla on taulukossa esiteltynä <code>3072-1024-512-10</code> FCNN-verkon parametrien lukumäärä. </p>
<table>
<thead>
<tr>
<th>Layer</th>
<th>Shape</th>
<th>Count</th>
</tr>
</thead>
<tbody>
<tr>
<td>fc1.weight</td>
<td>torch.Size([1024, 3072])</td>
<td>3,145,728</td>
</tr>
<tr>
<td>fc1.bias</td>
<td>torch.Size([1024])</td>
<td>1,024</td>
</tr>
<tr>
<td>fc2.weight</td>
<td>torch.Size([512, 1024])</td>
<td>524,288</td>
</tr>
<tr>
<td>fc2.bias</td>
<td>torch.Size([512])</td>
<td>512</td>
</tr>
<tr>
<td>fc3.weight</td>
<td>torch.Size([10, 512])</td>
<td>5,120</td>
</tr>
<tr>
<td>fc3.bias</td>
<td>torch.Size([10])</td>
<td>10</td>
</tr>
<tr>
<td><strong>Total</strong></td>
<td></td>
<td><strong>3,676,682</strong></td>
</tr>
</tbody>
</table>
<p>Olet varmasti kokeillut tätä ratkaisua itsekin: verkon kokoa kasvattamalla ei päästä kovin pitkälle. Mikä siis avuksi? Historiasta löytyy vastaus: konvoluutioverkot (Convolutional Neural Networks, CNN). Alla näkyy kurssikirjasta kuva, joka havainnollistaa konvoluutioverkkojen suorituskykyä MNIST-datasetin avulla <sup id="fnref:udlbook"><a class="footnote-ref" href="#fn:udlbook">3</a></sup>.</p>
<p><img alt="" src="../../images/500_ConvMNIST1D.svg" /></p>
<p><strong>Kuva 1:</strong> MNIST konvoluutioverkolla (2050 parametria) vs. FCNN:llä (150,185 parametria). <sup id="fnref2:udlbook"><a class="footnote-ref" href="#fn:udlbook">3</a></sup></p>
<p>Ihmiseen kun vertaa, niin jo vuonna 2014 Grahamin <strong>Fractional Max-Pooling</strong> -malli saavutti huimat tulokset: <em>"we obtained test errors of 4.50% (1 test), 3.67% (12 tests) and 3.47% (100 tests)"</em> <sup id="fnref2:fractionalmp"><a class="footnote-ref" href="#fn:fractionalmp">2</a></sup>. Konvoluutioverkot mahdollistavat siis huomattavan tehokkaan tavan käsitellä kuvia. Ja mikä oli Grahamin mallin parametrien määrä? <strong>74 miljoonaa</strong> parametria (jos <code>filter_growth_rate = 160</code>). Tosin paperissa mainitaan myös 12M parametria käyttänyt malli (<code>filter_growth_rate = 64</code>). Tämä pienempi malli on se, mikä on toteutettu kurssin koodissa.</p>
<p><span class="arithmatex">\(74 \text{M}\)</span> parametrin malli ylsi Grahamin paperin mukaan <span class="arithmatex">\(3.47 \%\)</span> virheeseen CIFAR-10 datasetin kanssa. Opettajan kouluttamalla, pienemmällä <span class="arithmatex">\(12 \text{M}\)</span> parametrin mallilla päästiin noin <span class="arithmatex">\(92 \%\)</span> tarkkuuteen eli <span class="arithmatex">\(8 \%\)</span> virheeseen. Tutustut tähän toteutukseen myöhemmin tehtäväosiossa, ja tähän tutustutaan myös <a href="#case-study-fractional-max-pooling-graham-2014">Case Study: Fractional Max-Pooling (Graham, 2014)</a>-otsikon alla hieman tarkemmin.</p>
<p><img alt="" src="../../images/500_fmp_training_curves.png" /></p>
<p><strong>Kuva 2:</strong> <em>300 epookin koulutuksen aikaiset tarkkuus- ja virhekäyrät Grahamin Fractional Max-Pooling -mallille (12M parametria).</em></p>
<h3 id="miten-paljon-muistia-saastyy">Miten paljon muistia säästyy?</h3>
<p>Vuonna 2014 olisi ollut mahdollista käyttää esimerkiksi GeForce GTX TITAN -korttia, jossa on 6 GB muistia. Muistiin mahtuisi <span class="arithmatex">\(\frac{6 \times 1024^3}{4} \approx 1600 \text{M}\)</span> miljoonaa <code>float32</code>-liukulukua (4 tavua per luku). Tätä tilaa ei kuitenkaan voi käyttää pelkästään verkon parametreille. Koulutuksen aikana muistia tarvitaan:</p>
<ol>
<li><strong>Parametreille</strong> (weights &amp; biases)</li>
<li><strong>Gradienteille</strong> (yleensä yhtä paljon tilaa kuin parametreille)</li>
<li><strong>Optimoijan tiloille</strong> (esim. Adam-optimoija tallettaa kaksi lisäarvoa per parametri)</li>
<li><strong>Aktivoinneille</strong> (välitulokset verkon kerroksissa, nämä riippuvat suoraan <strong>batch-koosta</strong>)</li>
</ol>
<p>Alla on typistetty <code>nvidia-smi</code>-komennon tulos Fractional Max-Pooling -mallin koulutuksen aikana (GeForce RTX 3060 Ti, 8 GB muistia):</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>+-------------------------------------------------------------------+
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>| Processes:                                                        |
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>|  GPU   GI   Type   Process name                        GPU Memory |
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>|        ID                                              Usage      |
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>|===================================================================|
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>|    0   N/A     C   ...n/notebooks/.venv/bin/python3       2650MiB |
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>+-------------------------------------------------------------------+
</span></code></pre></div>
<p>Jos 12M parametria vie 32-kokoisella erällä <code>2650 MiB</code> muistia, niin suuremman mallin (<code>filter_growth_rate = 160</code>) huimat 74M parametria veisi hyvin karkeiden oletusten kera <code>74/12 * 2650 ≈ 16342 MiB</code> – eli noin 16 GB muistia. Termi <code>filter_growth_rate</code> selitetään alla MaxPooling-mallin yhteydessä. Jos tämän suuremman mallin halutaan mahtuvan 6 GB VRAM:iin, niin batch-kokoa pitäisi pienentää: parametrien määrää tämä ei vähennä, mutta aktivaatioiden määrää kylläkin.</p>
<p>12M mallin kouluttamiseen kului opettajan GeForce RTX 3060 Ti:llä <mark>yli 11 tuntia</mark> (300 epookkia, noin 2 min 17 sek per epookki).</p>
<div class="admonition note">
<p class="admonition-title">Syötekuva ja parametrien määrä</p>
<p>VGG-16-konvoluutioverkossa käytetään tyypillisesti kuvia koossa 224×224×3 (RGB, 3 kanavaa). Dataset on nimeltään ImageNet, jossa on 1000 eri luokkaa ja miljoonia kuvia. Konvoluutioverkossa VGG-16 on tästä huolimatta kokonaisuudessaan vain 138M parametria.</p>
<p>Kuinka olisi FCNN-verkon laita, jos input on <code>224x224x3</code> ja ensimmäinen piilotettu kerros <code>4096</code> neuronia? Input olisi siis <code>150,528</code>-pituinen vektori. Tällöin <mark>pelkästään ensimmäisen</mark> piilotetun kerrokset olisivat parametrimäärältään:</p>
<div class="arithmatex">\[
150,528 \times 4096 \approx 617 \text{M}
\]</div>
</div>
<h3 id="lyhyt-historia">Lyhyt historia</h3>
<p>Alla olevan historian parametriluvut ovat hyvinkin suuntaa-antavia, sillä useimmista arkkitehtuureista voi muovata eri kokoisia malleja. Lukema liittyy usein alkuperäiseen julkaisuun.</p>
<ul>
<li><strong>1980</strong>: Konvoluutioverkkojen juuret ulottuvat 1980-luvulle, jolloin Kunihiko Fukushima esitteli Neocognitron-mallin, josta polveutuvat myöhemmät konvoluutioverkot. <sup id="fnref:neocognition"><a class="footnote-ref" href="#fn:neocognition">4</a></sup> </li>
<li><strong>1998</strong>: LeNet-5, tunnetuin näistä LeNet-X -malleista. ~60k parametria <sup id="fnref:lenet5"><a class="footnote-ref" href="#fn:lenet5">5</a></sup>.</li>
<li><strong>2012</strong>: AlexNet, merkittävä edistysaskel syvien konvoluutioverkkojen koulutuksessa, joka voitti ImageNet-kilpailun ylivoimaisesti. <sup id="fnref:alexnet"><a class="footnote-ref" href="#fn:alexnet">6</a></sup>.</li>
<li><strong>2014</strong>: GoogLeNet (Inception v1), joka esitteli Inception-kerroksen ja syvän arkkitehtuurin. ~6.8 M parametria. <sup id="fnref:googlenet"><a class="footnote-ref" href="#fn:googlenet">7</a></sup>.</li>
<li><strong>2015</strong>: VGG-16, syvä konvoluutioverkko, joka käytti nimensä mukaisesti 16 kerrosta. ~138 M parametria. <sup id="fnref:vgg16"><a class="footnote-ref" href="#fn:vgg16">8</a></sup> <sup id="fnref:vgg16neurohive"><a class="footnote-ref" href="#fn:vgg16neurohive">9</a></sup>.</li>
<li><strong>2015</strong>: ResNet, esitteli "residual connections", jotka mahdollistivat erittäin syvien verkkojen koulutuksen. ~19 M parametria. <sup id="fnref:resnet"><a class="footnote-ref" href="#fn:resnet">10</a></sup> <sup id="fnref:resnetmedium"><a class="footnote-ref" href="#fn:resnetmedium">11</a></sup>.</li>
<li><strong>2015</strong>: U-Net, erityisen mielenkiintoinen arkkitehtuuri segmentointiin. ~31 M parametria. <sup id="fnref:unet"><a class="footnote-ref" href="#fn:unet">12</a></sup>.</li>
<li><strong>2017</strong>: Mask R-CNN, joka yhdisti objektin tunnistuksen ja segmentoinnin. ~44 M parametria. <sup id="fnref:maskrcnn"><a class="footnote-ref" href="#fn:maskrcnn">13</a></sup>.</li>
<li><strong>2018</strong>: DenseNet, joka käytti tiheitä yhteyksiä kerrosten välillä parantaakseen tiedonsiirtoa ja vähentääkseen gradientin katoamista. ~28 M parametria. <sup id="fnref:densenet"><a class="footnote-ref" href="#fn:densenet">14</a></sup>.</li>
<li><strong>2020</strong>: Vision Transformer (ViT), joka sovelsi transformer-arkkitehtuuria kuvantunnistukseen, tarjoten vaihtoehdon perinteisille konvoluutioverkoille. ~86 M parametria (ViT-Base). <sup id="fnref:vit"><a class="footnote-ref" href="#fn:vit">15</a></sup>.</li>
</ul>
<h2 id="piirrevektorit-kasin">Piirrevektorit käsin</h2>
<p>On hyödyksi pohtia, miten kuvia käsitellään perinteisissä tietokonenäön sovelluksissa ennen konvoluutioverkkojen aikakautta. Yksi keskeinen käsite on <strong>feature vector</strong> eli piirrevektori, joka tiivistää kuvan olennaiset piirteet matemaattiseen muotoon. Piirrevektori voi näytää vaikka tältä:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="c1"># Piirrevektoreita</span>
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a><span class="n">features</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a>    <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">],</span> <span class="c1"># kuva 1</span>
</span><span id="__span-1-4"><a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a>    <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">],</span> <span class="c1"># kuva 2</span>
</span><span id="__span-1-5"><a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a>    <span class="o">...</span><span class="p">,</span>
</span><span id="__span-1-6"><a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a><span class="p">]</span>
</span><span id="__span-1-7"><a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a>
</span><span id="__span-1-8"><a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a><span class="c1"># Nyt voisimme kouluttaa esimerkiksi binääriluokittelijan</span>
</span><span id="__span-1-9"><a id="__codelineno-1-9" name="__codelineno-1-9" href="#__codelineno-1-9"></a><span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>  <span class="c1"># 1 = kissa, 0 = koira</span>
</span><span id="__span-1-10"><a id="__codelineno-1-10" name="__codelineno-1-10" href="#__codelineno-1-10"></a><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</span></code></pre></div>
<p>Vektoreita voi etsiä monin eri tavoin, ja nämä tavat voidaan jakaa kahteen pääkategoriaan:</p>
<ul>
<li><strong>Image descriptor</strong>: Koko kuva-alueen värijakauma histogrammina, mediaaniväri tai jokin/jotkin muut globaalit ominaisuudet.<ul>
<li>1 kuva sisään, 1 vektori ulos.</li>
</ul>
</li>
<li><strong>Feature descriptor</strong>: Kuvaa kuvan <mark>paikallisia</mark> piirteitä, kuten reunat, kulmat tai tekstuurit.<ul>
<li>1 kuva sisään, N vektoria ulos (N on paikallisten alueiden määrä).</li>
</ul>
</li>
</ul>
<p>Koko kuvan pinta-alaa kuvaavat piirteet voivat olla harvoissa tapauksissa hyödyllisiä, mutta usein paikalliset piirteet tarjoavat enemmän informaatiota. Kuvan voi myös jakaa pienempiin osiin (esim. 100x100 pikselin kuva -&gt; 10x10 pikselin ruudukko) ja laskea kullekin osalle (engl <em>cell</em>) piirrevektori.</p>
<p>Muista, että tämän kurssin aiheena eivät ole perinteiset tietokonenäön menetelmät, vaan konvoluutioverkot. <mark>Ethän siis käytät tähän osioon kymmeniä tunteja</mark>, ellei kalenterisi ole harvinaisen väljä. Riittää, että tunnistat perusidean, mikä tarjoaa mahdollisuuden ymmärtää konvoluutioverkkojen hyötyjä paremmin.</p>
<p>Tutustutaan alla lyhyesti kahteen globaaliin <em>image descriptor</em> -menetelmään: LBP ja HOG.</p>
<h3 id="lbp">LBP</h3>
<p>Tekstuureita voi kuvastaa esimerkiksi Local Binary Patterns (LBP) -menetelmällä, jonka esittelivät Ojala et al. vuonna 2002 Oulun yliopiston julkaisussa "Multiresolution Gray Scale and Rotation Invariant Texture Classification with Local Binary Patterns" <sup id="fnref:lbp"><a class="footnote-ref" href="#fn:lbp">16</a></sup>. Paperi on ladattavissa kirjautumatta <a href="http://vision.stanford.edu/teaching/cs231b_spring1415/papers/lbp.pdf">Stanfordin CS216B kurssin linkistä</a>. LBP perustuu pikselin vertailuun sitä ympäröivien pikseleiden kanssa. Naiivi toteutus vertailee 3x3 alueen keskustaa muihin. Jos ympäröivä pikseli on kirkkaampi tai yhtä kirkas kuin keskuspikseli, sille annetaan arvo 1, muuten 0. Näin muodostuu 8-bittinen binaariluku, joka voidaan muuntaa desimaaliluvuksi. Kellonvastaisesti oletetaan siis, että ympäröivät pikselit ovat arvoltaan <span class="arithmatex">\(x_0 \times 2^0 + x_1 \times 2^1 + ... + x_7 \times 2^7\)</span>. Tämä luku kuvaa kyseisen pikselin tekstuuria. Monimutkaisemmassa esimerkissä voidaan valita säde, jolloin ympäröivät pisteet eivät olekaan välittömästi keskuspikselin vieressä, vaan kauempana. Katso Kuva 3, jossa tämä toteutus on havainnollistettu.</p>
<p><img alt="" src="../../images/500_LBP_neighbors.svg" /></p>
<p><strong>Kuva 3:</strong> <em>Local Binary Patterns (LBP) -menetelmä vertailee keskuspikseliä sitä ympäröiviin pikseleihin. Kuva: By Xiawi - Own work, CC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=11743214</em></p>
<div class="admonition tip">
<p class="admonition-title">Käytännössä?</p>
<p>Jos haluat kokeilla LBP:tä Pythonissa, niin <code>skimage</code>-kirjasto tarjoaa valmiin toteutuksen: <a href="https://scikit-image.org/docs/0.25.x/auto_examples/features_detection/plot_local_binary_pattern.html">Local Binary Pattern for texture classification</a>. Jos haluat nähdä kokonaisemman esimerkin, Adrian Rosebrockin blogipostaus <a href="https://pyimagesearch.com/2021/05/03/face-recognition-with-local-binary-patterns-lbps-and-opencv/">Face Recognition with Local Binary Patterns (LBPs) and OpenCV</a> on hyvä paikka aloittaa. Huomaa, että näissäkin tapauksissa on vahva oletus, että sinulla on jokin tapa rajata kiinnostava alue kuvasta (esim. kasvot). Tähän voi käyttää perinteisiä tietokonenäön menetelmiä, kuten Haar-cascade -luokittelijoita tai HOG+SVM -yhdistelmää.</p>
</div>
<h3 id="hog">HOG</h3>
<p>HOG (Histogram of Oriented Gradients) on toinen suosittu piirrevektorin muodostamismenetelmä. Dalal ja Triggs esittelivät HOG:n vuonna 2005 julkaistussa artikkelissaan "Histograms of Oriented Gradients for Human Detection". Artikkeli on ladattavissa <a href="http://lear.inrialpes.fr/people/triggs/pubs/Dalal-cvpr05.pdf">Inria:n sivuilta</a>. Termin "oriented gradients" voi suomentaa suunnatuiksi kaltevuuksiksi. Sinulle on jo aiemmin kurssilta tuttu käsite <em>gradientti</em>, joka kuvaa funktion muutosnopeutta. Tässä muutoksella tarkoitetaan pikselin kirkkausarvon muutosta. Tämä muutos selvitetään – laita seuraava sana korvan taakse – <em>konvoluutiosuodattimilla</em> (esim. Sobel), jotka laskevat pikselin kirkkausarvon muutoksen horisontaalisesti (x-suunta) ja vertikaalisesti (y-suunta). Näin saadaan jokaiselle pikselille kaksi arvoa: <span class="arithmatex">\(G_x\)</span> ja <span class="arithmatex">\(G_y\)</span>. Näiden avulla voidaan laskea gradientin suuruus ja suunta:</p>
<div class="arithmatex">\[
\text{magnitude} = \sqrt{G_x^2 + G_y^2}
\]</div>
<p>Kuva jaetaan soluihin (engl. <em>cells</em>), esimerkiksi 10x10 pikselin alueisiin. Kustakin solusta lasketaan histogrammi, jossa on esimerkiksi 9 laaria (esim. 0-19°, 20-39°, ..., 160-179°). Pikselin gradientin kontribuutio painotetaan sen suuruudella, eli jyrkemmät muutokset vaikuttavat enemmän. Nämä laarit osallistuvat lohkoihin (engl. <em>blocks</em>), jotka liukuvat kuvan yli askelein siten, että lohkojen alueet voivat olla päällekkäisiä. Jokaisesta lohkosta saadaan normaaliarvoitu histogrammi, joka yhdistetään lopulta yhdeksi pitkäksi piirrevektoriksi koko kuvalle. Piirrevektorin pituus riippuu solujen ja lohkojen koosta sekä histogrammin laarien määrästä. Sen voi laskea näin, jos meillä on <code>200x200</code> kuva:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="n">ppc</span> <span class="o">=</span> <span class="mi">10</span>                       <span class="c1"># pixels per cell</span>
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="n">cbp</span> <span class="o">=</span> <span class="mi">2</span>                        <span class="c1"># cells per block</span>
</span><span id="__span-2-3"><a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a><span class="n">cells_xy</span> <span class="o">=</span> <span class="mi">200</span> <span class="o">//</span> <span class="n">ppc</span>          <span class="c1"># 20 cells per dimension</span>
</span><span id="__span-2-4"><a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a><span class="n">blocks_xy</span> <span class="o">=</span> <span class="n">cells_xy</span> <span class="o">-</span> <span class="mi">1</span>       <span class="c1"># 19 blocks per dimension (assuming stride 1)</span>
</span><span id="__span-2-5"><a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a><span class="n">feat_per_block</span> <span class="o">=</span> <span class="n">cbp</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">*</span> <span class="mi">9</span>  <span class="c1"># 2x2 cells per block, 9 bins per histogram</span>
</span><span id="__span-2-6"><a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a><span class="n">fd</span> <span class="o">=</span> <span class="n">blocks_xy</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">feat_per_block</span>
</span><span id="__span-2-7"><a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a><span class="c1"># Output: 12996</span>
</span></code></pre></div>
<p>Voi olla hyödyllistä silmäillä läpi myös: <a href="https://medium.com/analytics-vidhya/a-gentle-introduction-into-the-histogram-of-oriented-gradients-fdee9ed8f2aa">Medium.com | Katthik Mittal: A Gentle Introduction Into The Histogram Of Oriented Gradients</a></p>
<p><img alt="alt text" src="../../images/500_hog_cat_loop_nanobanana.png" /></p>
<p><strong>Kuva 4:</strong> <em>HOG-piirteiden visualisointi. Kuva on 200x200 pikseliä ja solun koko 10x10 (turkoosi viiva). Keltaiset neliöt näyttävät blockin (2x2 solua, yhteensä 20x20 pikseliä) kolme ensimmäistä sijaintia, kun block liukuu yhden solun askelin x-suunnassa. Opacity kasvaa (0.2 → 0.3 → 1.0) havainnollistamaan liukumisen etenemistä. HOG-kuvassa gradientti määrää viivan suunnan ja voimakkuus paksuuden. Kissakuva: Nanobanana.</em></p>
<div class="admonition tip">
<p class="admonition-title">Mitä tällä siis tekee?</p>
<p>Vastaavan HOG-piirrevektorin voisi syöttää esimerkiksi:</p>
<ol>
<li>SVM-luokittelijalle</li>
<li>FCNN-verkolle</li>
</ol>
<p>Jos laskisit HOG-piirteet MNIST-numeroista, niin voisit käyttää FCNN:ää kuten kurssilla aiemminkin on käytetty. Erona olisi, että pelkän pikselin intensiteetin sijaan syötteenä olisi tietoa reunojen suunnista ja voimakkuuksista. Neuroverkkojen osalta tämä lähestymistapa on kuitenkin vanhentunut, sillä konvoluutioverkot pystyvät oppimaan piirteet suoraan kuvista ilman erillistä piirrevektorin laskentaa.</p>
</div>
<h3 id="fast-ja-sift">FAST ja SIFT</h3>
<p>Edellä esitellyt LBP ja HOG laskevat piirteitä koko kuvasta (tai rajatusta/ikkunoidusta osasta). Toinen lähestymistapa on tunnistaa ensin <strong>kiinnostavat pisteet</strong> (keypoints) kuvasta ja laskea piirrevektori <mark>vain näiden pisteiden</mark> ympäriltä. Ensimmäiseen vaiheeseen, jossa tunnistaan kiinnostavat pisteet, voidaan käyttää erilaisia algoritmeja, kuten: <strong>FAST</strong>, <strong>Harris</strong> tai <strong>DoG</strong>. Jälkimmäiseen vaiheeseen, jossa lasketaan kustakin kiinnostavasta pisteestä piirrevektori, voidaan käyttää menetelmiä kuten <strong>SIFT</strong> tai <strong>SURF</strong>.</p>
<p>Käsitellään lyhyesti näistä kenties yksinkertaisin kombinaatio: FAST + SIFT.</p>
<p><strong>FAST (Features from Accelerated Segment Test)</strong>: Etsii kiinnostavia pisteitä vertaamalla pikselin kirkkausarvoa sitä ympäröiviin pikseleihin. Tämä ei ole erityisen kaukana siitä, miten LBP toimii.</p>
<p><img alt="" src="../../images/500_FAST_corner_pattern.jpg" /></p>
<p><strong>Kuva 5:</strong> <em>FAST-algoritmin pikselimalli. Keskuspikseli (kirkas) verrataan ympäröiviin pikseleihin (tummat). Jotta pikseli luokiteltaisiin kulmaksi, sen ympärillä täytyy olla jatkuva kaari, jossa vähintään n peräkkäistä pikseliä (säteellä r) poikkeavat keskuspikselin kirkkaudesta samaan suuntaan – kaikki joko kirkkaampia tai tummempia – vähintään kynnysarvon t verran. Kuva: Jingjin Huang, Guoqing Zhou, Xiang Zhou and Rongting Zhang, CC <a href="https://creativecommons.org/licenses/by/4.0">BY 4.0</a>, via Wikimedia Commons</em></p>
<p><strong>SIFT (Scale-Invariant Feature Transform)</strong>: Kun kiinnostavat pisteet on löydetty FAST:lla, seuraava vaihe on muodostaa piirrevektorit. SIFT:n esitteli David Lowe vuonna 2004 julkaistussa artikkelissaan "Distinctive Image Features from Scale-Invariant Keypoints" <sup id="fnref:sift"><a class="footnote-ref" href="#fn:sift">17</a></sup>. SIFT laskee kullekin kiinnostavalle pisteelle piirrevektorin, joka on tyypillisesti 128-ulotteinen. Toteutus ei juuri poikkea HOG:sta, sillä SIFT käyttää myös kaltevuuksia (oriented gradients) piirteiden laskentaan. SIFT ottaa 16x16 alueen kiinnostavan pisteen ympäriltä ja jakaa sen 4x4 soluun (cells). Jokaisesta solusta lasketaan 8-bittinen histogrammi kaltevuuksista, käyttäen gaussian-painotusta, jolloin kaukana olevat pikselit vaikuttavat vähemmän. Lopuksi nämä histogrammit yhdistetään yhdeksi pitkäksi piirrevektoriksi. 4x4 solua, joissa kussakin 8 laaria, antaa yhteensä <span class="arithmatex">\(4 \times 4 \times 8 = 128\)</span>-ulotteisen vektorin.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Voi olla hyödyllistä käyttää 20 sekuntia elämästään katsoen kahta seuraavaa linkkiä, joissa esitellään kombinaatiotyökalut, jotka hoitavat sekä kiinnostavien pisteiden etsinnän että piirrevektorin laskennan. Katso erityisesti kuvat:</p>
<ul>
<li><a href="https://scikit-image.org/docs/0.25.x/auto_examples/features_detection/plot_orb.html">scikit-image: ORB feature detector and binary descriptor</a></li>
<li><a href="https://scikit-image.org/docs/0.25.x/auto_examples/features_detection/plot_sift.html">scikit-image: SIFT feature detector and descriptor extractor</a></li>
</ul>
<p>Bonus: jos aihe kiinnostaa enemmänkin, tutustu OpenCV:n dokumentaation osioon <a href="https://docs.opencv.org/4.12.0/db/d27/tutorial_py_table_of_contents_feature2d.html">Feature Detection and Description</a>. Jo pelkkä kuvien katselu voi konkretisoida aihetta.</p>
</div>
<div class="admonition info">
<p class="admonition-title">Mitä näillä siis tekeekään?</p>
<p>Jos jäi yhä vaivaamaan, mitä näillä piirrevektoreilla tekee, ja että eikös näitä synny joka kuvasta eri määrä, niin lyhyt vastaus:</p>
<ol>
<li>Kerätään kaikista kuvista kaikki piirrevektorit (esim. SIFT). Tämä on vocabulary.</li>
<li>Klusteroidaan vocabulary:n piirrevektorit (esim. K-means) ja määritellään kunkin klusterin keskipiste "visuaaliseksi sanaksi".</li>
<li>Lasketaan kullekin kuvalle histogrammi, joka kuvaa, kuinka monta kertaa kukin visuaalinen sana esiintyy kyseisessä kuvassa.</li>
</ol>
<p>Näistä voi sitten rakentaa: </p>
<ul>
<li>Google Reverse Image Search -tyyppisen sovelluksen, jossa syötetään kuva ja haetaan samankaltaisia kuvia.</li>
<li>...tai tyypillisen luokittelijan.</li>
</ul>
<p>Pidempi ja visuaalisempi vastaus: <a href="https://www.pinecone.io/learn/series/image-search/bag-of-visual-words/">Pinecone | Bag of Visual Words</a></p>
</div>
<h2 id="piirrevektorit-konvoluutioverkoissa">Piirrevektorit konvoluutioverkoissa</h2>
<h3 id="arkkitehtuuri">Arkkitehtuuri</h3>
<p>Aiemmasta opitusta on hyötyä, sillä konvoluutioverkkojen <em>head</em> eli viimeiset kerrokset ovat tuttuja FC-kerroksia (eli <em>fully connected</em>). Mallin viimeiset kerrokset ovat siis tyypillinen FCNN, joka ottaa syötteenään piirrevektorin ja tuottaa luokitusennusteen. Konvoluutioverkkojen voima piilee kuitenkin niiden <em>body</em>-osassa, joka koostuu uudenlaisista termeistä: <strong>konvoluutiokerros</strong> (<em>convolutional</em>) ja <strong>koontikerros</strong> (<em>pooling</em>). Malli on toki yhä <em>eteenpäin kytketty</em> (feedforward), mutta ei enää täysin kytketty (fully connected).</p>
<p><img alt="alt text" src="../../images/500_cnn_arch.png" /></p>
<p><strong>Kuva 6:</strong> <em>Yksinkertainen konvoluutioverkon arkkitehtuuri. Kuva on luotu <a href="https://alexlenail.me/NN-SVG/AlexNet.html">NN-SVG</a>-työkalulla.</em></p>
<p>Yllä oleva kuva havainnollistaa konvoluutioverkon arkkitehtuuria yksinkertaistetusti. Syöte on 224×224×3 RGB-kuva. Verkko koostuu kolmesta pääosasta:</p>
<p><strong>1. Konvoluutiokerrokset (body):</strong> Kolme suurta laatikkoa vasemmalla edustavat konvoluutiokerroksia, jotka tunnistavat kuvan piirteitä. Ensimmäinen kerros tuottaa 96 kappaletta 55×55-kokoisia piirrekarttoja. Kolmannessa kerroksessa piirrekartat ovat kutistuneet 13×13-kokoisiksi, mutta niitä on enemmän (384 kpl). Kerroksien välissä näkyvä sini-punainen "lyijykynä" kuvaa konvoluutio-operaatiota: lyijykynän runko edustaa <span class="arithmatex">\(n \times n\)</span> suodinta (kernel), joka liukuu syötteen yli, ja kärki osoittaa kohtaan, johon suotimen tulos tallennetaan.</p>
<p><strong>2. Litistäminen (flatten):</strong> Konvoluutiokerrosten tuottamat 3D-piirrekartat litistetään yhdeksi pitkäksi vektoriksi.</p>
<p><strong>3. Täysin kytketyt kerrokset (head):</strong> Oikealla olevat kaksi pystysuoraa palkkia edustavat perinteisiä FCNN-kerroksia. Nämä ottavat litistetyn piirrevektorin syötteenään ja tuottavat lopulta 10-ulotteisen logit-vektorin (tässä oletetaan 10 luokkaa).</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Tämä on AlexNet-tyyppinen visualisointi, jossa pooling-kerrokset on jätetty pois yksinkertaisuuden vuoksi. Todellisuudessa pooling-kerrokset pienentävät piirrekarttojen kokoa konvoluutiokerrosten välissä.</p>
</div>
<h3 id="konvoluutiokerros">Konvoluutiokerros</h3>
<p><img alt="" src="../../images/500_Conv2D.svg" /></p>
<p><strong>Kuva 7:</strong> <em>2D-konvoluutiokerros. Kukin lähtöarvo on painotettu summa lähimmistä 3×3 syötteistä (plus bias ja aktivointi). Ylärivin kuvat a ja b esittelevät, kuinka suodin liikkuu kuvassa. Seuraava kerros (<span class="arithmatex">\(H_1\)</span> eli käytännössä piirrekartta eli feature map) syntyy 3x3 syötteen ja painojen pistetulosta. Alarivin kuvat c ja d esittelevät, kuinka nollilla toppaamiinen (zero-padding) mahdollistavat reunapikseleiden arvojen käytön. <sup id="fnref3:udlbook"><a class="footnote-ref" href="#fn:udlbook">3</a></sup></em></p>
<p><img alt="" src="../../images/500_ConvImage.svg" /></p>
<p><strong>Kuva 8:</strong> <em>RGB-kuvassa, kuten myös myöhemmissä piirrekartoissa, on enemmän kuin 1 kanava. RGB-kuvan tapauksessa filtteri on kokoa <span class="arithmatex">\(3 \times 3 \times 3\)</span> (leveys x korkeus x syvyys). Jokainen kanava (R, G, B) kerrotaan vastaavalla suotimella. Nämä summataan yhteen, lisätään bias, ja aktivoidaan jolloin saadaan yksi arvo piirrekarttaan. <sup id="fnref4:udlbook"><a class="footnote-ref" href="#fn:udlbook">3</a></sup></em></p>
<p>Pysähdy tässä välissä ja lue tämä visuaalisesti ja selkeästi toteutettu selostus aiheesta: <a href="https://medium.com/data-science/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53">A Comprehensive Guide to Convolutional Neural Networks — the ELI5 way</a></p>
<p>Konvoluutiokerros suorittaa syötteelle konvoluution, joka on matemaattinen operaatio, jossa pieni suodin (kernel/filter) liukuu syötteen yli ja laskee pistetulon (dot product) suotimen ja syötteen vastaavien osien välillä. Tämä prosessi mahdollistaa paikallisten piirteiden, kuten reunojen, kulmien ja tekstuurien, tunnistamisen kuvasta. Aiheeseen tutustumiseen auttaa, jos tutkit, kuinka erilaiset suotimet (esim. reunojen tunnistamiseen tarkoitetut Sobel-suotimet) toimivat. Tähän on mainio apusivusto: <a href="https://setosa.io/ev/image-kernels/">Setosa.io | Image Kernels explained visually</a>.</p>
<p>Peräkkäin kytketyt konvoluutiokerrokset mahdollistavat yhä monimutkaisempien piirteiden oppimisen. Alkuvaiheen kerrokset saattavat tunnistaa yksinkertaisia piirteitä, kuten reunat ja kulmat, kun taas syvemmät kerrokset voivat yhdistellä näitä piirteitä muodostaakseen monimutkaisempia kuvioita, kuten kasvoja tai esineitä. Kukin konvoluutiokerros ottaa seuraavat parametrit sisäänsä <sup id="fnref:pyisgurus"><a class="footnote-ref" href="#fn:pyisgurus">18</a></sup>:</p>
<ul>
<li>Syöte: <span class="arithmatex">\(W_1 \times H_1 \times D_1\)</span> (leveys x korkeus x syvyys/kanavat)</li>
<li>Filttereiden määrä: <span class="arithmatex">\(K\)</span> (eli syvyyssuunnan koko)</li>
<li>Suotimen koko: <span class="arithmatex">\(F\)</span> (esim. <span class="arithmatex">\(3 \times 3\)</span>)</li>
<li>Askel (stride): <span class="arithmatex">\(S\)</span> (usein 1)</li>
<li>Toppaus (padding): <span class="arithmatex">\(P\)</span> (usein <code>j // 2</code> eli 'same' toppaus)</li>
</ul>
<p>Konvoluutiokerroksen lähtö täten kokoa:</p>
<ul>
<li>Leveys: <span class="arithmatex">\(W_2 = \frac{W_1 - F + 2P}{S} + 1\)</span></li>
<li>Korkeus: <span class="arithmatex">\(H_2 = \frac{H_1 - F + 2P}{S} + 1\)</span></li>
<li>Syvyys: <span class="arithmatex">\(D_2 = K\)</span></li>
</ul>
<p>Tämä osuus on jätetty lyhyeksi, koska aihe on niin kattavasti selitetty kurssikirjoissa, yllä olevassa Medium-artikkelissa ja esimerkiksi StatQuestin sekä 3Blue1Brownin videoissa.</p>
<h3 id="koontikerros">Koontikerros</h3>
<p>Koontikerros (pooling layer) on konvoluutioverkon komponentti, joka suorittaa alinäytteistämisen (downsampling) syötteelle. Tämän kerroksen päätarkoituksena on vähentää piirrekarttojen (engl. feature maps, activation maps) spatiaalista kokoa (leveys ja korkeus), mikä auttaa vähentämään laskennallista kuormitusta, muistinkäyttöä ja ylikoulutuksen riskiä. Koontikerros tiivistää tärkeimmät piirteet säilyttäen samalla olennaisen informaation. Näitä on montaa eri sorttia, mutta yleisimmät ovat <strong>max-pooling</strong> ja <strong>average-pooling</strong>. Näiden PyTorch-toteutukset löytyvät <code>torch.nn.MaxPool2d</code> ja <code>torch.nn.AvgPool2d</code> -luokista. Näiden 2-ulotteisten koontikerrosten lisäksi on olemassa myös 1-ulotteisia ja 3-ulotteisia versioita, joita käytetään vastaavasti 1D- ja 3D-datassa. Géron esittelee myös harvinaisemmat tyypit: <strong>depthwise pooling</strong> ja <strong>global average pooling</strong> <sup id="fnref:geronpytorch"><a class="footnote-ref" href="#fn:geronpytorch">1</a></sup>.</p>
<p><img alt="" src="../../images/500_pooling.png" /></p>
<p><strong>Kuva 9:</strong> <em>Max-pooling toteutettuna 5x5 taulukkoa vasten. Suotimen koko on 3x3. Ylemmässä esimerkissä askel on 1, alemmassa askel on 2. Kummassakin tapauksessa on esitelty kolme ensimmäistä askelta.</em></p>
<p>Kukin koontikerros ottaa seuraavat parametrit sisäänsä <sup id="fnref2:pyisgurus"><a class="footnote-ref" href="#fn:pyisgurus">18</a></sup>:</p>
<ul>
<li>Syöte: <span class="arithmatex">\(W_1 \times H_1 \times D_1\)</span> (leveys, korkeus, syvyys/kanavat)</li>
<li>Suotimen koko: <span class="arithmatex">\(F\)</span> (esim. <span class="arithmatex">\(2 \times 2\)</span>)</li>
<li>Askel (stride): <span class="arithmatex">\(S\)</span></li>
</ul>
<p>Koontikerroksen lähtö täten kokoa:</p>
<ul>
<li>Leveys: <span class="arithmatex">\(W_2 = \frac{W_1 - F}{S} + 1\)</span></li>
<li>Korkeus: <span class="arithmatex">\(H_2 = \frac{H_1 - F}{S} + 1\)</span></li>
<li>Syvyys: <span class="arithmatex">\(D_2 = D_1\)</span></li>
</ul>
<p>Hyvin tyypillinen koontikerros on <span class="arithmatex">\(2 \times 2\)</span> max-pooling, jossa askeleena on 2. Tämä tarkoittaa, että kuvan leveys ja korkeus puolittuvat jokaisella pooling-kerroksella. Kärjistäen kyseessä on siis <code>resize(50 %, interpolation=max)</code>-operaatio. Muista kuitenkin, että tässä ei sinänsä enää pienennetä <em>kuvaa</em> vaan <em>piirrekarttoja</em>.</p>
<h2 id="case-study-fractional-max-pooling-graham-2014">Case Study: Fractional Max-Pooling (Graham, 2014)</h2>
<p>Tässä osiossa syvennytään Benjamin Grahamin vuonna 2014 esittelemään <strong>Fractional Max-Pooling</strong> -arkkitehtuuriin, joka saavutti aikanaan poikkeuksellisen alle 4 % virheasteen CIFAR-10-datasetillä <sup id="fnref3:fractionalmp"><a class="footnote-ref" href="#fn:fractionalmp">2</a></sup>. Malli on erinomainen esimerkki siitä, kuinka konvoluutioverkkojen suunnittelussa voidaan poiketa valtavirran konventioista ja saavuttaa silti huipputuloksia. Motivaatio arkkitehtuurin valinnalle case studyyn on juurikin tämä: älä lukitse itseäsi ajattelemaan, että on vain yksi tapa rakentaa konvoluutioverkkoja tai muitakaan neuroverkkoja.</p>
<p>Case studyn koodi on toteutettu <code>501_fractional_max_pooling.py</code>-tiedostossa. Tähän osioon liittyy osion ensimmäinen tehtävä. Lue se alta.</p>
<h4 id="arkkitehtuurin-filosofia-ja-suotimien-kasvu">Arkkitehtuurin filosofia ja suotimien kasvu</h4>
<p>Tyypillisesti konvoluutioverkoissa, kuten VGG:ssä tai ResNetissä, kanavien määrä kaksinkertaistetaan tietyin väliajoin (esim. 64 <span class="arithmatex">\(\to\)</span> 128). Grahamin mallissa lähestymistapa on kuitenkin erilainen: kanavien määrä kasvaa lineaarisesti kaavalla <span class="arithmatex">\(160 \times n\)</span>, missä <span class="arithmatex">\(n\)</span> on kerroksen järjestysnumero <sup id="fnref4:fractionalmp"><a class="footnote-ref" href="#fn:fractionalmp">2</a></sup>.</p>
<h4 id="fractional-max-pooling-mekanismi">Fractional Max-Pooling -mekanismi</h4>
<p>Mallin keskeinen innovaatio on nimensä mukainen Fractional Max-Pooling. Perinteinen <span class="arithmatex">\(2\times2\)</span> max-pooling puolittaa kuvan koon jokaisella askeleella, mikä rajoittaa verkon syvyyttä pienillä kuvilla. Grahamin ratkaisussa skaalauskerroin on <span class="arithmatex">\(\sqrt[3]{2}\)</span> (noin 1,26) <sup id="fnref5:fractionalmp"><a class="footnote-ref" href="#fn:fractionalmp">2</a></sup>. Tämä maltillisempi koon pienentäminen mahdollistaa huomattavasti syvemmät verkot ilman, että piirrekartat kutistuvat liian nopeasti <span class="arithmatex">\(1\times1\)</span>-pikselin kokoon.</p>
<p>Lisäksi menetelmä hyödyntää satunnaisuutta. Pooling-alueet voidaan valita joko limittäin (overlapping) tai erillisinä (disjoint) ja niiden sijainti arvotaan <sup id="fnref6:fractionalmp"><a class="footnote-ref" href="#fn:fractionalmp">2</a></sup>. Kannattaa katsoa Figure 1 alkuperäisestä julkaisusta: se selventää asiaa, kuinka digitaalisessa kuvassa voi käyttää poolingia, joka ei ole kahdella jaollinen.</p>
<h4 id="moderni-head-rakenne">Moderni "Head" -rakenne</h4>
<p>Verkon loppuosa poikkeaa myös tyypillisestä CNN:stä. Sen sijaan, että piirrekartat litistettäisiin (flatten) ja syötettäisiin tiheille (Dense/Linear) kerroksille, malli käyttää <span class="arithmatex">\(1\times1\)</span> konvoluutiota (C1) <sup id="fnref7:fractionalmp"><a class="footnote-ref" href="#fn:fractionalmp">2</a></sup>. Tämä kerros projisoi piirteet suoraan luokkien lukumäärää vastaavaksi vektoriksi.</p>
<h4 id="regularisointi-ja-koulutuksen-erikoisuudet">Regularisointi ja koulutuksen erikoisuudet</h4>
<p>Koska malli on valtava suhteessa datasetin kokoon, regularisointi on kriittistä. Mallissa sovelletaan "kasvavaa dropoutia": ensimmäisissä piilotetuissa kerroksissa dropout on 0 %, ja se kasvaa lineaarisesti 50 %:iin verkon loppupäätä kohden. <sup id="fnref8:fractionalmp"><a class="footnote-ref" href="#fn:fractionalmp">2</a></sup></p>
<p>Toinen tekninen erikoisuus liittyy verkon syötteen kokoon. Koska pooling-suhde on murtoluku, verkon vaatima syötekoko ei ole triviaali laskea. Käytännössä haluttu output-koko päätetään ensin, ja vaadittu input-koko lasketaan "takaperin" kertomalla kokoa skaalauskertoimella jokaisen kerroksen kohdalla. Tämä johtaa usein siihen, että alkuperäisiä kuvia on pehmustettava (padding) runsaasti.</p>
<h4 id="inferenssi-verkko-on-itsessaan-ensemble">Inferenssi: Verkko on itsessään ensemble</h4>
<p>Pooling-vaiheen satunnaisuudesta johtuen saman kuvan ajaminen verkon läpi useaan kertaan tuottaa hieman erilaisia ennusteita. Tätä ominaisuutta hyödynnetään testausvaiheessa (inference). Lopullinen luokitus ei perustu yhteen ajokertaan, vaan usean (esim. 12) ajokerran keskiarvoon (Model Averaging). Tämä toimii ikään kuin "köyhän miehen ensemble-menetelmänä", parantaen luotettavuutta ilman tarvetta kouluttaa useita erillisiä verkkoja. <sup id="fnref9:fractionalmp"><a class="footnote-ref" href="#fn:fractionalmp">2</a></sup> Tätä ei ole toteutettu kurssin koodissa, mutta voit halutessasi kokeilla tätä itse. Se hoituisi jotakuinkin näin:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">model</span><span class="p">(</span><span class="n">image</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">12</span><span class="p">)]</span>   <span class="c1"># Run 12 times</span>
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a><span class="n">avg_output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># Average predictions</span>
</span></code></pre></div>
<h2 id="tehtavat">Tehtävät</h2>
<div class="admonition question">
<p class="admonition-title">Tehtävä: Tutustuminen Fractional Max-Pooling -toteutukseen</p>
<p>Avaa tiedosto <code>notebooks/nb/500/501_fractional_max_pooling.py</code>. Tutki koodia ja pohdi oppimispäiväkirjassasi seuraavia kysymyksiä:</p>
<ul>
<li><strong>Käänteinen koon laskenta:</strong> Miten <code>get_fmp_sizes</code>-funktio toimii? Miksi verkon kerrosten koot lasketaan "lopusta alkuun" (output <span class="arithmatex">\(\to\)</span> input)?</li>
<li><strong>Dynaaminen padding:</strong> Toteutuksessa käytetään dynaamista paddingia (<code>pad_total</code>). Miksi tämä on välttämätöntä juuri tässä arkkitehtuurissa, kun taas esimerkiksi VGG-verkossa pärjätään kiinteällä paddingilla?</li>
<li><strong>Verkon "pää" (Head):</strong> Miten <code>FMPNet</code>-luokan <code>forward</code>-metodin loppuosa eroaa perinteisestä <code>nn.Linear</code>-kerroksesta? Miksi tässä on käytetty <span class="arithmatex">\(1\times1\)</span> konvoluutiota (<code>convC1</code>)? Onko kenties niin, että matemaattisesti <span class="arithmatex">\(1\times1\)</span> konvoluutio <span class="arithmatex">\(1\times1\)</span> kokoisella spatiaalisella kartalla on identtisen täysin kytketyn kerroksen kanssa?</li>
<li><strong>Ensemble-ennustaminen:</strong> Miten mallin ennusteet lasketaan testausvaiheessa? Miksi sama kuva syötetään verkolle useita kertoja? Eikö neuroverkko olekaan deterministinen? Miksi minun toteutus toimii, vaikka siinä ei syötetä kuin kerran?</li>
</ul>
<p>Mallin kouluttamiseen meni opettajan GeForce RTX 3060 Ti:llä <mark>yli 11 tuntia</mark> (300 epookkia, noin 2 min 17 sek per epookki). Saat kouluttaa mallin itse tai voit käyttää valmista mallia, joka on tallennettu tiedostoon <code>notebooks/gitlfs-store/502_cifar10_fractionalmaxp.pth</code>. Huomaa, että repositorio tulee kloonata Git LFS -tuen kanssa, jotta malli löytyy koneeltasi. Jos tämä on täysin vieras konsepti, lue: <a href="https://sourander.github.io/how-to-git/kaytto/lfs/">How to Git | GitLab: LFS</a></p>
</div>
<div class="admonition question">
<p class="admonition-title">Tehtävä: FMP ja MNIST</p>
<p>Toteuta tiedostoon <code>notebooks/nb/500/503_fractional_max_pool_MNIST.py</code> versio Grahamin mallista, joka on sovitettu MNIST-datasetille.</p>
<p>Alkuperäisessä paperissa (Graham, 2014) on määritelty MNIST:lle kevyempi arkkitehtuuri kuin CIFAR-10:lle. Etsi paperista (tai kokeile itse) sopivat parametrit ja muokkaa koodia seuraavasti:</p>
<ul>
<li><strong>Dataset:</strong> Vaihda CIFAR-10 <span class="arithmatex">\(\to\)</span> MNIST. Huomioi, että MNIST on mustavalkoinen (1 kanava), kun taas CIFAR-10 on värillinen (3 kanavaa).</li>
<li><strong>Arkkitehtuuri:</strong> Paperin mukaan MNIST-mallissa käytetään eri määrää kerroksia ja eri kasvukerrointa.<ul>
<li>CIFAR-10-mallissa kerroksia oli 12 ja kasvukerroin suuri.</li>
<li>MNIST-mallille riittää vähempi määrä kerroksia ja pienempi kasvukerroin.</li>
<li>Myös skaalauskerroin <span class="arithmatex">\(\alpha\)</span> voi olla eri (esim. <span class="arithmatex">\(\sqrt{2}\)</span> vs <span class="arithmatex">\(\sqrt[3]{2}\)</span>), jotta kuva kutistuu sopivasti 28x28-koosta.</li>
</ul>
</li>
<li><strong>Tavoite:</strong> Kouluta malli ja vertaa saavuttamaasi tarkkuutta.<ul>
<li>Pärjännet reilusti pienemmällä epookkimäärällä kuin 300.   </li>
</ul>
</li>
</ul>
<p>Oikean arkkitehtuurin myötä mallin luomisen jälkeen pitäisi tulostua <code>Total trainable parameters: 438,826</code> ja <code>debug_forward_pass()</code>-funktion pitäisi tulostaa jotakuinkin seuraavaa viimeisissä riveissään::</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a>[Head] Input: torch.Size([1, 192, 2, 2]) (Expected 2x2)
</span><span id="__span-4-2"><a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a>-&gt; ConvC2 (2x2 kernel): torch.Size([1, 192, 1, 1]) (Should be 1x1)
</span><span id="__span-4-3"><a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a>-&gt; ConvC1 (1x1 kernel): torch.Size([1, 10, 1, 1]) (Channels = Num Classes)
</span><span id="__span-4-4"><a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a>-&gt; Final Output (Flattened): torch.Size([1, 10])
</span></code></pre></div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Voit kokeilla, kauan mallin koulutus kestää GPU vs. CPU. Jos haluat säästää aikaa, selvitä 10 epookkiin kuluva aika ja skaalaa se haluamaasi epookkimäärään. Opettajan GPU:lla kesti noin 7 sekuntia per epookki (batch size 32). Jos CPU olisi käytössä, niin mikä seuraavista olisi oikea arvio?</p>
<ul>
<li>10 sekuntia per epookki (+ 43 %)</li>
<li>30 sekuntia per epookki (+ 329 %)</li>
<li>1 min 30 s per epookki (+ 1186 %)</li>
<li>2 min 30 s per epookki (+ 2043 %)</li>
</ul>
</div>
</div>
<div class="admonition question">
<p class="admonition-title">Tehtävä: LeNet ja MNIST</p>
<p>Toteuta tiedostoon <code>notebooks/nb/500/504_lenet_MNIST.py</code> LeNet-5 -arkkitehtuuri MNIST-datasetille. Vertaile sen suorituskykyä toteuttamaasi  Grahamin Fractional Max-Pooling -malliin. Saat itse valita, toteutatko mahdollisimman orjallisesti alkuperäisen mallin vai Adrian Rosebrockin tulkitseman modernisoidun version. </p>
<p><strong>Vaihtoehto 1: Orjallinen LeNet-5</strong></p>
<p>Mallin arkkitehtuuri löytyy LeCunin alkuperäisestä paperista <sup id="fnref2:lenet5"><a class="footnote-ref" href="#fn:lenet5">5</a></sup>. Jos haluat olla uskollinenalkuperäiselle arkkitehtuurille, voit käyttää LeCunin tanh-aktivointifunktiota, jonka toteutus on <span class="arithmatex">\(1.7159 \times \tanh(\frac{2}{3}x)\)</span>.</p>
<p>Alkuperäisessä paperissa mainitaan 32x32 syötekoko. MNIST on 28x28, joten voit lisätä kuviin 2 pikselin reunuksen (padding) joka reunalle, jolloin kuvat ovat 32x32-kokoisia. Tämä prosessi liittyy paperin lauseeseen: <em>"In the first version, the images were centered in a 28 x 28 image by computing the center of mass of the pixels, and translating the image so as to position this point at the center of the 28x28 field In some instances, this 28x28 field was ex tended to 32x32 with background pixels"</em>.</p>
<p><strong>Vaihtoehto 2: Modernisoitu LeNet-5</strong></p>
<p>Modernisoitu versio on Adrian Rosebrockin blogipostauksesta <a href="https://pyimagesearch.com/2016/08/01/lenet-convolutional-neural-network-in-python/">LeNet – Convolutional Neural Network in Python</a> tai hänen kirjastaan <em>Deep Learning for Computer Vision with Python</em>. Tässä versiossa käytetään ReLU-aktivointia. Arkkitehtuuri on seuraava:</p>
<table>
<thead>
<tr>
<th>Layer Type</th>
<th>Output Size</th>
<th>Filter Size / Stride</th>
</tr>
</thead>
<tbody>
<tr>
<td>Input</td>
<td>28x28x1</td>
<td></td>
</tr>
<tr>
<td>Conv1</td>
<td>28x28x20</td>
<td>5x5 / K = 20</td>
</tr>
<tr>
<td>Act1</td>
<td>28x28x20</td>
<td>ReLU</td>
</tr>
<tr>
<td>Pool1</td>
<td>14x14x20</td>
<td>2x2 / S = 2</td>
</tr>
<tr>
<td>Conv2</td>
<td>14x14x50</td>
<td>5x5 / K = 50</td>
</tr>
<tr>
<td>Act2</td>
<td>14x14x50</td>
<td>ReLU</td>
</tr>
<tr>
<td>Pool2</td>
<td>7x7x50</td>
<td>2x2 / S = 2</td>
</tr>
<tr>
<td>FC1</td>
<td>500</td>
<td></td>
</tr>
<tr>
<td>Act3</td>
<td>500</td>
<td>ReLU</td>
</tr>
<tr>
<td>FC2</td>
<td>10</td>
<td></td>
</tr>
<tr>
<td>Softmax</td>
<td>10</td>
<td></td>
</tr>
</tbody>
</table>
</div>
<div class="admonition question">
<p class="admonition-title">Tehtävä: (Valinnainen) HOG</p>
<p>Tämä on valinnainen tehtävä. Kokeile <code>505_hog.py</code>-tiedostoa jotakin kuvaa vasten. Kyseisellä Notebookilla on luotu yllä oleva <em>"Kissa hyppää hularenkaasta"</em>-triptyykki.</p>
</div>
<h2 id="lahteet">Lähteet</h2>
<div class="footnote">
<hr />
<ol>
<li id="fn:geronpytorch">
<p>Géron, A. <em>Hands-On Machine Learning with Scikit-Learn and PyTorch</em>. O'Reilly. 2025.&#160;<a class="footnote-backref" href="#fnref:geronpytorch" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:geronpytorch" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:geronpytorch" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:geronpytorch" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:fractionalmp">
<p>Graham, B. <em>Fractional Max-Pooling</em>. University of Warwick. 2014 (version 4: 2015). https://doi.org/10.48550/arXiv.1412.6071&#160;<a class="footnote-backref" href="#fnref:fractionalmp" title="Jump back to footnote 2 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:fractionalmp" title="Jump back to footnote 2 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:fractionalmp" title="Jump back to footnote 2 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:fractionalmp" title="Jump back to footnote 2 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:fractionalmp" title="Jump back to footnote 2 in the text">&#8617;</a><a class="footnote-backref" href="#fnref6:fractionalmp" title="Jump back to footnote 2 in the text">&#8617;</a><a class="footnote-backref" href="#fnref7:fractionalmp" title="Jump back to footnote 2 in the text">&#8617;</a><a class="footnote-backref" href="#fnref8:fractionalmp" title="Jump back to footnote 2 in the text">&#8617;</a><a class="footnote-backref" href="#fnref9:fractionalmp" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
<li id="fn:udlbook">
<p>Prince, S. <em>Understanding Deep Learning</em>. The MIT Press. 2023. https://udlbook.github.io/udlbook/&#160;<a class="footnote-backref" href="#fnref:udlbook" title="Jump back to footnote 3 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:udlbook" title="Jump back to footnote 3 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:udlbook" title="Jump back to footnote 3 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:udlbook" title="Jump back to footnote 3 in the text">&#8617;</a></p>
</li>
<li id="fn:neocognition">
<p>Fukushima, K. <em>Neocognitron: A Self-organizing Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position</em>. Princeton. https://www.cs.princeton.edu/courses/archive/spr08/cos598B/Readings/Fukushima1980.pdf&#160;<a class="footnote-backref" href="#fnref:neocognition" title="Jump back to footnote 4 in the text">&#8617;</a></p>
</li>
<li id="fn:lenet5">
<p>LeCun, Y., Bottou, L., Bengio, Y., &amp; Haffner, P. <em>Gradient-Based Learning Applied to Document Recognition</em>. Proceedings of the IEEE, 86(11). http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf&#160;<a class="footnote-backref" href="#fnref:lenet5" title="Jump back to footnote 5 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:lenet5" title="Jump back to footnote 5 in the text">&#8617;</a></p>
</li>
<li id="fn:alexnet">
<p>Krizhevsky, A., Sutskever, I., &amp; Hinton, G. E. <em>ImageNet Classification with Deep Convolutional Neural Networks</em>. https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf&#160;<a class="footnote-backref" href="#fnref:alexnet" title="Jump back to footnote 6 in the text">&#8617;</a></p>
</li>
<li id="fn:googlenet">
<p>Szegedy, C. et. al. <em>Going Deeper with Convolutions</em>. https://arxiv.org/abs/1409.4842&#160;<a class="footnote-backref" href="#fnref:googlenet" title="Jump back to footnote 7 in the text">&#8617;</a></p>
</li>
<li id="fn:vgg16">
<p>Simonyan, K., &amp; Zisserman, A. <em>Very Deep Convolutional Networks for Large-Scale Image Recognition</em>. https://arxiv.org/abs/1409.1556&#160;<a class="footnote-backref" href="#fnref:vgg16" title="Jump back to footnote 8 in the text">&#8617;</a></p>
</li>
<li id="fn:vgg16neurohive">
<p>Hassan, M. <em>VGG16 – Convolutional Network for Classification and Detection</em>. Neurohive. https://neurohive.io/en/popular-networks/vgg16/&#160;<a class="footnote-backref" href="#fnref:vgg16neurohive" title="Jump back to footnote 9 in the text">&#8617;</a></p>
</li>
<li id="fn:resnet">
<p>He, K., Zhang, X., Ren, S., &amp; Sun, J. <em>Deep Residual Learning for Image Recognition</em>. https://arxiv.org/abs/1512.03385&#160;<a class="footnote-backref" href="#fnref:resnet" title="Jump back to footnote 10 in the text">&#8617;</a></p>
</li>
<li id="fn:resnetmedium">
<p>Azeem. <em>Understanding ResNet Architecture: A Deep Dive into Residual Neural Network</em>. https://medium.com/@ibtedaazeem/understanding-resnet-architecture-a-deep-dive-into-residual-neural-network-2c792e6537a9&#160;<a class="footnote-backref" href="#fnref:resnetmedium" title="Jump back to footnote 11 in the text">&#8617;</a></p>
</li>
<li id="fn:unet">
<p>Ronneberger, O., Fischer, P., &amp; Brox, T. <em>U-Net: Convolutional Networks for Biomedical Image Segmentation</em>. https://arxiv.org/abs/1505.04597&#160;<a class="footnote-backref" href="#fnref:unet" title="Jump back to footnote 12 in the text">&#8617;</a></p>
</li>
<li id="fn:maskrcnn">
<p>He, K., Gkioxari, G., Dollár, P., &amp; Girshick, R. <em>Mask R-CNN</em>. https://arxiv.org/abs/1703.06870&#160;<a class="footnote-backref" href="#fnref:maskrcnn" title="Jump back to footnote 13 in the text">&#8617;</a></p>
</li>
<li id="fn:densenet">
<p>Huang, G., Liu, Z., Van Der Maaten, L., &amp; Weinberger, K. Q. <em>Densely Connected Convolutional Networks</em>. https://arxiv.org/abs/1608.06993&#160;<a class="footnote-backref" href="#fnref:densenet" title="Jump back to footnote 14 in the text">&#8617;</a></p>
</li>
<li id="fn:vit">
<p>Dosovitskiy, A. et. al. <em>An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</em>. https://arxiv.org/abs/2010.11929&#160;<a class="footnote-backref" href="#fnref:vit" title="Jump back to footnote 15 in the text">&#8617;</a></p>
</li>
<li id="fn:lbp">
<p>Ojala, T., Pietikäinen, M., &amp; Mäenpää, T. <em>Multiresolution Gray Scale and Rotation Invariant Texture Classification with Local Binary Patterns</em>. IEEE Transactions on Pattern Analysis and Machine Intelligence, 24(7), 971-987. 2002. doi: 10.1109/TPAMI.2002.1017623&#160;<a class="footnote-backref" href="#fnref:lbp" title="Jump back to footnote 16 in the text">&#8617;</a></p>
</li>
<li id="fn:sift">
<p>Lowe, D. G. <em>Distinctive Image Features from Scale-Invariant Keypoints</em>. 2004. https://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf&#160;<a class="footnote-backref" href="#fnref:sift" title="Jump back to footnote 17 in the text">&#8617;</a></p>
</li>
<li id="fn:pyisgurus">
<p>Rosebrock, A. <em>PyImageSearch Gurus Course: 8.5.1 A CNN Primer</em>. https://www.pyimagesearch.com/pyimagesearch-gurus-course/&#160;<a class="footnote-backref" href="#fnref:pyisgurus" title="Jump back to footnote 18 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:pyisgurus" title="Jump back to footnote 18 in the text">&#8617;</a></p>
</li>
</ol>
</div>







  
  






                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2026 <a href="https://www.kamk.fi">Kajaanin Ammattikorkeakoulu Oy</a>. 
Licenced under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">BY-NC-SA 4.0</a>
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../..", "features": ["content.code.copy", "content.code.annotate", "content.tabs.link"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Kopioitu leikep\u00f6yd\u00e4lle", "clipboard.copy": "Kopioi leikep\u00f6yd\u00e4lle", "search.result.more.one": "1 lis\u00e4\u00e4 t\u00e4ll\u00e4 sivulla", "search.result.more.other": "# lis\u00e4\u00e4 t\u00e4ll\u00e4 sivulla", "search.result.none": "Ei t\u00e4sm\u00e4\u00e4vi\u00e4 dokumentteja", "search.result.one": "1 t\u00e4sm\u00e4\u00e4v\u00e4 dokumentti", "search.result.other": "# t\u00e4sm\u00e4\u00e4v\u00e4\u00e4 dokumenttia", "search.result.placeholder": "Kirjoita aloittaaksesi haun", "search.result.term.missing": "Puuttuu", "select.version": "Valitse versio"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
        <script src="../../javascripts/mathjax.js"></script>
      
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>