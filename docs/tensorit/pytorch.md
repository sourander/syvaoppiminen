---
priority: 210
---

# PyTorch

## AI-sovelluskehysten lyhyt historia

Modernien syv√§oppimiskehysten historia koostuu nopeasta innovaatiosta ja suurten teknologiayritysten sek√§ avoimen l√§hdekoodin yhteis√∂n kehittyvist√§ suhteista.

![](../images/210_framework_timeline.png)

**Kuva 1:** *Syv√§oppimiskehysten aikajana. Kuvaaja on koostettu alla olevan tekstin l√§hteiden pohjalta ja Githubin release-historiasta. Toisiinsa liittyv√§t kirjastot on yhdistetty v√§reill√§: esimerkiksi JAX on sininen, kuten my√∂s sen kirjastot Flax ja Rlax. Torch7 kattaa kaikki versiot alkuper√§isest√§ Torchista alkaen.*


### Varhainen perusta (2009-2014)

Matka alkaa Theanosta, joka kehitettiin noin vuonna 2009 ‚Äì tai ehk√§ olisi mainittava, ett√§ Nvidian CUDA syntyi 2006. Ennen t√§t√§ neuroverkot kirjoitettiin k√§sin esimerkiksi C++:lla. Fran√ßois Chollet kuvailee Theanoa: *"the conceptual ancestor of all modern deep learning tools"*. Theano oli ensimm√§inen kehys, joka mahdollisti automaattisen differentioinnin ja GPU-laskennan syv√§oppimismallien kouluttamiseen. Se sai merkitt√§v√§√§ jalansijaa vuosina 2013‚Äì2014, kun ImageNet 2012 -kilpailu her√§tti laajan kiinnostuksen syv√§oppimiseen. [^dlwithpython]

N√§ihin aikoihin my√∂s Lua-pohjainen Torch 7 ja C++-pohjainen Caffe olivat kovaa huutoa. Kyseist√§ kirjastoa ei ole p√§ivitetty sitten 2017, jolloin versio 1.0 julkaistiin [^dlwithpython]. Caffe:ta hy√∂dynsi esimerkiksi [bat-country](https://github.com/jrosebr1/bat-country) kirjastossa, joka on Deep Dream -tyylinen kuvageneraattori. Kirjastolla voi generoida unenomaisia kuvia tavallisten valokuvien pohjalta. Milt√§ n√§ytt√§√§ *Pelkoa ja Inhoa Las Vegasissa*‚Äìelokuva, jos katsoja n√§kee silmi√§ ja kasvoja siell√§kin, miss√§ niit√§ ei ole? K√§y toki katsomassa repositoriosta esimerkkej√§! Caffe2 julkaistiin Facebookin toimesta vuonna 2017, mutta se yhdistettiin my√∂hemmin PyTorchiin [^pytorchhistory]. 

### Keras: Korkean tason pioneeri (2015)

Keras lanseerattiin maaliskuussa 2015 uudenlaisena l√§hestymistapana syv√§oppimiseen. Se oli Fran√ßois Cholletin ‚Äì eli l√§hteiss√§ olevan kirjan *Deep Learning with Python (3rd ed.)* toisen kirjoittajan ‚Äì kehitt√§m√§. Kuten *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 3rd Edition* -kirjassa kerrotaan, Chollet kehitti alkuper√§isen Keras-kirjaston osana tutkimusprojektia, ja se *"quickly gained popularity, owing to its ease of use, flexibility, and beautiful design"*. [^geron3rd]

Alun perin Keras suunniteltiin korkean tason rajapinnaksi Theanon p√§√§lle, ja se oli suunnattu niille muutamalle tuhannelle ihmiselle, jotka tuolloin ty√∂skenteliv√§t syv√§oppimisen parissa. Filosofia oli yksinkertainen: tehd√§ syv√§oppimisesta saavutettavaa intuitiivisen ja k√§ytt√§j√§yst√§v√§llisen API:n avulla. [^dlwithpython] Kerasin kilpailijaina toimi tuolloin Lasagne, joka oli my√∂s Theano-pohjainen korkean tason kirjasto [^dlwithpytorch].

### TensorFlow:n l√§pimurto

Googlen julkaisema TensorFlow, 2015, oli k√§√§nteentekev√§ hetki, joka toi syv√§oppimisen valtavirran kehitt√§jien tietoisuuteen. Chollet ja Watson kuvailevat, ett√§ julkaisu oli: *"watershed moment that precipitated deep learning in the mainstream developer zeitgeist"*. TensorFlow otti keskeisi√§ ideoita Theanosta ja lis√§si kriittisen tuen laajamittaiselle hajautetulle laskennalle. Vuoden 2016 puoliv√§liin menness√§ puolet TensorFlow-k√§ytt√§jist√§ k√§yttiv√§t sit√§ nimenomaan Kerasin avulla. [^dlwithpython]

### PyTorch astuu n√§ytt√§m√∂lle (2016)

Meta (silloinen Facebook) julkaisi PyTorchin syyskuussa 2016 suorana vastauksena TensorFlow'n menestykselle [^geronpytorch]. PyTorch peri ohjelmointityylins√§ Chainer-kehykselt√§ ja torch-autogradilta. Jos PyTorchin suunnittelun tausta kiinnostaa, suosittelen tutustumaan [PyTorch's design origins](https://soumith.ch/blog/2023-12-17-pytorch-design-origins.md.html)-kirjoitukseen. Sen on kirjoittanut Soumith Chintala, PyTorchin co-founder ja Torch 7:n p√§√§kehitt√§j√§.

> "In contrast, PyTorch was designed from the ground up to provide a more flexible, Pythonic approach to building neural networks". [^geronpytorch]

### Suuri integraatio: Keras osaksi TensorFlow'ta (2017-2019)

Suuri muutos tapahtui, kun Google integroi Kerasin TensorFlow'n korkean tason rajapinnaksi. Keras valittiin virallisesti suositelluksi korkean tason rajapinnaksi, kun TensorFlow 2 julkaistiin. [^geron3rd]

Ennen t√§t√§ Keras ja TF tulivat toki jo toimeen kesken√§√§n. Tensorflow 1.1.0 julkaisun my√∂t√§ (elo 2018) Keras ladattiin `tf.keras`-moduulina, mutta se piti yh√§ asentaa erikseen. Jo vuonna 2019 Adrian Rosebrock totesi blogissaan: *"As you can tell, the history between Keras and TensorFlow is long, complicated, and intertwined"*. [^keras-vs-tf-keras]

TensorFlow 2.0:n julkaisuun menness√§ vuonna 2019 integraatio oli valmis. Aur√©lien G√©ron toteaa:

> "Installing TensorFlow will automatically install Keras as well, and Keras will not work without TensorFlow installed. In short, Keras and TensorFlow fell in love and got married". [^geron3rd]

Alunperin Keras tuki useita taustaj√§rjestelmi√§ (PlaidML, Theano, Microsoft Cognitive Toolkit), mutta versiosta 2.4 alkaen vain TensorFlow oli tuettu. [^geron3rd] T√§ll√∂in, 2020, min√§kin olin yh√§ aktiivinen Kerasin ja Tensorflow:n k√§ytt√§j√§. PyTorchin suosio oli kasvussa, mutta en l√∂yt√§nyt aikaa kokeilla sit√§.

### Keras itsen√§istyy j√§lleen

Viimeisin kehitys edustaa paluuta Kerasin monen taustaj√§rjestelm√§n juurille. Kuten *Machine Learning ‚Äì Modern Computer Vision & Generative AI* -kirjassa kuvataan:

> "Keras will support multiple backends including TensorFlow, JAX, and PyTorch. This is much like the original iteration of Keras which supported the backends which were popular at the time".

T√§m√§ kehitys tarkoittaa, ett√§ Keras on kulkenut t√§yden ympyr√§n ‚Äì monen taustaj√§rjestelm√§n kirjastosta osaksi TensorFlow'ta ja nyt takaisin tukemaan useita kehyksi√§, mukaan lukien PyTorch, JAX ja TensorFlow.

### Nykytilanne (2024-)

Keras on itsen√§inen ja vapaa, taas. Watson ja Chollet tiivist√§v√§t, ett√§ Python on voittanut kielikilvan seuraavaksi 15 vuodeksi. V√§hint√§√§n nykyiset nelj√§ kehyst√§ (ks. lainaus alta) tulevat pysym√§√§n relevantteina ‚Äì joskin uusia voi l√∂yty√§, kuten Applen MLX. [^dlwithpython]

> "Today, Keras, TensorFlow, PyTorch, and JAX are the top frameworks in the deep learning world." [^dlwithpython]

T√§st√§ nelikosta Keras on ainut, joka ei ole t√§ysin itsen√§inen kehys. Se on korkean tason rajapinta, joka k√§ytt√§√§ taustaj√§rjestelm√§n√§ TensorFlow'ta, PyTorchia tai JAX:ia. Sill√§ voi siis kirjoittaa helppolukuista koodia, jossa on k√§yt√∂ss√§ esim. Layerit n√§in: `dense = layers.Dense(64, activation="relu")`, mutta taustalla voi olla mik√§ tahansa tuettu kehys. N√§it√§ taustakehyksi√§ yhdist√§√§ se, ett√§ ne kaikki toteuttavat samankaltaisia matalamman tason toiminnallisuuksia, kuten tensoreita, automaattista differentiointia, GPU-kiihdytyst√§ ja vastavirtausta (backpropagation).

Voi hyvin olla, ett√§ jos k√§visit t√§m√§n kurssin vuoden p√§√§st√§, me k√§ytt√§isimme Kerasia ja vuorottellisimme backendien suhteen. T√§ll√§ hetkell√§ t√§m√§ kurssi on kuitenkin vahvasti PyTorch-painotteinen. Saat toki kurssin aikana kokeilla kirjoittaa jonkin teht√§v√§n Keras edell√§. Kenties haluat my√∂s kokeilla, miten jokin alkup√§√§n low level -teht√§v√§ onnistuisi TensorFlow:n tai JAX:n avulla. Jos kysyt kielimallilta, se kyll√§ k√§√§nt√§√§ (ainakin yksinkertaisen) koodin kehyksest√§ toiseen. Miksi vuorottelisimme? Kuten Watson ja Chollet kirjoittavat [^dlwithpython], PyTorch on kiva debugata ja sill√§ on erityisesti Hugging Facen ajamana loistava ekosysteemi, mutta se h√§vi√§√§ suorituskyvyss√§ kilpailijoille. JAX on suorituskyvylt√§√§n erinomainen, mutta sen ekosysteemi on viel√§ pieni. TensorFlow on suorituskyvylt√§√§n hyv√§ ja sill√§ on hyv√§t tuotantoon soveltuvat ty√∂kalut. Keras tarjoaa helppok√§ytt√∂isen API:n, mutta se ei ole itsen√§inen kehys. Jokaisella on siis omat vahvuutensa ja heikkoutensa. Erikoistunut rauta, kuten TPU:t, saattavat my√∂s vaikuttaa valintaan.

![](../images/210-star-history-tf-jax-pytorch.png)

**Kuva 2:** *TensorFlow, PyTorch ja JAX:n GitHub-t√§htien kehitys. Kuva kaapattu joulukuussa 2025. Jos haluat n√§hd√§ ajantasaisen version, k√§y [Star History Chart](https://www.star-history.com/#jax-ml/jax&pytorch/pytorch&tensorflow/tensorflow&keras-team/keras&type=date&legend=top-left)-sivulla.*


## Teht√§v√§t

!!! tip "Muokkaa ja kokeile vapaasti!"

    Ennen teht√§vien alustamista haluan v√§liss√§ haluan huomauttaa, ett√§ **on t√§ysin sallittua** muokata olemassaolevia Notebookeja ja/tai luoda omia Marimo-kirjoja, joissa kokeilet PyTorchin toiminnallisuuksia.

    **Ole rohkea!** Kokeile, tutki ja muokkaa. Riko ja korjaa.
    
    Dokumentoi l√∂yd√∂ksesi oppimisp√§iv√§kirjaan.

!!! question "Teht√§v√§: From NumPy to PyTorch (PyTorchNN)"

    Avaa `210_numpy_to_pytorch.py`-tiedosto ja tutustu `PyTorchNN`-malliin. Malli on sama 2-2-1 kun aiempi `NumpyNNwithBCE`-malli, mutta toteutettu PyTorchilla. 
    
    Aja koodi ja tutki mit√§ tapahtuu. Varmista, ett√§ ymm√§rr√§t, kuinka mik√§kin rivi koodia liittyy t√§h√§n menness√§ kurssilla opittuun.

    Keskity erityisesti PyTorch-kirjaston tensori- ja mallitoiminnallisuuksiin, joita Marimo-notebookissa k√§ytet√§√§n.

!!! question "Teht√§v√§: PyTorch Learn the Basics: Tensors"

    Avaa `211_pytorch_tensors.py`. Huomaa, ett√§ kyseess√§ on PyTorchin virallinen [Learn The Basics: Tensors](https://docs.pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html) -opas, joka on k√§√§nnetty Marimo-muotoon. 
    
    Jos k√§yt√§t Google Colabia, voit avata alkuper√§isen ohjeen.

!!! question "Teht√§v√§: PyTorch Introduction to Pytorch Tensors"

    Avaa `212_tensors.py`. Huomaa, ett√§ kyseess√§ on PyTorchin virallinen [Introduction to PyTorch - YouTube Series: Introduction to PyTorch Tensors](https://docs.pytorch.org/tutorials/beginner/introyt/tensors_deeper_tutorial.html) -opas, joka on k√§√§nnetty Marimo-muotoon.

    My√∂s t√§ss√§ voit k√§yt√§t√§ Google Colabia alkuper√§isen ohjeen avaamiseen tai noudattaa kurssin Marimo-versiota.


!!! question "Teht√§v√§: Auto MPG"

    Avaa `213_auto_mpg.py`. Notebookissa on matalan kynnyksen k√§ytt√∂√∂notto PyTorch-mallille. Data on loppumetreille asti aiemmin tutussa Pandas DataFramessa. Seuraavilla viikoilla tutustumme paremmin esimerkiksi Dataset ja DataLoader -toiminnallisuuksiin. Keskityt√§√§n toistaiseksi mallin kouluttamiseen ja tulosten validointiin yksinkertaisella MAE-metriikalla.
    
!!! question "Teht√§v√§: Kyberviha PyTorch-mallilla"

    Johdatus Koneoppimiseen -kurssin logistisen regression teht√§v√§n√§ oli tunnistaa, onko henkil√∂ kokenut kybervihaa viimeisen vuoden aikana.

    Alkuper√§inen datasetti l√∂ytyy Data in Brief [Digital skills among youth: A dataset from a three-wave longitudinal survey in six European countries](https://www.sciencedirect.com/science/article/pii/S2352340924003652)-data-artikkelista. K√§yt√§mme kuitenkin vertailun vuoksi edelliselt√§ kurssilta tuttua, esik√§sitelty√§ datasetti√§. Se on ladattavissa [hf:sourander/yskills](https://huggingface.co/datasets/sourander/yskills)-reposta.

    Muistanet, ett√§ tulos oli kohtalaisen heikko. T√§m√§n harjoituksen motiviina on tutkia, ovatko neuroverkot hopealuoti, joka parantaa tuloksia merkitt√§v√§sti ‚Äì ==vai k√§yk√∂ kenties niin==, ett√§ joudut taistella hyperparametrien kanssa saadaksesi edes jossain m√§√§rin vertailukelpoisen tuloksen.

    Teht√§v√§√§n l√∂ytyy `214_cyberhate.py` -notebook, jota voit k√§ytt√§√§ pohjana. Vaihtoehtoisesti voit kirjoittaa koodin alusta asti itse. T√§rkeint√§ on, ett√§ dokumentoit oppimisp√§iv√§kirjaasi, mit√§ teit ja mit√§ opit.

    !!! warning

        √Ñl√§ sukella liian syv√§lle hyperparametrien viritt√§miseen. T√§ss√§ voisi k√§ytt√§√§ uskomattoman m√§√§r√§n aikaa. Jos vibe-koodaat ratkaisua, joka alkaa sis√§lt√§√§ termej√§ kuten Dropout, Early Stopping, Optuna, kannattaa huomioida, ett√§ n√§m√§ tulevat tutuksi kurssin Mallinnus-osiossa my√∂hemmin.

!!! question "Teht√§v√§: ONXX JAX:ia n√§kynyt?"

    Yll√§ olevasta historiasta puuttuu ONXX tyystin ja Jax on vain sivuhuomio. Tutustu Jaxiin ja ONNX:√§√§n itsen√§isesti ja kirjoita lyhyt yhteenveto oppimisp√§iv√§kirjaasi. ONXX:iin tutustutaan kenties tarkemmin my√∂hemmin kurssilla ‚Äì ehk√§p√§ vaikka Syv√§oppiminen II:ssa.

    On √§√§rimm√§isen suositeltavaa lis√§ksi k√§ytt√§√§ Google Trendsi√§ ja vertailla, miten Worldwide-tasolla kehykset PyTorch, TensorFlow, Keras ja JAX ovat kehittyneet viimeisen viiden vuoden aikana. Huomaa, ett√§ t√§ss√§ on kuitenkin kyse vain hakuhistoriasta. Se ei v√§ltt√§m√§tt√§ suoraan heijasta todellista k√§ytt√∂√§ tuotantoymp√§rist√∂iss√§ tai tutkimuksessa.

    üí™ Jos oikein rohkea olet, ota JAX lyhyelle Hello World -tason koeajolle.

## L√§hteet

[^dlwithpython]: Watson, M & Chollet, F. *Deep Learning with Python, Third Edition*. Manning. 2025.
[^pytorchhistory]: TensorGym. *The Complete History and Evolution of PyTorch | Deep Learning Framework Timeline*. n.d. https://tensorgym.com/blog/pytorch-history
[^geron3rd]: G√©ron, A. *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 3rd Edition*. O'Reilly. 2022.
[^dlwithpytorch]: Stevens, E, Antiga, L & Viehmann, T. *Deep Learning with PyTorch*. Manning. 2020.
[^geronpytorch]: G√©ron, A. *Hands-On Machine Learning with Scikit-Learn and PyTorch*. O'Reilly. 2025.
[^keras-vs-tf-keras]: Rosebrock, J. *Keras vs. tf.keras: What‚Äôs the difference in TensorFlow 2.0?* PyImageSearch Blog. https://pyimagesearch.com/2019/10/21/keras-vs-tf-keras-whats-the-difference-in-tensorflow-2-0/
