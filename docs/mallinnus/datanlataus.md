---
priority: 410
---

# Datan lataus

## IDEAS

*  üöß Tarkista luku 10 (Implementing Mini-Batch Gradient Descent Using DataLoaders) kirjasta Hands-On Machine Laerning with Scikit-Learn and PyTorch.

## Datan lataus PyTorchissa

PyTorch tarjoaa `torch.utils.data`-moduulissa kaksi luokkaa, jotka helpottavat datan k√§sittely√§: `Dataset` ja `DataLoader`. Lis√§ksi l√∂ytyy esimerkiksi `TensorDataset`-luokka, josta voi olla apua harjoitellessa.

* **Dataset** on luokka, joka k√§√§rii sis√§√§ns√§ datan ja labelit.
* **DataLoader** on luokka, joka k√§√§riin yll√§ olevan iteraoitavaksi objektiksi.

### TensorDataset

K√§yt√§nn√∂ss√§ voimme siis k√§ytt√§√§ mit√§ tahansa tensoreita ja k√§√§ri√§ ne datasetiksi, n√§in:

```python
# 5 samples with 3 features each
X = torch.tensor([
    [1.0, 2.0, 3.0],
    [4.0, 5.0, 6.0],
    [7.0, 8.0, 9.0],
    [1.5, 2.5, 3.5],
    [4.5, 5.5, 6.5]
])

# Binary labels
y = torch.tensor([0, 1, 1, 0, 1])

# Dataset
dataset = TensorDataset(X, y)
```

Nyt voimme kaivaa datasetist√§ yksitt√§isi√§ n√§ytteit√§:

```python
data, label = dataset[0]
# tensor([1.0, 2.0, 3.0])
# tensor(0)
```

### Tee-se-itse

Yksinkertaisimmillaan `Dataset`-luokan tarvitsee toteuttaa kaksi metodia: `__len__` ja `__getitem__`, joista tosin ensimm√§inen on *optional*. Jos alaviivoilla ymp√§r√∂idyt funktiot ovat sinulle vieraita, niin ne ovat Pythonin erikoismetodeja, jotka vastaavat, kun objektia kutsutaan `len(dataset)`-funktiolla tai objektia yritet√§√§n viipaloida (*engl. slice*) hakasulkeilla `dataset[idx]` tai `dataset[start:stop]`.

```python
class CustomDataset(Dataset):
    def __init__(self):
        self.data = data
        self.labels = labels

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return self.data[idx], self.labels[idx]
```

Luonnollisesti voit tehd√§ datasetist√§ aivan mit√§ tahansa. Vain ohjelmointitaitosi ovat rajana. Voit toteuttaa esimerkiksi: 

* Etsi labelit indeksitiedostosta (`data/labels.txt`)
* Lue kuvat kovalevylt√§ (`data/train.parquet`, ...)
    * Tai kenties lataa S3:sta (jos `download=True`)
    * Tai varoita jos tuoreempi data on saatavilla verkosta
* Esik√§sittele dataa lennossa (jos `transform`-parametri on m√§√§ritelty)
* Palauta vain jokin tietty versio/subset datasta (esim. `train==True`)
* Parametri `obj.classes` sis√§lt√§en ihmisluettavat luokat
* Parametri `obj.class_to_idx` m√§√§rittelee, mik√§ luokka vastaa mit√§kin indeksi√§


### Jako koulutus- ja testidatasettiin

Yleinen k√§yt√§nt√∂ on jakaa data koulutus- ja testidatasettiin. T√§m√§ onnistuu helposti `torch.utils.data.random_split`-funktiolla [^mlforcoders]:

```python
from torch.utils.data import random_split
 
ds = CustomDataset(...)

total_count = len(ds)
train_count = int(0.7 * total_count)
val_count = int(0.15 * total_count)
 
# Varmistetaan ett√§ kaikki n√§ytteet tulevat k√§ytt√∂√∂n
# eli loput 15 %
test_count = total_count - train_count - val_count  
 
train_ds, val_ds, test_ds = 
     random_split(ds, [train_count, val_count, test_count])
```


### DataLoader

DataLoader on vain wrapper Datasetin ymp√§rille, joten jatketaan yll√§ luodun `CustomDataset`-esimerkin parissa. Huomaa, ett√§ DataLoader ei toteuta `__getitem__`-metodia, vaan ainoastaan `__iter__`-metodin, joka palauttaa iteraattorin. Et voi siis hakea yksitt√§ist√§ n√§ytett√§ `mydataloader[0]`, vaan sinun tulee iteroida datan l√§pi esimerkiksi `for`-silmukassa tai `next()`-funktiolla.

```python
# Alustetaan aiemmin luodun datasetin pohjalta DataLoader
dataloader = DataLoader(dataset, batch_size=2, shuffle=False)

# Loopataan ja tulostetaan datan√§ytteet
for data, label in dataloader:
    print(data.shape)
    print(label.shape)
    print()
```

```console title="Output"
torch.Size([2, 3])
torch.Size([2])

torch.Size([2, 3])
torch.Size([2])

torch.Size([1, 3])
torch.Size([1])
```

## Data ja PyTorch Vision

My√∂s TorchVision, joka on PyTorchin virallinen lis√§kirjasto kuvank√§sittelyyn, tarjoaa ty√∂kaluja datan lataukseen. Oletkin jo k√§ytt√§nyt `torchvision.datasets.MNIST`-datasetti√§ aiemmissa harjoituksissa. N√§iden lis√§ksi TorchVision tarjoaa pohjaluokkia (ks. [Base classes for custom datasets](https://docs.pytorch.org/vision/main/datasets.html#base-classes-for-custom-datasets)), jotka ovat: `DatasetFolder` ja `ImageFolder` ja `VisionDataset`. 

### VisionDataset

VisionDataset on Datasetin kaltainen pohjaluokka, joka tarjoaa lis√§toiminnallisuutta kuvadatasetin k√§sittelyyn. N√§ist√§ n√§kyvimm√§t ovat:

* `root`: Datasetin juurihakemisto (k√§ytet√§√§n tulostukseen)
* `transforms`: kutsuttava funktio, joka ottaa vastaan kuvat ja labelit ja palauttaa muokatun version niist√§
* `transform`: kutsuttava funktio, joka ottaa vastaan vain kuvan ja palauttaa muokatun version siit√§

Oletkin jo k√§ytt√§nyt `transforms`-ominaisuutta aiemmin:

```python
# 110_first_model.py
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,))  # MNIST mean and std
])
```

Itse luokan k√§ytt√∂ hoituu samalla tavalla kuin aiemmin esitellyn `CustomDataset`-esimerkin kanssa. Eli `class MyVisionDataset(VisionDataset):` ja toteutat `__len__` ja `__getitem__`-metodit.

### ImageFolder

ImageFolder on VisionDatasetin aliluokka, joka olettaa datan olevan j√§rjestettyn√§ hakemistoihin siten, ett√§ jokainen alihakemisto vastaa yht√§ luokkaa ==aakkosellisessa j√§rjestyksess√§==. T√§m√§ tekee kuvien lataamisesta helppoa, jos ne on j√§rjestetty valmiiksi oikeisiin hakemistoihin. Esimerkiksi:

```
data/
    aasiankultakissa/
        001.png
        002.png
        ...
    aavikkoilves/
        001.png
        ...
    ...
    zorilla/
        123.png
        ...
```

Saisit n√§m√§ ladattua suoraan datasetiksi n√§in:

```python
from torchvision.datasets import ImageFolder

dataset = ImageFolder(root='data/')
```

Moroney vihjaa kirjassa AI and ML for Coders in PyTorch [^mlforcoders], ett√§ aakkosj√§rjestyksen tuomilta ongelmilta voi v√§ltty√§ k√§ytt√§m√§ll√§ `target_transform`-parametria, jolla voi m√§√§ritell√§ oman funktionsa labelien muokkaamiseen. Esimerkiksi:

```python
# Mik√§ tahansa luokitusj√§rjestys
custom_class_to_idx = {
    'aasiankultakissa': 42, 
    'aavikkoilves': 3, 
    ...,
    'zorilla': 1024
}

# Luodaan dataset, jonka target_transform on lambda-funktio
dataset = ImageFolder(
  root='data/',
  target_transform=
    lambda x: custom_class_to_idx[dataset.classes[x]]
)

# Ylikirjoitetaan class_to_idx
dataset.class_to_idx = custom_class_to_idx
print(dataset.class_to_idx)
```

## Muut keinot datan lataukseen

### Keras 3 ja PyTorch-backend

Kuten [PyTorch-luvussa](../tensorit/pytorch.md) mainittiin, Keras 3 tukee j√§lleen useita taustaj√§rjestelmi√§ ‚Äì mukaan lukien PyTorchia. T√§m√§ tarkoittaa, ett√§ voit k√§ytt√§√§ Kerasin tuttuja datasettej√§ ja datan k√§sittelyty√∂kaluja, vaikka malli py√∂risikin PyTorch-backendilla. Emme k√§yt√§ t√§ss√§ toteutuksessa Kerasia, mutta j√§tet√§√§n kuitenkin maininnan tasolle, ett√§ saatat t√∂rm√§t√§ t√§m√§n sortin snippetteihin:

```python
train_ds, val_ds = keras.utils.image_dataset_from_directory(
    "PetImages",
    validation_split=0.2,
    subset="both",
    seed=1337,
    image_size=image_size,
    batch_size=batch_size,
)
``` 

### Hugging Face Datasets

T√§h√§n oletkin jo t√∂rm√§nnyt `214_cyberhate.py`-tiedostossa. Hugging Facesta voi ladata Datasets-repoista dataa joko `huggingface-hub` tai `datasets`-kirjastolla. Hub-kirjasto on tarkoitettu my√∂s muiden kuin datasettien noutamiseen: sill√§ voi etsi√§ Hugging Facesta esimerkiksi valmiiksi koulutettuja malleja.

L√∂yd√§t n√§iden dokumentaation online: [Datasets](https://huggingface.co/docs/datasets/en/index), [huggingface_hub](https://github.com/huggingface/huggingface_hub).

#### huggingface-hub

T√§m√§ on kyberviha-Notebookista tuttu:

```python
filepath = hf_hub_download(
    repo_id="sourander/yskills",
    repo_type="dataset",
    filename="ySKILLS_longitudinal_dataset_teacher_processed.csv",
)

df = pd.read_csv(filepath)
```

Ideaalitilanteessa CSV-tiedosto ladattaisiin jonkin oman PyTorch Datasets-toteutuksen avulla sis√§√§n. Tiedosto on kuitenkin niin pieni, ett√§ harjoituksessa se otettiin `train_test_split`:n j√§lkeen k√§ytt√∂√∂n `torch.FloatTensor(X_train).to(device)`-komennolla.

#### datasets

Yll√§ mainitulla ty√∂kalulla on n√§pp√§r√§ ladata yksitt√§inen tiedosto kerrallaan. Jos Hugging Face -repo on oikein j√§rjestetty, sielt√§ voi ladata kerralla train, test ja muutkin datasetit n√§in:

```python
from datasets import load_dataset
ds = load_dataset("username/repoid")
```

Esimerkiksi `sourander/yskills`-datasetti on j√§rjestetty siten, ett√§ erillist√§ train/test/validation jakoa ei ole tehty tiedostotasolla vaan koko datasetti on samassa CSV-tiedostossa. T√§ll√∂in `load_dataset` lataa koko datasetin `train`-avaimeen. Jos `datasets`-kirjaston kanssa haluaisi kuitenkin edet√§, voisi koodin n√§ytt√§√§ t√§lt√§:

```python
from datasets import load_dataset

# CSV:n sis√§lt√∂ l√∂ytyy "train"-avaimesta.
# T√§ss√§ datasetiss√§ ei ole test- tai validation-osioita.
ds = load_dataset("sourander/yskills").with_format("torch")

# Nyt on batch ja train
split_ds = ds["train"].train_test_split(test_size=0.3, seed=42)

# Siirret√§√§n ne eri loadereihin
trainloader = DataLoader(ds["train"], batch_size=32)
testloader = DataLoader(ds["train"], batch_size=32)

# Kaivetaan yksi batch ulos
for batch in trainloader:
    break
```

T√§ss√§ v√§liss√§ on hyv√§ huomauttaa, ett√§ jatkossa `len(batch) != 32`, koska Hugging Face -Datasets palauttaa sanakirjan, jossa on avaimina sarakkeiden nimet. Eli siis `batch.keys()` palauttaa sarakenimet. T√§m√§ vaatisi jotakuinkin seuraavanlaista k√§sittely√§ koulutusloopissa:

```python
for batch in dataloader:
    # Erotellaan piirteet ja labelit ja st√§k√§t√§√§n horisontaalisesti X:ksi
    feature_cols = [c for c in batch.keys() if c != "RISK101"]
    X = torch.stack([batch[col] for col in feature_cols], dim=1).float().to(device)
    y = batch["RISK101"].float().to(device)

    # Normaali forward pass
    outputs = model(X).squeeze(1)
```

T√§m√§ on hieman hankalampi tapa edet√§ kuin suora CSV:n lukeminen Pandasilla, mutta on hyv√§ tunnistaa eri vaihtoehdot. Eri tutoriaaleissa ja eri kirjastojen kanssa pelatessa saatat t√∂rm√§t√§ yll√§tt√§v√§√§n valikoimaan erilaisia tapoja datan lataukseen (ja muuhunkin).

## Teht√§v√§t

!!! question "Teht√§v√§: MNIST MLP Revisited"

    Muistat varmaan aiemman `110_first_model.py`-notebookin, jossa ajoit ensimm√§ist√§ kertaa yksinkertaista eteenp√§in kytkeytyv√§√§ neuroverkkoa MNIST-datasetill√§. Palaa t√§h√§n harjoitukseen ja tee seuraavat parannukset:

    ```python
    import os
    NUM_CPU = os.cpu_count()

    # Voit kokeilla, hy√∂tyyk√∂ GPU vaiko CPU enemm√§n:
    USE_GPU = True # or False

    # Lis√§√§ kumpaankin DataLoaderiin seuraavat keyword-argumentit:
    trainloader = DataLoader(..., persistent_workers=True, num_workers=NUM_CPU)
    testloader = DataLoader(..., persistent_workers=True, num_workers=NUM_CPU)
    ```

    Jos et ole kirjannut aiemmin koulutuksen kestoa yl√∂s, tee se nyt ennen muutoksia. T√§m√§n j√§lkeen tee yll√§ mainitut muutokset ja aja koulutus uudestaan. Kuinka paljon nopeutusta sait aikaan? Tutustu siihen, mit√§ `persistent_workers` ja `num_workers` tekev√§t ja miksi ne nopeuttavat datan latausta n√§inkin paljon.

!!! question "Teht√§v√§: CIFAR10 Datasetin pl√§r√§√§minen"

    Tutustu [CIFAR10](https://docs.pytorch.org/vision/main/generated/torchvision.datasets.CIFAR10.html) -datasettiin. Datasetti koostuu 60 000 ==v√§rikuvasta==. Kuvia on 6,000 kutakin luokkaa kohden eli luokkia on 10. Harjoittele seuraavia:

    * Lataa CIFAR10-datasetti PyTorchin `torchvision.datasets`-moduulista.
    * Tutki datan rakennetta (kuinka monta kuvaa, kuvan koko, v√§rit, luokat).
    * Visualisoi yksi kuva
    * Visualisoi useampi kuva ruudukossa (grid). 
        * Bonus: K√§ytt√§j√§ voi valita luokan.
    * Luo `DataLoader`, jolla voit iteroida datan l√§pi mini-batcheina.
        * Visualisoi yksi mini-batch ruudukossa.
  
    Voit k√§ytt√§√§ apuna `410_cifar10.py`-notebookia tai kirjoittaa koodin alusta itse.


!!! question "Teht√§v√§: CIFAR10 Malli"

    Kouluta my√∂s yksinkertainen eteenp√§in kytkeytyv√§ (feedforward) neuroverkko CIFAR10-datasetill√§. Tulemme my√∂hemmin vertaamaan t√§t√§ suoritusta konvoluutioverkkoon (CNN).

    Alta saat jo osviittaa, mihin lukemiin tulet p√§√§sem√§√§n ==seuraavissa luvuissa==. Nyt voit olla tyytyv√§inen, jos p√§√§set noin 50‚Äì60 % tarkkuuteen (accuracy). Mik√§ mahtaa olla baseline, jotta olet arpaa parempi?

    | Paper title                                                                | Error rate | Accuracy | Year |
    | -------------------------------------------------------------------------- | ---------- | -------- | ---- |
    | Convolutional Deep Belief Networks on CIFAR-10                             | 21.1 %     | 78.9%    | 2010 |
    | Maxout Networks                                                            | 9.38 %     | 90.62%   | 2013 |
    | Wide Residual Networks                                                     | 4.0 %      | 96.0%    | 2016 |
    | ...                                                                        | ...        | ...      | ...  |
    | An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale | 0.5 %      | 99.5%    | 2021 |

    Kannattaa tutkia my√∂s, kauan mallin koulutus kest√§√§. Data sek√§ malli ovat aiempaa suurempia. Opettajan valitsemalla arkkitehtuurilla saatiin 51 % testitarkkuus (joka ei juuri parantunut epookin nro 50 j√§lkeen). T√§ll√§ arkkitehtuurilla koulutus kesti, kun `persistent_workers=True` ja `num_workers=NUM_CPU` asetukset olivat paikoillaan:

    * CPU 100 epookkia: 10 min 5 s
    * GPU 100 epookkia: 8 min 38 s

    Taulukon l√§hde: [Wikipedia: CIFAR-10](https://en.wikipedia.org/wiki/CIFAR-10)

    Voit k√§ytt√§√§ apuna `411_cifar10.py`-notebookia tai kirjoittaa koodin alusta itse.

!!! question "Teht√§v√§: ImageFolderin k√§ytt√∂"

    K√§yt√§ ImageFolder-luokkaa ja `custom_class_to_idx`-sanakirjaa. T√§h√§n on valmis pohja, jossa tarvii muokata vain yht√§ solua. Katso `412_imagefolder.py`-notebook.

    Varmista, ett√§ ymm√§rr√§t, miss√§ tiedostot ovat fyysisesti levyll√§.

## L√§hteet

[^mlforcoders]: Moroney, L. *AI and ML for Coders in PyTorch*. O'Reilly. 2025.