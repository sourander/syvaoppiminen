{"config":{"lang":["fi"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Tervetuloa kurssille","text":"<p>Warning</p> <p>T\u00e4m\u00e4 sivusto on kokonaisuudessaan ty\u00f6n alla. Valmistuu kev\u00e4\u00e4ll\u00e4 2026.</p> <p>Tervetuloa kurssille! T\u00e4m\u00e4 kurssi on jatkoa Johdatus koneoppimiseen -kursille. Kurssilla syvennyt\u00e4\u00e4n koneoppimisen keskeiseen osa-alueeseen, syv\u00e4oppimiseen (deep learning). Aiheita k\u00e4yd\u00e4\u00e4n l\u00e4pi lyhyesti teoreettisesta n\u00e4k\u00f6kulmasta, mutta p\u00e4\u00e4paino on k\u00e4yt\u00e4nn\u00f6n toteutuksissa. Viralliset oppimistavoitteet l\u00f6yd\u00e4t OPS:sta, mutta p\u00e4\u00e4piirteitt\u00e4in kurssin j\u00e4lkeen:</p> <ul> <li>Osaat selitt\u00e4\u00e4 syv\u00e4oppimisen keskeiset k\u00e4sitteet 5-vuotiaalle.</li> <li>Olet kouluttanut esimerkkien mukaiset mallit.</li> <li>... joiden pohjalta olet luonut omia malleja.</li> <li>Olet luonut oppimisp\u00e4iv\u00e4kirjan, joka mahdollistaa kertauksen ja jatko-opiskelun.</li> </ul> <p>Tutustut kurssin aikana kirjoihin Understanding Machine Learning ja Hands-On Machine Learning with Scikit-Learn and PyTorch. Kurssin j\u00e4lkeen sinulla on valmiudet k\u00e4ytt\u00e4\u00e4 syv\u00e4oppimista projektikursseilla ja ty\u00f6el\u00e4m\u00e4ss\u00e4.</p>"},{"location":"#tehtavat","title":"Teht\u00e4v\u00e4t","text":"<p>Kurssi sis\u00e4lt\u00e4\u00e4 teht\u00e4vi\u00e4, jotka tukevat syv\u00e4oppimisen keskeisten k\u00e4sitteiden ja menetelmien ymm\u00e4rt\u00e4mist\u00e4. Teht\u00e4vien tarkoitus ei ole tuottaa yksitt\u00e4isi\u00e4 \u201coikeita vastauksia\u201d, vaan toimia l\u00e4ht\u00f6kohtana oppimiselle, kokeilulle ja reflektoinnille.</p> <p>Kurssin lopullinen palautus on oppimisp\u00e4iv\u00e4kirja, joka on yhten\u00e4inen, raporttimainen dokumentti. Oppimisp\u00e4iv\u00e4kirja ei ole teht\u00e4v\u00e4kohtainen loki, vaan kokonaisuus, jossa:</p> <ul> <li>yhdist\u00e4t kurssimateriaalin, kirjallisuuden ja teht\u00e4vien kautta syntyneet havainnot</li> <li>perustat esityksesi omaan ymm\u00e4rrykseesi, kokeiluihisi ja pohdintaasi</li> <li>k\u00e4yt\u00e4t teht\u00e4vi\u00e4 esimerkkein\u00e4, kokeiluina ja havaintojen l\u00e4hteen\u00e4</li> </ul> <p>Teht\u00e4viin ei odoteta kysymys\u2013vastaus-tyyppisi\u00e4 ratkaisuja oppimisp\u00e4iv\u00e4kirjassa. Sen sijaan odotetaan selitt\u00e4v\u00e4\u00e4, perustelevaa ja kokonaisuuksia yhdistelev\u00e4\u00e4 teksti\u00e4, hieman opinn\u00e4ytety\u00f6n tapaan, mutta kurssin laajuuteen sopivassa mittakaavassa.</p> <p>Teht\u00e4v\u00e4t l\u00f6ytyv\u00e4t kunkin osion lopusta. Lis\u00e4ksi kaikki teht\u00e4v\u00e4t ovat koostettuna Teht\u00e4v\u00e4kooste-sivulle. Teht\u00e4v\u00e4t palautetaan Oppimisp\u00e4iv\u00e4kirja 101 -ohjeistuksen mukaisesti eli Gitlab Pages:ssa hostattuna staattisena sivustona.</p> <p>Useat teht\u00e4v\u00e4t viittaavat Marimo-ty\u00f6kalulla tehtyihin notebookeihin. Kyseess\u00e4 on Jupyter Notebook -ty\u00f6kalun seuraaja. Notebookit l\u00f6yd\u00e4t kurssin repositoriosta polusta gh:sourander/syvaoppiminen/notebooks.</p>"},{"location":"#numerointi","title":"Numerointi","text":"<p>Kurssiaiheet ovat numeroitu sataluvuilla. Otetaan esimerkiksi kuvitteelliset luvut 1 ja 2:</p> <pre><code>1. El\u00e4inkunta:\n    (100:) Nis\u00e4kk\u00e4\u00e4t\n    (110:) Linnut\n2. Ohjelmointikielet:\n    (200:) Python\n    (210:) Rust\n</code></pre> <p>Aiheeseen El\u00e4inkunta liittyv\u00e4t aineistot tunnistat sataluvulla <code>1xx</code>, ja aiheeseen Ohjelmointikielet liittyv\u00e4t aineistot tunnistat satakymmenluvulla <code>2xx</code>. Esimerkiksi</p> <ul> <li><code>notebooks/nb/100/</code><ul> <li><code>100_marsu.py</code> </li> <li><code>101_leijona.py</code></li> <li><code>102_kissa.py</code></li> <li><code>110_varis.py</code> (seuraava kymppi eli linnut)</li> <li><code>111_kotka.py</code></li> </ul> </li> <li><code>notebooks/nb/200/</code><ul> <li><code>200_python_alkeet.py</code></li> <li><code>210_rust_alkeet.py</code> (seuraava kymppi eli Rust)</li> </ul> </li> </ul> <p>Sama p\u00e4tee esimerkiksi kurssin videoihin. Jos videon otsikossa on luku v\u00e4lill\u00e4 <code>100-199</code>, tied\u00e4t, ett\u00e4 se liittyy aiheeseen El\u00e4inkunta. Jos taas videon otsikossa on luku v\u00e4lill\u00e4 <code>200-299</code>, tied\u00e4t, ett\u00e4 se liittyy aiheeseen Ohjelmointikielet. Kymmenluvusta tunnistat tarkemman aiheen.</p>"},{"location":"#koodin-ajaminen","title":"Koodin ajaminen","text":"<p>Kurssilla ei pelk\u00e4st\u00e4\u00e4n katsella koodia vaan sit\u00e4 ajetaan my\u00f6s. Voit ajaa koodit seuraavilla tavoilla, j\u00e4rjestettyn\u00e4 suositelluimmasta v\u00e4hiten suositeltuun:</p> <ul> <li>Paikallisesti <code>uv</code>:lla</li> <li>Disco Coder -ymp\u00e4rist\u00f6ss\u00e4</li> <li>Jupyter Hubissa</li> <li>Google Colabissa</li> </ul> <p>Vaihtoehtoja esitell\u00e4\u00e4n kurssivideoilla ja tukisessioissa. Mik\u00e4li sinulla on oma n\u00e4yt\u00f6nohjain, on \u00e4\u00e4rimm\u00e4isen suositeltavaa opetella ajamaan koodia paikallisesti kyseist\u00e4 n\u00e4yt\u00f6nohjainta hy\u00f6dynt\u00e4en. AI-opiskelijalta t\u00e4m\u00e4 on jopa odotettavaa.</p> <p>Jupyter Hub ja Colab</p> <p>Jupyter Hub ei ymm\u00e4rr\u00e4 Marimo-notebookeja, joten ne t\u00e4ytyy ensin muuntaa Jupyter Notebook -muotoon. Sama p\u00e4tee ainakin kirjoitushetkell\u00e4 Colabiin. </p> <p>K\u00e4\u00e4nn\u00f6s onnistuu <code>marimo export ipynb notebook.py -o notebook.ipynb</code> -komennolla. Lue lis\u00e4\u00e4 Marimon Coming from Jupyter -ohjeesta.</p> <p>On suositeltavaa kuitenkin opetella Marimo-ty\u00f6kalun k\u00e4ytt\u00f6.</p>"},{"location":"exercises/","title":"Teht\u00e4v\u00e4kooste","text":"<p>T\u00e4ss\u00e4 tiedostossa on listattuna kaikki materiaalin teht\u00e4v\u00e4t. Osa niist\u00e4 ei v\u00e4ltt\u00e4m\u00e4tt\u00e4  kuulu sinun kurssitoteutukseesi. Huomaa, ett\u00e4 t\u00e4m\u00e4 tiedosto luodaan automaattisesti parsimalla  kaikki repositorion Markdown-tiedostot l\u00e4pi. Mik\u00e4li huomaat puuttuvia teht\u00e4vi\u00e4, ilmoita opettajalle. Otsikon per\u00e4ss\u00e4 suluissa oleva numero on j\u00e4rjestysprioriteetti: se vaikuttaa vain t\u00e4m\u00e4n listan j\u00e4rjestykseen.</p> <p>Lista hy\u00f6dynt\u00e4\u00e4 Material for MkDocs -teeman Tasklist -ominaisuutta.</p> <p>Kopioi teht\u00e4v\u00e4lista leikep\u00f6yd\u00e4lle ja muokkaa se sinun k\u00e4ytt\u00f6\u00f6si sopivaksi.</p> <pre><code>## Neuroverkot (100)\n\n- [ ] Teht\u00e4v\u00e4: TensorFlow Playground\n- [ ] Teht\u00e4v\u00e4: Quick, Draw!\n- [ ] Teht\u00e4v\u00e4: UDLbook Shallow\n- [ ] Teht\u00e4v\u00e4: ANN ja el\u00e4inkunta\n- [ ] Teht\u00e4v\u00e4: BERT Large\n\n## Syv\u00e4t neuroverkot (110)\n\n- [ ] Teht\u00e4v\u00e4: UDLbook Deep\n- [ ] Teht\u00e4v\u00e4: Valitse kehitysymp\u00e4rist\u00f6si\n- [ ] Teht\u00e4v\u00e4: Aja MNIST MLP koodi\n- [ ] Teht\u00e4v\u00e4: TensorBoard\n- [ ] Teht\u00e4v\u00e4: Mallin tarkkuus CPU vs MPS vs CUDA\n\n## Vektorointi (200)\n\n- [ ] Teht\u00e4v\u00e4: Tutustu vektorointiin\n- [ ] Teht\u00e4v\u00e4: NumPy Neural Network (NumpyNNwithBCE)\n\n## PyTorch (210)\n\n- [ ] Teht\u00e4v\u00e4: From NumPy to PyTorch (PyTorchNN)\n- [ ] Teht\u00e4v\u00e4: PyTorch Learn the Basics: Tensors\n- [ ] Teht\u00e4v\u00e4: PyTorch Introduction to Pytorch Tensors\n- [ ] Teht\u00e4v\u00e4: Auto MPG\n- [ ] Teht\u00e4v\u00e4: Kyberviha PyTorch-mallilla\n- [ ] Teht\u00e4v\u00e4: ONNX JAX:ia n\u00e4kynyt?\n\n## Vastavirta (Backprop) (300)\n\n- [ ] Teht\u00e4v\u00e4: Takaisinvirtaus intuition tasolla\n- [ ] Teht\u00e4v\u00e4: Lopusta vaiheittain alkuun\n- [ ] Teht\u00e4v\u00e4: PyTorch Learn the Basics: Automatic Differentiation with torch.autograd\n- [ ] Teht\u00e4v\u00e4: Ensin lokaalit ja sitten kertolasku\n- [ ] Teht\u00e4v\u00e4: Laskentaketju PyTorchissa\n\n## Yleiskatsaus (400)\n\n- [ ] Teht\u00e4v\u00e4: Mallinna Fashion MNIST\n- [ ] Teht\u00e4v\u00e4: Lataa Fashion MNIST -malli\n- [ ] Teht\u00e4v\u00e4: Tutustu aktivointifunktioihin\n\n## Datan lataus (410)\n\n- [ ] Teht\u00e4v\u00e4: MNIST MLP Revisited\n- [ ] Teht\u00e4v\u00e4: CIFAR10 Datasetin pl\u00e4r\u00e4\u00e4minen\n- [ ] Teht\u00e4v\u00e4: CIFAR10 Malli\n- [ ] Teht\u00e4v\u00e4: ImageFolderin k\u00e4ytt\u00f6\n\n## Kouluttamisen k\u00e4yt\u00e4nn\u00f6t (420)\n\n- [ ] Teht\u00e4v\u00e4: Kouluttamisen k\u00e4yt\u00e4nn\u00f6t\n- [ ] Teht\u00e4v\u00e4: Piirr\u00e4 multihead malli (Gaussian)\n\n## Konvoluutioverkot (500)\n\n- [ ] Teht\u00e4v\u00e4: Tutustuminen Fractional Max-Pooling -toteutukseen\n- [ ] Teht\u00e4v\u00e4: FMP ja MNIST\n- [ ] Teht\u00e4v\u00e4: LeNet ja MNIST\n- [ ] Teht\u00e4v\u00e4: (Valinnainen) HOG\n\n## Koulutetun mallin k\u00e4ytt\u00f6 (600)\n\n- [ ] Teht\u00e4v\u00e4: Luo Hugging Face tunnus\n- [ ] Teht\u00e4v\u00e4: Hugging Face Hello World\n- [ ] Teht\u00e4v\u00e4: Hate Speech over Naive Bayes\n- [ ] Teht\u00e4v\u00e4: MobileNetV3 k\u00e4ytt\u00f6\n\n## Siirtovaikutus (610)\n\n- [ ] Teht\u00e4v\u00e4: Dogs vs. Cats siirtovaikutus\n- [ ] Teht\u00e4v\u00e4: RPS-datasetin luonti webcamilla\n- [ ] Teht\u00e4v\u00e4: RPS ja Transfer Learning\n\n## Luonnollinen kieli (700)\n\n- [ ] Teht\u00e4v\u00e4: Embeddings\n- [ ] Teht\u00e4v\u00e4: SpaCY Playground\n- [ ] Teht\u00e4v\u00e4: Sanavektorien vertailu\n\n## RNN ja j\u00e4lkel\u00e4iset (710)\n\n- [ ] Teht\u00e4v\u00e4: RNN videoiden avulla\n- [ ] Teht\u00e4v\u00e4: Sukunimien luokittelu Pt.1\n- [ ] Teht\u00e4v\u00e4: Sukunimien luokittelu Pt.2\n- [ ] Teht\u00e4v\u00e4: Sukunimien generointi\n- [ ] Teht\u00e4v\u00e4: Konek\u00e4\u00e4nn\u00f6s (Seq2Seq + Attention)\n- [ ] Teht\u00e4v\u00e4: Kielimalli ja sanaulottuvuudet\n\n## Transformers (999)\n\n- [ ] Teht\u00e4v\u00e4: Perplexity\n- [ ] Teht\u00e4v\u00e4: ???\n</code></pre>"},{"location":"aikasarjat/ideat/","title":"Aikasarjat","text":"<p>T\u00e4m\u00e4 tullaan k\u00e4ym\u00e4\u00e4n l\u00e4pi l\u00e4hinn\u00e4 loppukaneettina kurssille.</p> <p>TODO! T\u00e4h\u00e4n tulee ainakin seuraavat asiat:</p> <ul> <li>Mit\u00e4 ovat aikasarjat (time series)</li> <li>Miten aikasarjoja mallinnetaan (esim. RNN, LSTM, GRU)</li> <li>Case: Aikasarjamallinnus jollain datalla</li> </ul> <p>Muista tsekata osio 4.4 kirjasta Deep Learning with PyTorch (Manning).</p>"},{"location":"kieli/nlp/","title":"Luonnollinen kieli","text":"<p>Tietojenk\u00e4sittelytieteiss\u00e4 luonnollisella kielell\u00e4 tarkoitetaan kieli\u00e4 kuten suomi, englanti, ranska tai japani, joita ihmiset k\u00e4ytt\u00e4v\u00e4t p\u00e4ivitt\u00e4isess\u00e4 viestinn\u00e4ss\u00e4\u00e4n. T\u00e4m\u00e4 on vastakohta keinotekoisille kielille, kuten ohjelmointikielille (esim. Python, Java) tai merkint\u00e4kielille (esim. HTML, XML). Merkitt\u00e4v\u00e4 ero n\u00e4iden v\u00e4lill\u00e4 on, ett\u00e4 koneelle tarkoitetut kielet ovat tehty insin\u00f6\u00f6rin\u00e4k\u00f6kulmasta siten, ett\u00e4 formaalit s\u00e4\u00e4nn\u00f6t ovat muodostettu ensin. Konekieli on k\u00e4ytt\u00f6kelpoinen vasta kun s\u00e4\u00e4nn\u00f6t ovat tarkoin m\u00e4\u00e4ritelty. Ihmisten k\u00e4ytt\u00e4m\u00e4t kielet ovat syntyneet p\u00e4invastoin: k\u00e4ytt\u00f6 ensin, s\u00e4\u00e4nn\u00f6t my\u00f6hemmin. <sup>1</sup></p> <p>\"As a result, while machine-readable language is highly structured and rigorous, natural language is messy\u2014ambiguous, chaotic, sprawling, and constantly in flux.\"</p> <p>\u2013 Fran\u00e7ois Chollet ja Matt Watson <sup>1</sup></p> <p>Termi ambiguous tarkoittaa, ett\u00e4 luonnollisessa kieless\u00e4 samalle asialle voi olla useita merkityksi\u00e4 tai tulkintoja. Suomalaisittain kuuluisa esimerkki t\u00e4st\u00e4 on lyhyt lause: \"Kuusi palaa\" (engl. the spruce is on fire / spruce returns / the number six is on fire / ... / six pieces). Ent\u00e4p\u00e4 kuinka tulkitaan seuraava uutisotsikko:</p> <p>\"Susi hy\u00f6k\u00adk\u00e4\u00adsi omis\u00adta\u00adjan\u00adsa kanssa py\u00f6\u00adr\u00e4\u00adlen\u00adkil\u00adl\u00e4 olleen koiran kimp\u00adpuun kes\u00adkel\u00adl\u00e4 asu\u00adtus\u00adta Raa\u00adhes\u00adsa\"</p> <p>\u2013 Pyh\u00e4jokiseutu 02.10.2024</p> <p></p> <p>Kuva 1: Kirjaimellisesti tulkittu otsikko: \"Susi hy\u00f6kk\u00e4si omistajansa kanssa py\u00f6r\u00e4lenkill\u00e4 olleen koiran kimppuun keskell\u00e4 asutusta Raahessa.\". Kuva luotu Gemini Nano Banana mallilla.</p> <p>Onko tilanne kenties ollut Kuvan 1 mukainen: susi ja h\u00e4nen omistajansa olivat hy\u00f6kk\u00e4\u00e4j\u00e4t, kun koiraraukka yritti py\u00f6r\u00e4ill\u00e4 karkuun? Vastaavia monitulkintaisia lauseita on Suomen Kuvalehden Jyv\u00e4t &amp; Akanat -palstalla viikoittain. T\u00e4ss\u00e4 kaksi tuoretta esimerkki\u00e4 lis\u00e4viihteen\u00e4 5/2026 numerosta: </p> <p>\"Nikotiinipussit muuttavat aivoja \u2013 kokenut l\u00e4\u00e4k\u00e4ri kertoo, miten p\u00e4\u00e4set niist\u00e4 pysyv\u00e4sti eroon\"</p> <p>\u2013 Iltasanomat 5.1.2026</p> <p>\"Varkaudessa anastettiin omaisuutta marraskuussa\"</p> <p>\u2013 Iltasanomat 7.1.2026</p> <p>T\u00e4ten lienee selv\u00e4, ett\u00e4 koneellinen kielen k\u00e4sittely haastavaa, mutta koska kieli on ihmisten p\u00e4\u00e4asiallinen viestint\u00e4v\u00e4line, on luonnollisen kielen k\u00e4sittely (Natural Language Processing, NLP) keskeinen osa tietojenk\u00e4sittely\u00e4 ja teko\u00e4ly\u00e4. K\u00e4yt\u00e4nn\u00f6n sovelluksia ovat esimerkiksi tekstin luokittelu (spam, no spam), konek\u00e4\u00e4nn\u00f6kset (ranska \u2192 suomi), hakukoneet ja tekstin generointi (\"Olipa kerran... ?\"). N\u00e4iden haastavien teht\u00e4vien suhteen suuret l\u00e4pimurrot ovat varsin tuoreita, mutta yrityst\u00e4 on kuitenkin ollut viimeisen yli 60 vuoden ajan. <sup>1</sup></p>"},{"location":"kieli/nlp/#historia","title":"Historia","text":"<p>Nykyisten chatbottien suuret merkkipaalut ovat syntyneet l\u00e4hitulevaisuudessa, mutta NLP:ll\u00e4 on pitk\u00e4 historia. Historia voidaan jakaa kolmeen p\u00e4\u00e4kauteen: s\u00e4\u00e4nn\u00f6pohjainen (rule-based), tilastollinen (statistical) ja syv\u00e4oppimiseen perustuva (deep learning-based) NLP \u2013 joka toki on my\u00f6s tilastollista.</p>"},{"location":"kieli/nlp/#turingin-koe","title":"Turingin koe","text":"<p>Kaiken luonnollisen kielen k\u00e4sittelyn p\u00e4\u00e4m\u00e4\u00e4r\u00e4 ei ole v\u00e4ltt\u00e4m\u00e4tt\u00e4 matkia ihmisen \u00e4lykkyytt\u00e4, mutta t\u00e4m\u00e4 ajatus on kulkenut matkassa alusta asti \u2013 aivan kuten muussakin teko\u00e4lyn historiassa. Alan Turing julkaisi 1950 paperin otsikolla \"Computing Machinery and Intelligence\", jossa h\u00e4n esitteli ajatuksen Turingin kokeesta nimell\u00e4 \"The Imitation Game\" <sup>2</sup>. Peli perustuu vanhaan seurapeliin, jolla salongissa on voinut viihdytt\u00e4\u00e4 vieraita: henkil\u00f6t A ja B istuvat erill\u00e4\u00e4n toisistaan, ja kolmas henkil\u00f6 C esitt\u00e4\u00e4 kysymyksi\u00e4 kummallekin. A ja B ovat mies ja nainen, ja henkil\u00f6n C teht\u00e4v\u00e4 on p\u00e4\u00e4tell\u00e4 kirjoitetun viestin perusteella, kumpi on kumpi. Turingin koe on sama asetelma, mutta A ja B ovat kone ja ihmminen. Jos C ei pysty luotettavasti erottamaan konetta ihmisest\u00e4, voidaan sanoa, ett\u00e4 kone on l\u00e4p\u00e4issyt Turingin kokeen. <sup>3</sup></p> <p>L\u00f6yd\u00e4t internetist\u00e4 helposti t\u00e4t\u00e4 koetta kritisoivaa sis\u00e4lt\u00f6\u00e4, ja my\u00f6s v\u00e4itteit\u00e4, ett\u00e4 eri mallit ovat l\u00e4p\u00e4isseet kokeen. Jos haluat tutustua aihepiiriin, kannattanee tutustua vuoden 2025 artikkeliin otsikolla Large Language Models Pass the Turing Test, jossa on vertailtu niin ELIZAa kuin tuoreita GPT-4.5-malleja. <sup>4</sup></p>"},{"location":"kieli/nlp/#eliza","title":"ELIZA","text":"<p>Tunnetuin varhaisista chatterbot-sovelluksista on ELIZA, erityisesti skripti DOCTOR, joka kehitettiin 1960-luvulla MIT:ss\u00e4. Sen loi Joseph Weizenbaum, ja se simuloitsi Carl Rogerin asiakaskeskeist\u00e4 psykoterapiaa. Ohjelma on nimetty fiktiivisen Eliza Doolittle hahmon mukaan, joka esiintyy George Bernard Shaw'n n\u00e4ytelm\u00e4ss\u00e4 \"Pygmalion\" (ja my\u00f6hemmin musikaalissa \"My Fair Lady\"). ELIZA k\u00e4ytti yksinkertaisia s\u00e4\u00e4nt\u00f6j\u00e4 ja avainsanojen tunnistusta vastatakseen k\u00e4ytt\u00e4j\u00e4n sy\u00f6tteisiin, luoden vaikutelman ymm\u00e4rryksest\u00e4. Kyseess\u00e4 on siis pattern-matching-j\u00e4rjestelm\u00e4. <sup>5</sup></p> <p>\"There are even accounts of ELIZA\u2019s responses being so human-like that it evoked emotional responses from people who forgot they were interacting with a computer, including Weizenbaum\u2019s own secretary. This led to much discussion about ELIZA\u2019s potential to pass the Turing Test, although there are no known accounts of ELIZA actually doing this.\"</p> <p>\u2013 Robert Barton ja Jerome Henry <sup>5</sup></p> <p>Kokeile!</p> <p>ELIZA:sta l\u00f6ytyy JavaScript-toteutuksia, mutta yksi n\u00e4pp\u00e4r\u00e4 tapa saada p\u00e4\u00e4sy siihen on APT-paketinhallinnasta l\u00f6ytyv\u00e4 PERL-toteutus. Sen saat k\u00e4ytt\u00f6\u00f6n n\u00e4in:</p> <ol> <li>Luo Dockerfile. Katso sis\u00e4lt\u00f6 alta.</li> <li>Aja <code>docker build -t eliza .</code></li> <li>Aja <code>docker run -it --rm eliza</code></li> </ol> Dockerfile <pre><code>FROM ubuntu:latest\n\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN apt-get update &amp;&amp; \\\n    apt-get install -y --no-install-recommends \\\n        perl \\\n        libchatbot-eliza-perl &amp;&amp; \\\n    rm -rf /var/lib/apt/lists/*\n\nWORKDIR /app\n\nRUN cat &gt; eliza.pl &lt;&lt; 'EOF'\n#!/usr/bin/perl\nuse strict;\nuse warnings;\nuse Chatbot::Eliza;\n\nmy $eliza = Chatbot::Eliza-&gt;new;\n\nprint \"Eliza: Hello. How can I help you today?\\n\";\n\nwhile (1) {\n    print \"You: \";\n    my $input = &lt;STDIN&gt;;\n    last unless defined $input;\n\n    my $response = $eliza-&gt;transform($input);\n    chomp $response;\n    print \"Eliza: $response\\n\";\n}\nEOF\n\nRUN chmod +x /app/eliza.pl\n\nENTRYPOINT [\"/app/eliza.pl\"]\n</code></pre> <p></p> <p>Kuva 2: ELIZA vastailee opettajan murheisiin.</p> <p>ELIZA her\u00e4tti yleis\u00f6n mielenkiinnon ja sen ymp\u00e4rille syntyi hype\u00e4. Weizenbaum p\u00e4\u00e4tyi itse taistelemaan t\u00e4t\u00e4 hype\u00e4 vastaan, aloittaen ik\u00e4\u00e4n kuin ristiretken omaa ohjelmaansa vastaan. ELIZA ei tiennyt mit\u00e4\u00e4n psykologiasta ja oli pikemminkin Carl Rogerin terapian karikatyyri tai parodia, joka l\u00e4hinn\u00e4 heijastaa kysymykset takaisin k\u00e4ytt\u00e4j\u00e4lle. <sup>6</sup></p>"},{"location":"kieli/nlp/#parry","title":"PARRY","text":"<p>Toinen varhainen chatbot on PARRY, joka kehitettiin 1970-luvulla psykiatri Kenneth Colbyn Stanfordissa. Applikaatio pyrki simuloimaan skitsofreniaa sairastavan potilaan puhetta. PARRY k\u00e4ytti monimutkaisempia s\u00e4\u00e4nt\u00f6j\u00e4 ja malleja kuin ELIZA, pyrkien j\u00e4ljittelem\u00e4\u00e4n skitsofrenian oireita, kuten vainoharhaisuutta ja ep\u00e4johdonmukaista ajattelua. <sup>5</sup> Ohjelman LISP-koodi on linkitettyn\u00e4 Wikipedia-artikkelissa ja l\u00f6ytyy Carnegie Mellonin arkistosta. Sen ajaminen modernilla koneella olisi haastellista, joten tyydyt\u00e4\u00e4n kurkkaamaan ELIZA:n (DOCTOR) ja PARRY:n keskustelua, joka on dokumentoitu vuonna 1972. Keskustelun alku muotoiltuna alla: <sup>7</sup></p> <p> DOCTOR: Good Evening. Tell me your problems.  Please terminate input with a period or a question mark.</p> <p> PARRY: People get on my nerves sometimes.</p> <p> DOCTOR: I am not sure I understand you fully.</p> <p> PARRY: You should pay more attention.</p> <p> DOCTOR: Suppose you should pay more attention.</p> <p> PARRY: You're entitled to your own opinion.</p> <p> DOCTOR: What makes you think I am entitled to my own opinion?</p>"},{"location":"kieli/nlp/#myohemmat-kehitysvaiheet","title":"My\u00f6hemm\u00e4t kehitysvaiheet","text":"Nimi Kehitt\u00e4j\u00e4 Vuosi Huomioitavaa ELIZA Joseph Weizenbaum 1966 Simuloi psykoterapeuttia PARRY Kenneth Colby 1972 Simuloi skitsofreenikkoa Jabberwacky Rollo Carpenter 1988 Online-julkaisu 1997 MS Word AutoCorrect Microsoft 1993 Yksinkertainen s\u00e4\u00e4nt\u00f6pohjainen ALICE Richard Wallace 1995 K\u00e4ytt\u00e4\u00e4 AIML-skriptauskielt\u00e4 MedSpeak IBM 1996 L\u00e4\u00e4ketieteellinen litterointi VAL BellSouth 1996 Puheentunnistus ja vastaus SmarterChild Robert Hoffer 2001 Agentti AOL ja Messengeriss\u00e4 Cleverbot Rollo Carpenter 2008 Jabberwackyn seuraaja Siri Adam Cheyer 2011 Assistentti Xiaoice Microsoft 2014 Empaattinen chatbot Alexa Amazon 2014 Assistentti Melody Andrew Ng 2015 L\u00e4\u00e4ketieteellinen assistentti <p>Taulukko on koostettu kirjoista Conversational Artificial Intelligence <sup>8</sup> ja The Invisible Brand: Marketing in the Age of Automation, Big Data, and Machine Learning. <sup>3</sup></p>"},{"location":"kieli/nlp/#asiantuntijajarjestelmat-expert-systems","title":"Asiantuntijaj\u00e4rjestelm\u00e4t (Expert Systems)","text":"<p>Heti alkuun suosittelen, ett\u00e4 kannattaa silm\u00e4ill\u00e4 seuraavia videoita. Sinun ei v\u00e4ltt\u00e4m\u00e4tt\u00e4 tarvitse katsoa pitki\u00e4 videoita kokonaan, mutta silm\u00e4ilem\u00e4ll\u00e4 n\u00e4et, miten niiss\u00e4 k\u00e4sitellyt asiantuntijaj\u00e4rjestelm\u00e4t toimivat:</p> <ul> <li>MIT: 3. Reasoning: Goal Trees and Rule-Based Expert Systems. 50-minuuttinen ideo, jossa Patrick Winston esittelee Genesis-ryhm\u00e4n tuottamaa Genesis-ohjelmaa, joka kykenee selostaa Macbeth-kirjan tapahtumia (aivan videon lopussa). Edelt\u00e4v\u00e4ss\u00e4 osio on pohjustavaa teoriaa.</li> <li>URBS: Lecture 13: Building an Expert System and PyKE. 50-minuuttinen luento, jossa esitell\u00e4\u00e4n PyKE-kirjasto ja rakennetaan asiantuntijaj\u00e4rjestelm\u00e4. Pit\u00e4\u00e4k\u00f6 ottaa sateenvarjo mukaan vai ei?</li> </ul> <p>Asiantuntijaj\u00e4rjestelm\u00e4t ovat s\u00e4\u00e4nn\u00f6pohjaisia j\u00e4rjestelmi\u00e4, jotka k\u00e4ytt\u00e4v\u00e4t tietokantaa s\u00e4\u00e4nt\u00f6j\u00e4 ja faktoja p\u00e4\u00e4t\u00f6ksenteon tai ongelmanratkaisun tukena.</p> <p>\"Expert systems are computer programs designed to mimic the decision-making abilities of human experts by leveraging predefined rules and knowledge bases.\"</p> <p>\u2013 Vijay Kanabar ja Jason Wong <sup>9</sup></p> <p>Jos asiantuntijaj\u00e4rjestelm\u00e4ll\u00e4 haluaa analysoida tekstin tapahtumia, tulee k\u00e4ytt\u00e4\u00e4 jonkin sortin semantic parser -ohjelmaa, joka muuttaa luonnollisen kielen lauseet koneen ymm\u00e4rt\u00e4m\u00e4\u00e4n muotoon. Genesiksen kohdalla t\u00e4m\u00e4 on START-niminen ohjelma, joka k\u00e4\u00e4nt\u00e4\u00e4 englantia Genesiksen sis\u00e4iseen esitysmuotoon. T\u00e4m\u00e4 selitet\u00e4\u00e4n A Commonsense Approach to Story Understanding-artikkelissa <sup>10</sup>. START itsess\u00e4\u00e4n on Boris Katz:n ja InfoLab:n (MIT) kehitt\u00e4m\u00e4 kysymyksiin vastaava hakukone, mutta Genesis k\u00e4ytt\u00e4\u00e4 sit\u00e4 vain parsijana. Sis\u00e4inen kieli sis\u00e4lt\u00e4\u00e4 entiteettej\u00e4 (substantiiveja), suhteita (henkil\u00f6 A verbi henkil\u00f6 B), funktioita ja sekvenssej\u00e4. Genesis k\u00e4ytt\u00e4\u00e4 apunaan ConceptNet-tietokantaa, knowledge graph:ia, jonka avulla voit esimerkiksi tutkia sanan dog suhteita muihin k\u00e4sitteisiin. N\u00e4iden p\u00e4\u00e4lle ovi k\u00e4ytt\u00e4j\u00e4 rakaentaa s\u00e4\u00e4nt\u00f6j\u00e4, kuten <code>if XX harms YY, YY becomes angry</code> tai <code>if XX eats food, XX becomes full</code>. Jatkossa, lause <code>Matt eats an apple</code> istuu t\u00e4h\u00e4n s\u00e4\u00e4nt\u00f6\u00f6n, koska ConceptNet yhdist\u00e4\u00e4 <code>apple</code>-sanan <code>food</code>-k\u00e4sitteeseen (is type of edible fruit).</p> <p>Toivon mukaan on t\u00e4ss\u00e4 vaiheessa selv\u00e4\u00e4, ett\u00e4 olisi \u00e4\u00e4rimm\u00e4isen haastavaa luoda modernin suuren kielimallin tasoinen asiantuntijaj\u00e4rjestelm\u00e4. Asiantuntijaj\u00e4rjestelm\u00e4t olivat kovinta huutoa 80-luvulla. Modernien kielimallien kohdalla tulet kuitenkin t\u00f6rm\u00e4\u00e4m\u00e4\u00e4n termeihin knowledge graph ja ontology. </p>"},{"location":"kieli/nlp/#haasteita-vs-mlp","title":"Haasteita vs. MLP","text":"<p>90-luvulta alkoi selke\u00e4 siirtym\u00e4 tilastollisiin menetelmiin ja perinteiseen koneoppimiseen. T\u00e4m\u00e4n kurssin osalta t\u00e4m\u00e4 aihepiiri alkaa FC-MLP-verkoista (fully connected multilayer perceptron). Kuten on jo opittu, MLP-versiot eiv\u00e4t kykene tunnistamaan spatiaalisuutta. T\u00e4h\u00e4n k\u00e4ytimme kuvien (ja \u00e4\u00e4nen) kanssa konvoluutioverkkoja aiemmissa luvuissa. Lauseen voi kuvitella 1-D -spatiaaliseksi dataksi, jossa sanat ovat \"pikseleit\u00e4\" per\u00e4kk\u00e4in. N\u00e4in Conv1D-kerrokset soveltuvat tekstin k\u00e4sittelyyn ainakin paperilla, ja niit\u00e4 on siihen my\u00f6s k\u00e4ytetty. Ongelmia, joita Conv1D-kerrokset eiv\u00e4t kuitenkaan ratkaise, ovat mm.:</p> <ol> <li>Sanat eiv\u00e4t ole lukuja. Kuvissa pikselit ovat numeerisia arvoja (esim. 0\u2013255), mutta sanat ovat kategorisia muuttujia. On ensin keksitt\u00e4v\u00e4 tapa k\u00e4\u00e4nt\u00e4\u00e4 lauseet listaksi numeroita.</li> <li>Lauseiden pituudet vaihtelevat. Yksi lause voi olla \"Kissa istuu matolla.\" ja toinen \"Kissa matolla istui olevaista pohtien.\" Konvoluutioverkot olettivat kiinte\u00e4n sy\u00f6tteen pituuden.</li> <li>Pitk\u00e4aikaiset riippuvuudet. Conv1D-kerrokset havaitsevat paikallisia kuvioita hyvin (esim. 2\u20135 per\u00e4kk\u00e4ist\u00e4 sanaa), mutta niiden on vaikea mallintaa pitk\u00e4n kantaman riippuvuuksia. Kuvittele teos, joka alkaa sanoilla: \"Seuraavat 100 asiaa eiv\u00e4t ole totta: (1) ...\".</li> <li>Konteksti ja monet merkitykset. Sanat voivat saada merkityksens\u00e4 kontekstin perusteella. Muista: \"kuusi palaa\".</li> <li>Taivutusmuodot. Monet kielet sallivat sanojen taivuttamisen, eli ovat jossain m\u00e4\u00e4rin morphologically rich. Mitenp\u00e4 suomen \"ep\u00e4j\u00e4rjestelm\u00e4llistytt\u00e4m\u00e4tt\u00f6myydell\u00e4ns\u00e4k\u00e4\u00e4nk\u00f6h\u00e4n\" ja \"ep\u00e4j\u00e4rjestelm\u00e4llinen\" liittyv\u00e4t toisiinsa?</li> </ol> <p>Todella, todella naiivi ratkaisu yll\u00e4 oleviin ongelmiin keitti\u00f6filosofin pohdinnalla olisi:</p> <ol> <li>\u2705 Tee sanoista lukuja One-Hot Encoding -menetelm\u00e4ll\u00e4.</li> <li>\u2705 T\u00e4yt\u00e4 lauseet nollilla (padding) niin, ett\u00e4 kaikilla on sama pituus.</li> <li>\u26d4 ???</li> <li>\u26d4 ???</li> <li>\u26d4 ???</li> </ol> <p>Kolme viimeisint\u00e4 j\u00e4isiv\u00e4t siis tyystin ratkaisematta \u2013 ainakin opettajan keitti\u00f6filosofian taidoilla. N\u00e4ihin ongelmiin onneksi l\u00f6ytyy parempia ratkaisuja, joihin pureudutaan t\u00e4ss\u00e4 ja seuraavissa luvuissa.</p>"},{"location":"kieli/nlp/#nlpn-perusteet","title":"NLP:n perusteet","text":""},{"location":"kieli/nlp/#tekstin-esikasittely-spacy","title":"Tekstin esik\u00e4sittely: SpaCy","text":"<p>Modernissa NLP:ss\u00e4 esik\u00e4sittely on usein virtaviivaistettu valmiiden kirjastojen, kuten SpaCy:n, avulla. SpaCy ei ole ainut. Vaihtoehtoja olisivat esimerkiksi NLTK ja Gensim. SpaCy on kuitenkin suorituskykyinen ja helppok\u00e4ytt\u00f6inen, joten keskitymme siihen.</p> <p>Kun sy\u00f6t\u00e4t teksti\u00e4 SpaCy-putkeen (engl. pipeline), se suorittaa taustalla automaattisesti useita komponentteja. T\u00e4m\u00e4 ei ole kielen k\u00e4sittelyn kurssi, joten keskitymme p\u00e4\u00e4asiassa k\u00e4ytt\u00e4m\u00e4\u00e4n valmiita putkia. Yksi valmiiksi koulutettu putki on en_core_web_sm. Kyseess\u00e4 ei ole yksitt\u00e4inen tilastollinen malli, vaan joukko NLP-komponentteja, jotka on ketjutettu yhteen. Alla on taulukko, jossa n\u00e4m\u00e4 ovat selitettyn\u00e4 auki linkkeineen, sek\u00e4 tieto siit\u00e4, onko kyseinen komponentti koulutetttava tilastollinen (lue: koneoppimiseen perustuva) malli vai s\u00e4\u00e4nt\u00f6pohjainen menetelm\u00e4 (lue: pattern matching).</p> Komponentti Tyyppi Tunnistaa Esim Mist\u00e4 l\u00f6ytyy tulos? Tokenizer Rule N/A <code>Doc</code> itsess\u00e4\u00e4n tok2vec ML N/A <code>Doc.tensor</code> tai <code>Doc[i].vector</code> tagger ML Sanaluokat NN (noun; apple), PRP (pronoun; they), JJ (adj; big) <code>Doc[i].tag_</code> parser ML Sanojen keskin\u00e4iset riippuvuudet nsubj (subject; she), prep (prep modifier; on) <code>Doc[i].dep_</code> ner ML Erisnimet ORG (organization; Google) <code>Doc[i].ent_type_</code> attributeruler Rule Poikkeuss\u00e4\u00e4nn\u00f6t esim. sanaluokille N/A lemmatizer Rule Sanan perusmuoto <code>Doc.lemmas</code> <p>Tip</p> <p>Jos haluat tiet\u00e4\u00e4, mit\u00e4 vaikkapa <code>PRP</code> tarkoittaa, voit tarkistaa sen <code>explain()</code>-metodilla.</p> <pre><code>nlp = spacy.load(\"se_malli_jonka_tagger_tai_parser_sinua_kiinnostaa\")\nprint(nlp.explain(\"PRP\"))\n</code></pre> <p>Tip</p> <p>Kannattaa tutustua dokumentaatiosta sivuihin: </p> <ul> <li>SpaCy Linguistic Features. Siell\u00e4 k\u00e4sitell\u00e4\u00e4n tarkemmin se, mik\u00e4 on alla vain listattuna yhden esimerkin avulla.</li> <li>SpaCy Library Architecture. T\u00e4m\u00e4 auttaa yll\u00e4 olevan taulukon ymm\u00e4rt\u00e4misess\u00e4 visuaalisesti.</li> <li>SpaCy Training Pipelines &amp; Models. T\u00e4m\u00e4 dokumentti selitt\u00e4\u00e4, miten SpaCy-mallit on koulutettu, ja paljastaa, mik\u00e4 syv\u00e4oppimiskirjasto sill\u00e4 on k\u00e4yt\u00f6ss\u00e4 konepellin alla.</li> </ul> <p>Jos haluaisit opetella SpaCyn syv\u00e4llisemmin, kuten tehd\u00e4 itse omia komponentteja putkeen, voisit aloittaa kurssin Advanced NLP with spaCy. Todenn\u00e4k\u00f6isesti haluaisit tutustua my\u00f6s YouTube: ExplosionAI-kanavaan, joka on SpaCyn kehitt\u00e4j\u00e4n kanava, sis\u00e4lt\u00e4en videoita sek\u00e4 SpaCyn ett\u00e4 Prodigyn k\u00e4yt\u00f6st\u00e4.</p> Kuinka ajaa alla olevat snippetit? <p>Sinulla pit\u00e4\u00e4 luonnollisesti olla SpaCy asennettuna (<code>uv add spacy</code>). Lis\u00e4ksi sinun pit\u00e4\u00e4 ladata malli. Aja terminaalissa seuraava komento:</p> <pre><code>uv add \"fi-core-news-sm @ https://github.com/explosion/spacy-models/releases/download/fi_core_news_sm-3.8.0/fi_core_news_sm-3.8.0-py3-none-any.whl\"\n</code></pre> <p>T\u00e4m\u00e4n j\u00e4lkeen k\u00e4ynnist\u00e4 Marimo, luo uusi Notebook, ja ota malli k\u00e4ytt\u00f6\u00f6n:</p> <pre><code>import spacy\n\nnlp = spacy.load(\"fi_core_news_sm\")\n</code></pre>"},{"location":"kieli/nlp/#tokenisointi","title":"Tokenisointi","text":"<p>Tekstin pilkkominen pienempiin yksik\u00f6ihin, tokeneihin (sanat, v\u00e4limerkit, erikoismerkit). Toisin kuin yksinkertainen <code>split(\" \")</code>, \u00e4lyk\u00e4s tokenisoija ymm\u00e4rt\u00e4\u00e4 esimerkiksi v\u00e4limerkkien erottamisen sanoista.</p> <pre><code>tokenized = nlp.make_doc(\"Kissa, se    on el\u00e4in?!\")\n\nfor tok in tokenized:\n    print(tok, end=\"|\")\n# Kissa|,|se|   |on|el\u00e4in|?|!|\n</code></pre>"},{"location":"kieli/nlp/#perusmuotoistaminen-lemmatization","title":"Perusmuotoistaminen (Lemmatization)","text":"<p>Sanojen palauttaminen niiden sanakirjamuotoon eli perusmuotoon (esim. \"juoksi\" \u2192 \"juosta\", \"kissojen\" \u2192 \"kissa\"). T\u00e4m\u00e4 on erityisen kriittist\u00e4 suomen kielen kaltaisissa morfologisesti rikkaissa kieliss\u00e4 sanaston koon hallitsemiseksi.</p> <pre><code>doc = nlp(\"Pienet py\u00f6re\u00e4t pippurit hyppiv\u00e4t\")\nfor token in doc:\n  print(token.lemma_, end=\" \")\n# pieni py\u00f6re\u00e4 pippuri hyppi\u00e4 \n</code></pre>"},{"location":"kieli/nlp/#sanaluokat-pos","title":"Sanaluokat (POS)","text":"<p>Jokaiselle tokenille ennustetaan sen sanaluokka (esim. substantiivi, verbi, adjektiivi). Onko kuusi numero vai mik\u00e4? Muuttuuko sanaluokka, jos annat lauseessa kontekstia, kuten kertomalla ett\u00e4 taskussani on kuusi pient\u00e4 palaa kakkua.</p> <pre><code>doc = nlp(\"Kuusi palaa.\")\nfor token in doc:\n    print(f\"{token.text} {token.pos_}\")\n# Kuusi NUM\n# palaa VERB\n</code></pre>"},{"location":"kieli/nlp/#riippuvuussuhteet","title":"Riippuvuussuhteet","text":"<p>Sanojen v\u00e4listen syntaktisten suhteiden analysointi (engl. syntactic dependency parsing) \u2013 kuka tekee, mit\u00e4 tekee, kenelle tekee. T\u00e4m\u00e4 auttaa ymm\u00e4rt\u00e4m\u00e4\u00e4n lauseen rakennetta pintaa syvemm\u00e4lt\u00e4. T\u00e4h\u00e4n l\u00f6ytyy jopa oma visualisointity\u00f6kalu:</p> <pre><code>from spacy import displacy\n\ndoc = nlp(\"Susi hy\u00f6kk\u00e4si omistajansa kanssa py\u00f6r\u00e4lenkill\u00e4 \" \n+ \"olleen koiran kimppuun keskell\u00e4 asutusta Raahessa\")\n\nmo.Html(displacy.render(doc, style=\"dep\"))\n</code></pre> <p></p> <p>Kuva 3: Riippuvuussuhteiden visualisointi SpaCy:ll\u00e4.</p>"},{"location":"kieli/nlp/#nimettyjen-entiteettien-tunnistus-ner","title":"Nimettyjen entiteettien tunnistus (NER)","text":"<p>Errisnimien, organisaatioiden, paikkojen, p\u00e4iv\u00e4m\u00e4\u00e4rien ja rahasummien automaattinen tunnistus tekstivirrasta.</p> <pre><code>doc = nlp(\"microsoft Microsoft MiCrOSofT MICROSOFT macrohard\")\n\nfor token in doc:\n    print(token.text, \"==\", token.ent_type_)\n# microsoft == ORG\n# Microsoft == ORG\n# MiCrOSofT == \n# MICROSOFT == \n# macrohard == \n</code></pre>"},{"location":"kieli/nlp/#morfologinen-analyysi","title":"Morfologinen analyysi","text":"<p>Tunnistaa taivutusmuotoja.</p> <pre><code>doc = nlp(\"P\u00f6yd\u00e4ll\u00e4\")\ndoc[0].morph\n# Case=Ade|Number=Sing\n# eli adessiivi\n\ndoc = nlp(\"P\u00f6ydill\u00e4\")\ndoc[0].morph\n# Case=Ade|Number=Plur\n# eli monikon adessiivi\n</code></pre>"},{"location":"kieli/nlp/#hukkasanat-stop-words","title":"Hukkasanat (Stop Words)","text":"<p>Hyvin yleisten ja usein merkitykselt\u00e4\u00e4n v\u00e4h\u00e4isten sanojen (kuten \"ja\", \"on\", \"ett\u00e4\") suodattaminen pois, jotta malli voi keskitty\u00e4 oleelliseen sis\u00e4lt\u00f6\u00f6n.</p> <pre><code>doc = nlp(\"Minua rassaa kun tuon niille j\u00e4\u00e4tel\u00f6\u00e4, mutta kukaan ei niinku edes hymyile.\")\nfor token in doc:\n    print(token, end=\" \") if not token.is_stop else print(\"---\", end=\" \")\n# --- rassaa --- --- tuon --- j\u00e4\u00e4tel\u00f6\u00e4 , --- --- --- hymyile .\n</code></pre>"},{"location":"kieli/nlp/#sanavektorit","title":"Sanavektorit","text":"<p>M\u00e4\u00e4ritelm\u00e4t</p> <ul> <li>Embedding: Yleinen termi, joka viittaa mihin tahansa tihe\u00e4\u00e4n numeeriseen esitykseen, joka s\u00e4ilytt\u00e4\u00e4 tietyn rakenteen tai suhteet alkuper\u00e4isess\u00e4 datassa. Raschka:n mukaan se on \"a mapping from discrete objects, such as words, images, or even entire documents, to points in a continuous vector space\" <sup>11</sup>. T\u00e4h\u00e4n liittyy ainakin satavuotinen historia, sis\u00e4lt\u00e4en klassiset PCA:t (Principal Component Analysis) sek\u00e4 modernit ongelmat/ratkaisut kuten MDE (MinimumDistortion Embedding) sek\u00e4 tietenkin alla esitelt\u00e4v\u00e4t neuroverkkopohjaiset menetelm\u00e4t. <sup>12</sup></li> <li>Word Embedding: Erityisesti sanojen tihe\u00e4 numeerinen esitys, joka s\u00e4ilytt\u00e4\u00e4 semanttisia suhteita sanojen v\u00e4lill\u00e4. Esimerkiksi Word2Vec ja GloVe ovat menetelmi\u00e4, jotka luovat sanavektoreita. <sup>11</sup></li> <li>Word Vector eli sanavektori: Sama kuin aiempi, mutta korostaa sen vektoriluonnetta matemaattisena objektina.</li> </ul> <p>Huomaa, ett\u00e4 on siis muitakin embedding-tyyppej\u00e4, kuten lause- tai osasana- (engl. subword) embeddingit. Pahoittelut finglishist\u00e4: en l\u00f6yd\u00e4 hyv\u00e4\u00e4 k\u00e4\u00e4nn\u00f6st\u00e4 embedding-sanalle.</p> <p>SpaCy laskee sanavektoreita, joten kurkataan, kuinka niihin p\u00e4\u00e4see k\u00e4siksi. SpaCy:n suomenkielisen pipelinen tapauksessa vektori on 96-ulotteinen. Esimerkiksi sanaa <code>Pizza</code> kuvaa 96 featurea. N\u00e4m\u00e4 featuret on opittu tilastollisesti valtavasta m\u00e4\u00e4r\u00e4st\u00e4 teksti\u00e4.</p> <pre><code>doc = nlp(\"Pizza on ravitsevaa.\")\nfor token in doc:\n    print(f\"{token.text:&gt;12}: \", end=\"\")\n    for value in token.vector[:3]:\n        print(f\"{value:&gt;5.2f}\", end=\" | \")\n    print(f\"... | {value:&gt;5.2f}\")\n</code></pre> <p>Output:</p> <pre><code>       Pizza:  0.49 | -5.49 | -3.25 | ... | -3.25\n          on:  5.62 | -1.54 | -0.35 | ... | -0.35\n  ravitsevaa:  4.88 |  3.93 |  0.55 | ... |  0.55\n           .: -0.65 | -0.54 |  6.29 | ... |  6.29\n</code></pre> <p>L\u00f6yd\u00e4t vastaavan rakenteen my\u00f6s <code>doc.tensor</code>-attribuutista, joka sis\u00e4lt\u00e4\u00e4 koko lauseen vektoritensorin, jonka muoto olisi t\u00e4ss\u00e4 tapauksessa <code>(3, 96)</code>. PyTorchissa tulet k\u00e4sittelem\u00e4\u00e4n niit\u00e4 yleisimmin tensoreina kokoa: <code>(batch_size, seq_len, embedding_dim)</code>.</p> <p>Mutta kuinka t\u00e4h\u00e4n outoon vektoriin ollaan p\u00e4\u00e4dytty? Tutustutaan alla eri menetelmiin, aloittaen Johdatus koneoppimiseen -kurssilta tutuksi tulleesta One-Hot Encoding -menetelm\u00e4st\u00e4, edeten tiheisiin vektoreihin, joiden piirteet on opittu tilastollisesti. Seuraavassa luvussa tutustumme suurten kielimallien k\u00e4ytt\u00e4miin kontekstisidonnaisiin sanavektoreihin. Niiden ymm\u00e4rt\u00e4minen on helpompaa, jos aloitetaan perusasioista.</p>"},{"location":"kieli/nlp/#one-hot-encoding","title":"\u26d4 One-Hot Encoding","text":"<p>T\u00e4m\u00e4n pit\u00e4isi olla sinulle tuttu konsepti Johdatus koneoppimiseen -kurssilta. Yksinkertaisesti sanottuna, One-Hot Encodin muuntaa jokaisen sanan vektoriksi, jossa on yht\u00e4 monta ulottuvuutta kuin sanakirjassa on sanoja. Vektorin arvo on 1 siin\u00e4 ulottuvuudessa, joka vastaa kyseist\u00e4 sanaa, ja 0 muualla. Eli siis, jos meill\u00e4 on 6 sanan sanasto (engl. corpus): [\"kissa\", \"koira\", \"auto\", \"talo\", \"puu\", \"vene\"], niin koko sanasto olisi enkoodattuna:</p> <pre><code>vocab = {\n    \"kissa\": [1, 0, 0, 0, 0, 0],\n    \"koira\": [0, 1, 0, 0, 0, 0],\n    \"auto\":  [0, 0, 1, 0, 0, 0],\n    \"talo\":  [0, 0, 0, 1, 0, 0],\n    \"puu\":   [0, 0, 0, 0, 1, 0],\n    \"vene\":  [0, 0, 0, 0, 0, 1],\n    \"UNK\":   [0, 0, 0, 0, 0, 0],  # Tuntematon sana\n}\n</code></pre> <p>Jos koko sanasto on siis \\(400\\,000\\) sanaa, jokainen sana esitet\u00e4\u00e4n \\(400\\,000\\)-ulotteisena vektorina, jossa vain yksi arvo on 1 ja loput \\(399\\,999\\) ovat 0. T\u00e4m\u00e4 johtaa eritt\u00e4in harvaan (sparse) esitykseen. Kukin vektori on orthogonaalinen toisiinsa n\u00e4hden, mik\u00e4 tarkoittaa, ett\u00e4 sanojen v\u00e4lill\u00e4 ei ole lainkaan semanttista yhteytt\u00e4. Esimerkiksi \"kissa\" ja \"koira\" ovat yht\u00e4 kaukana toisistaan kuin \"kissa\" ja \"auto\", vaikka ne ovat semanttisesti l\u00e4hemp\u00e4n\u00e4 toisiaan. T\u00e4m\u00e4 metodi oli k\u00e4yt\u00f6ss\u00e4 1990-luvulla, mutta nykyisten kielimallien kohdalla sen voi unohtaa tyystin. <sup>13</sup></p>"},{"location":"kieli/nlp/#tiheat-vektorit","title":"Tihe\u00e4t vektorit","text":"<p>Naiivi harva esitys on siis ongelmallinen. Seuraavaksi yksinkertaisin l\u00e4hestymsistapa on k\u00e4ytt\u00e4\u00e4 tiheit\u00e4 vektoreita, joissa jokainen sana esitet\u00e4\u00e4n matalammassa ulottuvuudessa (esim. 100 tai 300 ulottuvuutta). T\u00e4llaiset vektorit oppivat s\u00e4ilytt\u00e4m\u00e4\u00e4n sanojen semanttisia suhteita, kuten synonyymit ja analogiat. Useita menetelmi\u00e4 on kehitetty t\u00e4llaisten sanavektorien luomiseksi, joista hyv\u00e4t esimerkit ovat Word2Vec, GloVe ja fastText. <sup>13</sup></p> <p>Word2Vec ei itsess\u00e4\u00e4n ole algoritmi vaan pikemminkin joukko malleja, jotka oppivat sanavektoreita tilastollisesti. Mikolov esitteli alkuper\u00e4isess\u00e4 artikkelissaan kaksi p\u00e4\u00e4mallia: Continuous Bag of Words (CBOW) ja Skip-Gram. <sup>14</sup> Tutustumme erityisesti CBOW:iin alla.</p> <p>Ennen Mikolovin artikkelia oli tyypillist\u00e4, ett\u00e4 kukin NLP-tutkija kehitti/koulutti oman sanavektorimallinsa omaan k\u00e4ytt\u00f6\u00f6ns\u00e4. Word2Vec:n mallit mullistivat t\u00e4t\u00e4 siten, ett\u00e4 jatkossa tutkijat pystyiv\u00e4t hy\u00f6dynt\u00e4m\u00e4\u00e4n valmiiksi koulutettuja sanavektoreita, pretrained word embeddings, jotka oli koulutettu valtavilla tekstikorpuksilla (esim. Google News, Wikipedia). N\u00e4in sanavektorit muuttuivat standardoiduiksi resursseiksi, joita voitiin jakaa ja k\u00e4ytt\u00e4\u00e4 eri NLP-teht\u00e4viss\u00e4. <sup>13</sup></p>"},{"location":"kieli/nlp/#word2vec","title":"Word2Vec","text":"<p>Warning</p> <p>V\u00e4lt\u00e4 sekaannusta Bag of Words (BoW) -menetelm\u00e4n kanssa, joka on eri asia kuin Continuous Bag of Words (CBOW). BOW on Naive Bayesin ja muiden perinteisten mallien esik\u00e4sittelymenetelm\u00e4, jossa lause esitet\u00e4\u00e4n sanakirjassa esiintyvien sanojen frekvenssein\u00e4 ilman j\u00e4rjestyst\u00e4.</p> <ul> <li>BoW: <ul> <li>Dokumentti-tason esitys, jossa lasketaan kunkin sanaston sanan esiintymiskerrat (tai muita tilastollisia esiintymisi\u00e4, kuten TF-IDF).</li> <li>Ei vaadi mink\u00e4\u00e4n sortin koulutusta.</li> </ul> </li> <li>CBOW: <ul> <li>Sanatason esitys.</li> <li>Koulutetaan ennustamaan sanaa sen kontekstin perusteella.</li> </ul> </li> </ul> <p>Continuous Bag of Words (CBOW) -malli ennustaa keskimm\u00e4isen sanan ymp\u00e4r\u00f6ivien sanojen perusteella. <sup>14</sup> K\u00e4yd\u00e4\u00e4n algoritmi l\u00e4pi esimerkin avulla. Kuvitellaan lause: \"Train will arrive at five\". Meid\u00e4n ikkunakoko on 2, eli otamme kaksi sanaa kummaltakin puolelta keskimm\u00e4ist\u00e4 sanaa. Meid\u00e4n haluttu embedding ulottuvuus on 3. T\u00e4ten input ja target ovat esik\u00e4sittelyn j\u00e4lkeen:</p> <pre><code>n = len(rest_of_vocab)\nX = [\n  [1,0,0,0,0] + [0]*n,  # train\n  [0,1,0,0,0] + [0]*n,  # will\n  [0,0,0,1,0] + [0]*n,  # at\n  [0,0,0,0,1] + [0]*n   # five\n]\ny = [0,0,1,0,0] + [0]*n  # arrive\n</code></pre> <p>N\u00e4iden johdosta meill\u00e4 on <code>Nx3</code>-kokoinen embedding matrix <code>W</code> (<code>N</code> sanaa sanastossa, 3 ulottuvuutta). T\u00e4m\u00e4n matriisin jokainen rivi on sanan vektoriesitys. T\u00e4m\u00e4 vektori on siis embedding matrix. Koulutuksen j\u00e4lkeen t\u00e4m\u00e4 on se, mit\u00e4 me haluamme k\u00e4ytt\u00e4\u00e4 sanavektoreina. Aluksi n\u00e4m\u00e4 arvot ovat satunnaisia. Sy\u00f6te k\u00e4yt\u00e4nn\u00f6ss\u00e4 valitsee <code>W</code>:st\u00e4 nelj\u00e4 rivi\u00e4 (operaatiolla <code>X @ W</code>), jotka vastaavat t\u00e4ss\u00e4 tapauksessa sanoja <code>train</code>, <code>will</code>, <code>at</code> ja <code>five</code>. T\u00e4m\u00e4 valinta tapahtuu siten, ett\u00e4 matriisin muut arvot saavat arvon nolla, jolloin vain n\u00e4iden nelj\u00e4n sanan rivit vaikuttavat lopputulokseen.</p> <p>T\u00e4m\u00e4 operaatio k\u00e4\u00e4rit\u00e4\u00e4n viel\u00e4 summan tai keskiarvon sis\u00e4\u00e4n, <code>h = torch.sum(X @ W, dim=0)</code>, jolloin saadaan kolmeulotteinen vektori <code>h</code>, joka on n\u00e4iden nelj\u00e4n sanan vektoreiden summa. T\u00e4m\u00e4n j\u00e4lkeen lasketaan <code>h @\u00a0W2</code>, jossa <code>W2</code> on toinen painomatriisi, joka muuntaa takaisin sanatilaan. Alla olevassa kuvassa t\u00e4m\u00e4 on nimelt\u00e4\u00e4n \\(W'\\). Tulos on vektori, jossa on <code>N</code> ulottuvuutta. Lopuksi k\u00e4ytet\u00e4\u00e4n softmaxia ja lasketaan tappio (loss) verraten ennustettua sanaa <code>y</code>:t\u00e4 vastaan. Koko prosessi toistetaan valtavalla m\u00e4\u00e4r\u00e4ll\u00e4 lauseita, jolloin <code>W</code> oppii s\u00e4ilytt\u00e4m\u00e4\u00e4n sanojen semanttisia suhteita.</p> <p></p> <p>Kuva 4: Continuous Bag of Words (CBOW) -mallin arkkitehtuuri. Kuva on mukailtu Mikolov:n alkuper\u00e4isest\u00e4 artikkelista, mutta avattu yll\u00e4 olevan tekstiesimerkin mukaiseksi.</p> <p>Seuraavaksi voisimme liu'uttaa t\u00e4t\u00e4 ikkunaa eteenp\u00e4in lauseessa, jolloin saamme lis\u00e4\u00e4 input- ja target-pareja. Seuraava ikkuna voisi olla: \"will arrive at five o'clock\", jolloin <code>y</code> olisi <code>at</code>. N\u00e4in jatketaan koko korpuksen l\u00e4pi useita kertoja.</p> <p>CBOW ei suinkaan ole t\u00e4ydellinen, vaan siin\u00e4 on seuraavat heikkoudet <sup>13</sup>:</p> <ol> <li>Pieni ikkuna. CBOW k\u00e4ytt\u00e4\u00e4 kiinte\u00e4n kokoista liukuvaa ikkunaa, joka rajoittaa kontekstin m\u00e4\u00e4r\u00e4\u00e4. Pitk\u00e4n kantaman riippuvuudet j\u00e4\u00e4v\u00e4t huomiotta.</li> <li>Subword-tieto puuttuu. CBOW k\u00e4sittelee sanat kokonaisina yksikk\u00f6in\u00e4. Esimerkiksi substansiitivsta muodostetun adjektiivin kantasanan yhteys j\u00e4\u00e4 huomiotta (<code>vaara</code> vs. <code>vaarallinen</code> tai <code>intelligent</code> vs. <code>intelligence</code>).</li> <li>Out of Vocabulary (OOV). CBOW ei pysty k\u00e4sittelem\u00e4\u00e4n sanoja, joita ei ole n\u00e4hty koulutuksen aikana. T\u00e4m\u00e4 on ongelma harvinaisille sanoille tai kirjoitusvirheille.</li> <li>Staattisuus. Jokaisella sanalla on yksi kiinte\u00e4 vektoriesitys, joka ei muutu kontekstin mukaan. Ono se kuusi nyt sitten numero vai puu?</li> </ol> <p>Ent\u00e4 Skip-gram?</p> <p>Skip-gram toimii p\u00e4invastoin kuin CBOW: se ennustaa kontekstisanoja annetun sanan perusteella. Eli jos meill\u00e4 on sana <code>arrive</code>, Skip-gram yritt\u00e4\u00e4 ennustaa sanat <code>train</code>, <code>will</code>, <code>at</code> ja <code>five</code>. Arkkitehtuuri on muuten samanlainen, mutta sy\u00f6te ja tavoite ovat vaihtaneet paikkaa <sup>14</sup>. Skip-gram toimii erityisen hyvin harvinaisten sanojen kanssa, koska se keskittyy yksitt\u00e4isiin sanoihin ja niiden konteksteihin. <sup>15</sup></p>"},{"location":"kieli/nlp/#glove","title":"GloVe","text":"<p>GloVe julkaistiin 2014 Stanfordissa, vuosi Word2Vec:n j\u00e4lkeen. GloVe korjaa CBOW:n ensimm\u00e4isen\u00e4 puutteen (ks. ylt\u00e4) hy\u00f6dynt\u00e4m\u00e4ll\u00e4 koko korpuksen globaaleja yhteisesiintymistilastoja(engl. co-occurrence matrix) pelk\u00e4n lokaalin ikkunan sijaan. GloVe rakentaa sanavektorit siten, ett\u00e4 sanojen vektoreiden v\u00e4linen et\u00e4isyys heijastaa niiden yhteisesiintymistiheytt\u00e4 koko korpuksessa: t\u00e4m\u00e4 tehd\u00e4\u00e4n tekem\u00e4ll\u00e4 dimensiov\u00e4hennys yhteisesiintymismatriisille <sup>13</sup>.</p> <p>Emme k\u00e4sittele algoritmia t\u00e4ss\u00e4 tarkemmin, mutta voit tutua sen verkkosivuihin GloVe: Global Vectors for Word Representation. Sivuilta l\u00f6ytyy sek\u00e4 julkaisu, kivoja kuvia, ett\u00e4 linkki GitHub-koodiin (C-kielt\u00e4).</p>"},{"location":"kieli/nlp/#fasttext","title":"fastText","text":"<p>Facebook julkaisi fastText-algoritmin vuonna 2016. Kuten sen artikkelin otsikosta, \"Enriching Word Vectors with Subword Information\", voi p\u00e4\u00e4tell\u00e4, fastText ottaa huomioon sanojen sis\u00e4iset osat (subwords), kuten n-grammit. T\u00e4m\u00e4 auttaa k\u00e4sittelem\u00e4\u00e4n harvinaisia sanoja ja morfologisesti rikkaita kieli\u00e4 paremmin kuin Word2Vec tai GloVe. fastText edustaa kutakuinkin seuraavaa evoluutiovaihetta sanavektoreissa <sup>16</sup>.</p> <p>Emme k\u00e4sittele my\u00f6sk\u00e4\u00e4n t\u00e4t\u00e4 algoritmia tarkemmin. Voit tutustua sen verkkosivuihin fastText: Library for Efficient Text Classification and Representation Learning. Sivuilta l\u00f6ytyy Explain Like I'm Five -video, linkki koodiin ja muuta hy\u00f6dyllist\u00e4.</p> <p>Se, mik\u00e4 meit\u00e4 kiinnostaa, on ett\u00e4 mitk\u00e4 CBOW:n heikkouksista on nyt korjattu <sup>13</sup>:</p> <ol> <li>\u26d4 Pieni ikkuna. fastText k\u00e4ytt\u00e4\u00e4 edelleen kiinte\u00e4n kokoista ikkunaa.</li> <li>\u2705 Subword-tieto. fastText jakaa sanat n-grammeihin.</li> <li>\u2705 Out of Vocabulary (OOV). fastText voi luoda vektoreita tuntemattomille sanoille niiden n-grammien perusteella.</li> <li>\u26d4 Staattisuus. fastTextin sanavektorit ovat edelleen staattisia.</li> </ol>"},{"location":"kieli/nlp/#vektorien-vertailu","title":"Vektorien vertailu","text":"<p>TODO! Kun sanat on muutettu numeerisiksi vektoreiksi, voimme laskea niiden v\u00e4lisi\u00e4 et\u00e4isyyksi\u00e4 selvitt\u00e4\u00e4ksemme, mitk\u00e4 sanat tai dokumentit ovat sis\u00e4ll\u00f6llisesti l\u00e4himp\u00e4n\u00e4 toisiaan.</p> <p>TODO! Yleisin tapa mitata kahden sanavektorin samankaltaisuutta on laskea niiden v\u00e4linen kulma (kosini), joka on riippumaton itse vektorin pituudesta (skaalasta). K\u00e4yt\u00e4nn\u00f6n harjoituksissa hy\u00f6dynn\u00e4mme t\u00e4h\u00e4n Pythonin SciPy-kirjaston spatial.distance.cosine -funktiota.</p>"},{"location":"kieli/nlp/#vektorien-analogiat","title":"Vektorien analogiat","text":"<p>\"We now evaluate our approach on word analogy questions, of the form A is to B as C is to D, where D must be predicted by the models.\" </p> <p>\u2014 Mikolov et al., 2013 <sup>14</sup></p> <p>Koska embedding on piirrovektori, voidaan laskea vektoreiden v\u00e4lisi\u00e4 eroja ja summia. T\u00e4m\u00e4 mahdollistaa semanttisten analogioiden l\u00f6yt\u00e4misen. Esimerkiksi, jos meill\u00e4 on sanat <code>king</code>, <code>man</code> ja <code>woman</code>, voimme tehd\u00e4 seuraavanlaista matematiikkaa:</p> <pre><code>import numpy as np\n\nking_vector = nlp(\"king\").vector\nman_vector = nlp(\"man\").vector\nwoman_vector = nlp(\"woman\").vector\nqueen_vector = king_vector - man_vector + woman_vector\n</code></pre>"},{"location":"kieli/nlp/#samankaltaisuus-numerona","title":"Samankaltaisuus numerona","text":"<p>Johdatus koneoppimiseen -kurssilta sinulle pit\u00e4isi olla tuttu k\u00e4site euklidinen et\u00e4isyys, joka mittaa suoraa et\u00e4isyytt\u00e4 kahden vektorin v\u00e4lill\u00e4. Kyseess\u00e4 on linnuntie-et\u00e4isyys. Piirrevektorin kohdalla t\u00e4m\u00e4 ei kuitenkaan ole paras tapa mitata samankaltaisuutta, koska se on herkk\u00e4 vektoreiden normille eli pituudelle. Siksi k\u00e4ytet\u00e4\u00e4n usein kosinista samankaltaisuutta, joka mittaa vektoreiden v\u00e4list\u00e4 kulmaa, eik\u00e4 niink\u00e4\u00e4n et\u00e4isyytt\u00e4. <sup>17</sup> Ajatus itsess\u00e4\u00e4n on hyvin vanha. Ainakin itse sen esittelij\u00f6ist\u00e4 on Zellig Harris julkaisussa \"Distributional Structure\" vuodelta 1954. <sup>18</sup> PsycNetin tiivistelm\u00e4 on seuraava: \"Harris maintains that it is possible to define a linguistic structure solely in terms of the \"distributions\" (= patterns of co-occurrences) of its elements. There is no parallel meaning-structure which can aid in describing formal structure. Meaning is partly a function of distribution.\" <sup>19</sup></p> <p>T\u00e4m\u00e4 cosine similarity on pistetulon normalisoitu versio. Se vastaa kahden vektorin v\u00e4lisen kulman kosinia, mist\u00e4 nimi kosininen samankaltaisuus <sup>17</sup>:</p> \\[ \\text{cosine_similarity}(\\mathbf{u}, \\mathbf{v}) = \\frac{\\mathbf{u} \\cdot \\mathbf{v}}{\\|\\mathbf{u}\\| \\|\\mathbf{v}\\|} \\] <p>Kosinilla on hy\u00f6dyllisi\u00e4 ominaisuuksia skaalainvarianssin lis\u00e4ksi <sup>17</sup>:</p> <ul> <li>Se on v\u00e4lill\u00e4 -1 ja 1. <ul> <li>Vastakkaiset: -1</li> <li>Ortogonaaliset: 0</li> <li>Samansuuntaiset: 1</li> </ul> </li> <li>Se on nopea ja edullinen laskea.</li> <li>Se on v\u00e4hemm\u00e4n herkk\u00e4 sanojen esiintymistiheydelle ja siten kest\u00e4v\u00e4mpi poikkeuksille (engl. outliers)</li> <li>Koska se on normalisoitu, sit\u00e4 voidaan k\u00e4ytt\u00e4\u00e4 my\u00f6s korkeaulotteisen datan kanssa.</li> </ul> <p></p> <p>Kuva 5: Havainnekuva kosinisen samankaltaisuuden arvoista eri rypp\u00e4iden v\u00e4lill\u00e4. Punainen kolmio edustaa kahden rypp\u00e4\u00e4n v\u00e4list\u00e4 kosinikulmaa.</p> <p>Yll\u00e4 olevassa kuvassa pisteet edustavat sanoja tai N-grammeja eli yleens\u00e4 yhdess\u00e4 esiintyvist\u00e4 sanoista koostettuja kokonaisuuksia. Pisteparven <code>x</code>-akseli on <code>individual\u2014social</code> ja <code>y</code> on <code>physical\u2014digital</code>. </p> <ul> <li> Siniset sanat ovat vahvan digitaalisia, l\u00e4hes neutraaleja sosiaalisuudeltaan, kuten: <code>cloud_storage</code>, <code>database</code>, <code>encryption</code>. </li> <li> Keltaiset sanat ovat v\u00e4hemm\u00e4n digitaalisia, enemm\u00e4n sosiaalisia, kuten: <code>social_media_app</code>, <code>group_chat</code>, <code>wikipedia</code>.</li> <li> Violetit sanat ovat miedosti fyysisen puolella ja yksil\u00f6llisi\u00e4, kuten: <code>map</code>, <code>board_game_rulebook</code>, <code>print</code>. </li> </ul> <p>Jos valitsemme kustakin rypp\u00e4\u00e4st\u00e4 yhden sanan, voimme laskea et\u00e4isyyksi\u00e4. Saamme <code>cosine(yellow, blue) \u2248 0.5</code>. Sen sijaan <code>cosine(yellow, purple) \u2248 -1.0</code>. Huomaa, ett\u00e4 jos k\u00e4ytt\u00e4isimme euklidista et\u00e4isyytt\u00e4, tulos olisi hyvin eri: <code>euclid(yellow, blue) &gt; euclid(yellow, purple)</code>. Yksinkertaisessa 2-ulotteisessa kuvaajassa t\u00e4m\u00e4 on silm\u00e4m\u00e4\u00e4r\u00e4isesti todistettavissa: muista, ett\u00e4 sanavektori on esimerkiksi 300-ulotteinen vektori.</p>"},{"location":"kieli/nlp/#yhteenveto","title":"Yhteenveto","text":"<p>Tiivistet\u00e4\u00e4n yll\u00e4 l\u00f6ydetty, ELIZA:aa ja PARRY:\u00e4 seuraava historia lyhyesti v\u00e4itteisiin vuosikymmenitt\u00e4in:</p>"},{"location":"kieli/nlp/#1990-luku","title":"1990-luku","text":"<ul> <li>Esiprosessointi ja sanojen tokenisointi. Tilastolliset menetelm\u00e4t ovat hyvin hauraita sy\u00f6tteen suhteen, joten sananmuodot, hukkasanat ja muut on k\u00e4sitelt\u00e4v\u00e4 huolellisesti. Tied\u00e4t t\u00e4m\u00e4n Johdatus koneoppimiseen -kurssilta. Naive Bayes luulee esimerkiksi ett\u00e4 <code>Kissa</code> ja <code>kissa</code> ovat eri sanoja, ellet erikseen k\u00e4sittele datasetti\u00e4.</li> <li>One-Hot &amp; BoW. Sanat esitettiin eristettyin\u00e4 indeksein\u00e4 tai frekvenssein\u00e4 sanakirjassa, jossa esiintyy aivan jokainen mallin tuntema sana. <sup>13</sup></li> <li>N-Gram. Ainut tapa mallintaa kontekstia oli tarkastella per\u00e4kk\u00e4isten sanojen yhdistelmi\u00e4. K\u00e4rjistetysti tietyist\u00e4 sanapareista (bigram) tai -kolmikoista (trigram) laskettiin todenn\u00e4k\u00f6isyydet, eli vaikkapa <code>new york</code> on yksi token.</li> <li>RNN ja LSTM. RNN oli 90-luvulla akateeminen kuriositeetti. Laskentatehoa oli todella v\u00e4h\u00e4n ja saatavat datasetit pieni\u00e4. Wikipediaa tai n\u00e4yt\u00f6nohjaimia ei ollut olemassa.</li> </ul>"},{"location":"kieli/nlp/#2000-luku","title":"2000-luku","text":"<ul> <li>Word Embeddings. Bengio ja kollegat esitteliv\u00e4t sanavektorit kielimallinnukseen (tai k\u00e4\u00e4nn\u00f6sty\u00f6h\u00f6n). Sanavektori sis\u00e4lt\u00e4\u00e4 tietoa kontekstista, kuten sanojen <code>dog</code> ja <code>cat</code> samankaltaisuudesta. <sup>20</sup></li> </ul>"},{"location":"kieli/nlp/#2010-luku","title":"2010-luku","text":"<ul> <li>Word2Vec. Mikolov ja kollegat Googlessa esitteliv\u00e4t Word2Vecin (CBOW ja Skip-Gram), joka mahdollisti eritt\u00e4in tehokkaan tavan oppia sanavektoreita suurista tekstikorpuksista. Huomaa sana efficient julkaisun otsikossa. T\u00e4m\u00e4 jatkoi Bengion kehityst\u00e4. <sup>14</sup></li> <li>Kontekstisidonnaiset sanavektorit. Sanavektorit eiv\u00e4t ole en\u00e4\u00e4 staattisia, vaan ne riippuvat lauseen kontekstista.</li> <li>Subword-tokenisointi. Koko sanan k\u00e4ytt\u00f6 tokenina on naiivi ratkaisu. Yksitt\u00e4isen kirjaimen k\u00e4ytt\u00f6 tokenina sis\u00e4lt\u00e4\u00e4 enemm\u00e4n informaatiota, mutta on ep\u00e4tehokas ratkaisu. V\u00e4list\u00e4 l\u00f6ytynee siis hyv\u00e4 balanssi? Byte-Pair Encoding (BPE) ja vastaavat menetelm\u00e4t pyrkiv\u00e4t muodostamaan tokenit dynaamisesti yleisimmist\u00e4 osasanoista. <sup>21</sup></li> <li>Seq2Seq. Sutskever ja kollegat esitteliv\u00e4t encoder-decoder-arkkitehtuurin konek\u00e4\u00e4nn\u00f6kseen, jossa RNN-verkko koodaa sy\u00f6tteen ja toinen RNN dekoodaa sen toiselle kielelle. Enkooderin ja dekooderin v\u00e4liss\u00e4 on kiinte\u00e4mittainen vektori, joka pyrkii sis\u00e4lt\u00e4m\u00e4\u00e4n kaiken sy\u00f6tteen merkityksen. <sup>22</sup> T\u00e4st\u00e4 jatketaan tarkemmin RNN ja j\u00e4lkel\u00e4iset-luvussa.</li> <li>Attention. Bahdanau ja kollegat esitteliv\u00e4t attention-mekanismin, joka sallii dekooderin keskitty\u00e4 eri osiin sy\u00f6tett\u00e4 eri aikoina, parantaen merkitt\u00e4v\u00e4sti k\u00e4\u00e4nn\u00f6sten laatua. <sup>23</sup></li> <li>Transformers. T\u00e4st\u00e4 jatketaan tarkemmin Transformers-luvussa.</li> </ul>"},{"location":"kieli/nlp/#tehtavat","title":"Teht\u00e4v\u00e4t","text":"<p>Teht\u00e4v\u00e4: Embeddings</p> <p>Avaa Marimo Notebook <code>700_embeddings.py</code> ja tutustu koodiin. Suorita koodi ja tarkastele tuloksia. Kokeile muuttaa sanoja ja n\u00e4hd\u00e4, miten vektorit muuttuvat. Notebookissa muun muassa:</p> <ul> <li>Vertaillaan sanaparien et\u00e4isyyksi\u00e4 (esim. <code>sielu</code> vs. <code>ter\u00e4s</code>)</li> <li>Tutustutaan 1000 yleisimm\u00e4n suomenkielisen sanan keskin\u00e4isiin et\u00e4isyyksiin: mitk\u00e4 ovat l\u00e4himm\u00e4t ja kaukaisimmat sanat?</li> <li>Tarkastellaan 2-ulotteiseen koordinaatistoon projisoituja sanavektoreita (PCA- ja t-SNE-menetelmill\u00e4)</li> </ul> <p>Teht\u00e4v\u00e4: SpaCY Playground</p> <p>T\u00e4m\u00e4 teht\u00e4v\u00e4 on vapaaehtoinen: tee, jos se auttaa sinua ymmm\u00e4rt\u00e4m\u00e4\u00e4n konseptit ylt\u00e4.</p> <p>K\u00e4yt\u00e4 <code>701_spacy_playground.py</code>-notebookia apuna esimerkiksi yll\u00e4 olevan tekstin ymm\u00e4rt\u00e4miseen. Voit kopioida ja liitt\u00e4\u00e4 koodinp\u00e4tk\u00e4t ja kokeilla niit\u00e4 itse. Notebookissa on l\u00e4hinn\u00e4 vain import ja mallin lataus valmiina.</p> <p>Teht\u00e4v\u00e4: Sanavektorien vertailu</p> <p>T\u00e4m\u00e4 teht\u00e4v\u00e4 on vapaaehtoinen. Se vaatii suurehkon tiedoston lataamisen netist\u00e4, mik\u00e4 voi olla rajoite joillekin.</p> <p>Avaa <code>702_nvidia_pretrained_glove.py</code>-notebook ja tutustu koodiin. Suorita koodi ja tarkastele tuloksia. T\u00e4m\u00e4 on oiva tapa tutustua suurella datalla koulutettuihin sanavektoreihin.</p>"},{"location":"kieli/nlp/#lahteet","title":"L\u00e4hteet","text":"<ol> <li> <p>Watson, M &amp; Chollet, F. Deep Learning with Python, Third Edition. Manning. 2025.\u00a0\u21a9\u21a9\u21a9</p> </li> <li> <p>Turing, A. M. Computing Machinery and Intelligence. Mind. 1950. https://courses.cs.umbc.edu/471/papers/turing.pdf\u00a0\u21a9</p> </li> <li> <p>Ammerman, W. The Invisible Brand: Marketing in the Age of Automation, Big Data, and Machine Learning. McGraw-Hill. 2024.\u00a0\u21a9\u21a9</p> </li> <li> <p>Jones, C.R. &amp; Benjamin, B. Large Language Models Pass the Turing Test. 2025. https://arxiv.org/abs/2503.23674\u00a0\u21a9</p> </li> <li> <p>Barton, R. &amp; Henry, J. Demystifying Generative AI: A Practical and Intuitive Introduction. Addison-Wesley Professional. 2026.\u00a0\u21a9\u21a9\u21a9</p> </li> <li> <p>Lew, G. &amp; Schumacher, R. AI and UX: Why Artificial Intelligence Needs User Experience. Apress. 2020.\u00a0\u21a9</p> </li> <li> <p>Unknown. PARRY Encounters the DOCTOR. 1973. https://www.rfc-editor.org/rfc/rfc439.html\u00a0\u21a9</p> </li> <li> <p>Rawat, R. et. al. Conversational Artificial Intelligence. Wiley-Scrivener. 2024.\u00a0\u21a9</p> </li> <li> <p>Kanabar, V. &amp; Wong, J. The AI Revolution in Project Management: Elevating Productivity with Generative AI*. Pearson. 2023.\u00a0\u21a9</p> </li> <li> <p>Williams, B. A Commonsense Approach to Story Understanding. MIT. 2016. https://groups.csail.mit.edu/genesis/papers/2017%20Bryan%20Williams.pdf\u00a0\u21a9</p> </li> <li> <p>Raschka, S. Build a Large Language Model (From Scratch). Manning. 2024.\u00a0\u21a9\u21a9</p> </li> <li> <p>Akshay and pymde contributors. What is an embedding?. pymde docs. https://pymde.org/getting_started/#what-is-an-embedding\u00a0\u21a9</p> </li> <li> <p>Patel, A &amp; Arasanipalai, A. Applied Natural Language Processing in the Enterprise. O'Reilly. 2021.\u00a0\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9</p> </li> <li> <p>Mikolov, T. et. al. Efficient Estimation of Word Representations in Vector Space. 2013. https://arxiv.org/abs/1301.3781\u00a0\u21a9\u21a9\u21a9\u21a9\u21a9</p> </li> <li> <p>Kulshreshta, R. NLP 101: Word2Vec \u2014 Skip-gram and CBOW. Toward Data Science. 2019. https://medium.com/data-science/nlp-101-word2vec-skip-gram-and-cbow-93512ee24314\u00a0\u21a9</p> </li> <li> <p>Bojanowski, P. et. al. Enriching Word Vectors with Subword Information. 2016. https://arxiv.org/pdf/1607.04606\u00a0\u21a9</p> </li> <li> <p>Raieli, S. &amp; Iuculano, G. Building AI Agents with LLMs, RAG, and Knowledge Graphs. Packt. 2025.\u00a0\u21a9\u21a9\u21a9</p> </li> <li> <p>Harris, Z. Distributional Structure. Word. 1954. https://www.its.caltech.edu/~matilde/ZelligHarrisDistributionalStructure1954.pdf\u00a0\u21a9</p> </li> <li> <p>APA PsycNet. Distributional Structure. PsycINFO Database Record. 2016. https://psycnet.apa.org/record/1956-02807-001\u00a0\u21a9</p> </li> <li> <p>Bengio, Y. et. al. A Neural Probabilistic Language Model. Journal of Machine Learning Research. 2003. https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf\u00a0\u21a9</p> </li> <li> <p>Sennrich, R. et. al. Neural Machine Translation of Rare Words with Subword Units. 2016. https://arxiv.org/abs/1508.07909\u00a0\u21a9</p> </li> <li> <p>Sutskever, I. et. al. Sequence to Sequence Learning with Neural Networks. 2014. https://arxiv.org/abs/1409.3215\u00a0\u21a9</p> </li> <li> <p>Bahdanau, D. et. al. Neural Machine Translation by Jointly Learning to Align and Translate. 2015. https://arxiv.org/abs/1409.0473\u00a0\u21a9</p> </li> </ol>"},{"location":"kieli/rnn/","title":"RNN ja j\u00e4lkel\u00e4iset","text":""},{"location":"kieli/rnn/#linkki-aiemmin-opittuun","title":"Linkki aiemmin opittuun","text":"<p>Edellisess\u00e4 osiossa keskityimme paljolti termiin embedding. K\u00e4sitteen ymm\u00e4rt\u00e4minen helpottaa merkitt\u00e4v\u00e4sti RNN:n ja sen seuraajien, kuten LSTM:n ja GRU:n, toimintaperiaatteen ymm\u00e4rt\u00e4mist\u00e4. Jos olet ep\u00e4varma, kannattaa kerrata edellist\u00e4 osiota ja k\u00e4yd\u00e4 k\u00e4velyll\u00e4 tai nukkua y\u00f6n yli.</p> <p>Toinen k\u00e4site, mik\u00e4 kannattaa palauttaa mieleen, on shared weights eli jaetut painot. RNN:ss\u00e4, kuten konvoluutioverkoissakin, k\u00e4ytet\u00e4\u00e4n jaettuja painoja, mik\u00e4 tarkoittaa, ett\u00e4 samaa painojoukkoa k\u00e4ytet\u00e4\u00e4n useissa eri kohdissa verkkoa. Konvoluutioverkon kohdalla t\u00e4m\u00e4 on intuitiivista, koska paino on kernel eli suodatin, jonka vaikutusta kuvaan voi tarkastella visuaalisesti. RNN:ss\u00e4 jaettu paino on konseptuaalisesti sama, mutta sen visualisointi on vaikeampaa, koska RNN k\u00e4sittelee sekvenssidataa. Ihmismielell\u00e4 on vaikeampi k\u00e4sitt\u00e4\u00e4, kuinka samoja painoja voi soveltaa esimerkiksi lauseen eri sanoihin (tai siis niiden embedding-esityksiin).</p> <p></p> <p>Kuva 1: Kaksi tuttua ja tuore tuttavuus vierekk\u00e4in. Konvoluutioverkko v\u00e4hensi parametrien m\u00e4\u00e4r\u00e4\u00e4 hy\u00f6dynt\u00e4m\u00e4ll\u00e4 paikallista rakennetta, jolloin kaikkea ei kytket\u00e4 kaikkeen. RNN sen sijaan hy\u00f6dynt\u00e4\u00e4 datan sekvenssiluonnetta, jolloin se voi hy\u00f6dynt\u00e4\u00e4 aiempaa tietoa nykyisen sy\u00f6tteen k\u00e4sittelyss\u00e4. Sivuun piirretty nuoli vie pieneen laatikkoon: yksi per neuroni. T\u00e4m\u00e4 mahdollistaa \"muistin\", koska aktivoinnin vaikutus akkumuloituu t\u00e4h\u00e4n muuttujaan, joka on seuraavan sy\u00f6tteen k\u00e4sittelyn laskennan osaksi. <sup>1</sup></p> <p>RNN:n ja CNN:n eroavaisuuksista kannattaa jo heti hyv\u00e4ksy\u00e4 se, ett\u00e4 konvoluutioverkko vaatii tietyn kokoisen inputin. Sen sijaan RNN tarvitsee vain saman kokoisen embedding-esityksen, mutta sekvenssin pituus voi vaihdella. T\u00e4m\u00e4 mahdollistaa sen, ett\u00e4 RNN p\u00e4rj\u00e4\u00e4 eri mittaisten lauseiden kanssa. Konvoluutioverkkoa voi siis k\u00e4ytt\u00e4\u00e4 <code>Conv1D</code>-hengess\u00e4 k\u00e4sittelem\u00e4\u00e4n lauseita, mutta t\u00e4ll\u00f6in t\u00e4ytyy m\u00e4\u00e4ritell\u00e4 maksimipituus ja lyhent\u00e4\u00e4 tai t\u00e4ytt\u00e4\u00e4 lauseet sopiviksi. RNN:ss\u00e4 t\u00e4t\u00e4 ei tarvita. T\u00e4m\u00e4 on merkitt\u00e4v\u00e4 etu lauseiden kanssa, jotka ovat luonnostaan eri mittaisia.</p> <p>Danger</p> <p>T\u00e4ss\u00e4 on sekaannuksen vaara l\u00e4sn\u00e4, joten korostetaan asiaa. RNN:kin tarvitsee paddingia batch-k\u00e4sittely\u00e4 varten, mutta se ei vaadi sit\u00e4 yksitt\u00e4isen lauseen k\u00e4sittelyyn.</p>"},{"location":"kieli/rnn/#motivaatio","title":"Motivaatio","text":"<p>RNN:t ovat neuroverkkoarkkitehtuuri, joka on suunniteltu k\u00e4sittelem\u00e4\u00e4n sekvenssidataa, kuten teksti\u00e4, \u00e4\u00e4nt\u00e4 tai aikasarjoja. On t\u00e4rke\u00e4\u00e4 painottaa sanaa toistuva tai sekvenssi. Ratkomme samankaltaisia ongelmia kuin aiemmin kurssilla, mutta nyt data on j\u00e4rjestetty sekvensseiksi: per\u00e4kk\u00e4isyys voi olla selke\u00e4 temporaalinen j\u00e4rjestys, kuten aikasarjoissa, tai ihan vain sanojen per\u00e4kk\u00e4isyys lauseessa.</p> <p>Alla on taulukko, joka havainnollistaa erilaisten ongelmatyyppien ratkaisua. Taulukko mukailee Magnus Ekmanin vastaavaa <sup>1</sup>. Alempi rivi edustaa sekvenssidataa eli t\u00e4m\u00e4n viikon aihetta, ylempi rivi on aiemmilta viikoilta tuttua kauraa:</p> Regressio Luokittelu Multiclass luokittelu Ei-sekvenssi Ennusta talon hinta Tunnista sairaus Tunnista MNIST-digit Sekvenssi Ennusta ensi kuun kysynt\u00e4 Tunnista sataako huomenna Ennusta seuraava sana lauseessa <p>Tip</p> <p>Joissakin kirjoissa/kursseissa k\u00e4sitell\u00e4\u00e4n ensin aikasarjat, toisissa kielelliset ongelmat. T\u00e4ll\u00e4 kursilla on valittu aloittaa kielellisist\u00e4 ongelmista, koska ne ovat intuitiivisia heti ensivilkaisulla: lauseiden k\u00e4\u00e4nt\u00e4mist\u00e4 kielest\u00e4 toiseen ja niin edelleen. Lis\u00e4ksi suurten kielimallin (LLM) suosion takia meill\u00e4 kaikilla on jokin kosketuspinta t\u00e4m\u00e4n tyypin koneoppimismalleihin loppuk\u00e4ytt\u00e4j\u00e4n n\u00e4k\u00f6kulmasta.</p>"},{"location":"kieli/rnn/#rnnn-perusidea","title":"RNN:n perusidea","text":"<p>\"A recurrent neural network (RNN) is a neural network that consists of a hidden state \\(h\\) and an optional output \\(y\\) which operates on a variable length sequence \\(x = (x_1, \\ldots, x_T)\\). At each time step \\(t\\), the hidden state \\(h_{t}\\) of the RNN is updated by ...\"</p> <p>\u2014 Cho et. al. <sup>2</sup></p> <p>Yll\u00e4 esitellyss\u00e4 kuvassa RNN:\u00e4\u00e4n kuuluivat verkon takaisinkytkent\u00e4\u00e4n liittyv\u00e4t pienet keltaiset laatikot. N\u00e4ist\u00e4 voi k\u00e4ytt\u00e4\u00e4 termi\u00e4 hidden state. Kuten kuvatekstiss\u00e4 sanottiin, n\u00e4m\u00e4 k\u00e4yt\u00e4nn\u00f6ss\u00e4 edustavat <code>accumulator</code>-muuttujaa loopissa. Tarkastellaan t\u00e4t\u00e4 lyhyen kuvitteellisen Python-toteutuksen avulla:</p> <pre><code># Hyperparametrit\nembedding_size = 4   # Embedding-vektorin pituus (d_x)\nhidden_size    = 3   # Hidden state -vektorin pituus (d_h)\n\n# Embedding on vektori, joka edustaa sanaa.\nvec_I    = [0.1, 0.2, 0.3, 0.4]   # sana \"I\"\n\n# Lauseet ovat listoja n\u00e4ist\u00e4 vektoreista:\n# \"I am not an\"      \u2192 4 sanaa \u2192 4 aika-askelta\n# \"I will not buy\"   \u2192 4 sanaa \u2192 4 aika-askelta\nsentence1, target1 = ([vec_I, vec_am,   vec_not, vec_an],  label_A)\nsentence2, target2 = ([vec_I, vec_will, vec_not, vec_buy], label_B)\nbatch = [(sentence1, target1), (sentence2, target2)]\n\nfor sentence, target in batch:\n    # Nollataan muisti jokaisen lauseen alussa!\n    hidden_state = [0] * hidden_size\n\n    for word_vector in sentence:\n        # Joka aika-askeleella RNN saa sy\u00f6tteeksi:\n        #   1) nykyisen sanan embedding-vektorin\n        #   2) edellisen aika-askeleen hidden staten\n        # ja palauttaa uuden hidden staten.\n        hidden_state = rnn_cell(word_vector, hidden_state)\n\n    # Silmukan j\u00e4lkeen hidden_state on tiivistelm\u00e4 koko lauseesta.\n    # T\u00e4m\u00e4n perusteella tehd\u00e4\u00e4n ennustus ja lasketaan virhe.\n    prediction = output_layer(hidden_state)\n    loss = loss_function(prediction, target)\n    # backpropagation kulkee kaikkien aika-askelten l\u00e4pi (BPTT)\n</code></pre> <p>Matemaattisesti sek\u00e4 koodina RNN-mallin yhden <code>rnn_cell</code>:n laskenta, jota lasketaan loopissa, on <sup>1</sup> <sup>3</sup>:</p> \\[ h^{(t)} = \\sigma(W \\cdot h^{(t-1)} + U \\cdot x^{(t)} + b) \\] <pre><code>def rnn_cell(x_t, h_prev):\n    h_part = W @ h_prev   # shapes: (d_h, d_h) @ (d_h,) \u2192 (d_h,)\n    x_part = U @ x_t      # shapes: (d_h, d_x) @ (d_x,) \u2192 (d_h,)\n\n    h_t = tanh(x_part + h_part + b)\n    return h_t\n</code></pre> <p>Muuttujat ovat selitettyn\u00e4 alla:</p> <ul> <li>\\(t\\) on aika-askel, joka vastaa sanan sijaintia lauseessa (\\(t=0, 1, 2, \\ldots\\)).</li> <li>\\(x^{(t)}\\) on sy\u00f6tevektori ajanhetkell\u00e4 \\(t\\) eli kyseisen sanan embedding. <ul> <li>Koko: \\(d_x\\) (embedding_size).</li> </ul> </li> <li>\\(h^{(t)}\\) on hidden state ajanhetkell\u00e4 \\(t\\). T\u00e4m\u00e4 on verkon \"muisti\". <ul> <li>Koko: \\(d_h\\) (hidden_size).</li> </ul> </li> <li>\\(h^{(t-1)}\\) on edellisen aika-askeleen hidden state. Alussa (\\(t=0\\)) t\u00e4m\u00e4 on tyypillisesti nollavektori.</li> <li>\\(W\\) on \\(d_h \\times d_h\\) painomatriisi, joka painottaa edellist\u00e4 hidden statea.</li> <li>\\(U\\) on \\(d_h \\times d_x\\) painomatriisi, joka painottaa nykyist\u00e4 sy\u00f6tevektoria.</li> <li>\\(b\\) on bias-vektori (koko \\(d_h\\)).</li> <li>\\(\\sigma\\) on aktivointifunktio, tyypillisesti tanh.</li> </ul> <p>Huomaa, ett\u00e4 \\(d_h\\) (hidden_size) on vapaasti valittava hyperparametri \u2014 se ei ole sama kuin lauseen pituus. Huomaa my\u00f6s, ett\u00e4 painomatriisit \\(W\\) ja \\(U\\) sek\u00e4 bias \\(b\\) ovat jaettuja painoja: samaa matriisia ja vektoria k\u00e4ytet\u00e4\u00e4n kaikissa aika-askeleissa.</p> <p>T\u00e4ss\u00e4 vaiheessa nohevilla opiskelijoilla on toivon mukaan kysymyksi\u00e4 mieliss\u00e4\u00e4n. Yksi selke\u00e4 kysymysaihio on, ett\u00e4 jos batch:n on oltava matriisi (joka kerrotaan painomatriisilla \\(U\\)), niin miten lauseet tai tekstit, jotka ovat eri mittaisia, mahtuvat samaan matriisiin? Juurihan yll\u00e4 todettiin, ett\u00e4 RNN ei vaadi tietyn mittaisia sy\u00f6tteit\u00e4. Naiivi vastaus olisi pit\u00e4\u00e4 <code>batch_size</code> 1:ss\u00e4 eli toteuttaa pedanttinen SGD. T\u00e4m\u00e4 on toki mahdollista, mutta ei tehokasta. </p> <p>Ratkaisu on lis\u00e4t\u00e4 t\u00e4ytett\u00e4 (PAD) sy\u00f6tteen loppuun. Yksitt\u00e4inen batch-Tensor on siis muotoa <code>(samples, sequence_length, features)</code>, miss\u00e4 <code>max_sentence_length</code> on suurimman samplen pituus batch:ss\u00e4, ja <code>features</code> on embedding. Alla on datasetti, jossa on muutamia sampleja. Ensimm\u00e4inen on kenties satu: \"Once (upon a ... and lived) happily ever after\". Toinen lienee Raamattu: \"Alussa (loi Jumala ... olkoon kaikkien) kanssa. Amen\". Alimmat n\u00e4kyv\u00e4t samplet ovat pari sanaa lyhyempi\u00e4, joten ne loppuvat keltaisella v\u00e4rill\u00e4 korostettuun <code>vec_PAD</code>-t\u00e4ytteeseen, joka on siis \\(d_x\\)-ulotteinen embedding siin\u00e4 miss\u00e4 kaikki muutkin tokenit. <sup>4</sup></p> t=0 ... t=max-2 t=max-1 t=max sample1 vec_Once ... vec_happily vec_ever vec_after sample2 vec_Alussa ... vec_kanssa vec_DOT vec_Amen sample3 vec_Turussa ... vec_END vec_PAD vec_PAD ... ... ... ... ... ... sampleN vec_Olipa ... vec_Loppu vec_PAD vec_PAD <p>Tip</p> <p>Jos haluat, voit tutustua PyTorchin torch.nn.utils.rnn.pad_packed_sequence funktioon. T\u00e4m\u00e4n k\u00e4ytt\u00f6\u00e4 k\u00e4sitell\u00e4\u00e4n G\u00e9ronin kirjassa luvussa 14. <sup>3</sup></p>"},{"location":"kieli/rnn/#ongelmatyypit-sekvenssidatalle","title":"Ongelmatyypit sekvenssidatalle","text":"<p>Alla oleva jako tyyppeihin on per\u00e4isin Andrej Karpathyn blogipostauksesta otsikolla The Unreasonable Effectiveness of Recurrent Neural Networks, joka on yksi RNN:n klassikkol\u00e4hteist\u00e4. Jaottelu on hyvin intuitiivinen ja auttaa hahmottamaan, millaisiin ongelmiin RNN:t sopivat. <sup>5</sup></p> <p></p> <p>Kuva 2: RNN-arkkitehtuurien taksonomia. <sup>5</sup> <sup>3</sup></p>"},{"location":"kieli/rnn/#vector-to-vector","title":"Vector-to-Vector","text":"<p>T\u00e4m\u00e4 taksonomian yksinkertaisin malli voidaan k\u00e4sitell\u00e4 hyvin lyhyesti: siit\u00e4 puuttuu hidden state ja koko <code>R</code>-kirjaimen tarkoittama recurrent -elementti. Sis\u00e4\u00e4n menee <code>d_x</code>-ulotteinen vektori ja ulos tulee <code>d_y</code>-ulotteinen vektori (tai skaalari). T\u00e4m\u00e4 on siis perinteinen feedforward-verkko eli kurssilta tuttu MLP. Se on k\u00e4yt\u00e4nn\u00f6ss\u00e4 mukana vain kuriositeettina. <sup>5</sup></p>"},{"location":"kieli/rnn/#sequence-to-vector","title":"Sequence-to-Vector","text":"<p>T\u00e4ss\u00e4 \"many-to-one\" -mallissa sy\u00f6tesekvenssi, kuten tekstilause tai \u00e4\u00e4nin\u00e4yte, k\u00e4sitell\u00e4\u00e4n aikasarjana ja tiivistet\u00e4\u00e4n yhdeksi tulosvektoriksi, jota k\u00e4ytet\u00e4\u00e4n tyypillisesti luokitteluteht\u00e4viss\u00e4, kuten tunneanalyysissa tai roskapostin tunnistuksessa. <sup>3</sup></p> <p>T\u00e4llaisen l\u00f6yd\u00e4t harjoituksesta <code>713_nvidia_language_model_embedding.py</code>. Vaikka malli inferenssivaiheessa tuottaa useita sanoja per\u00e4kk\u00e4in, arkkitehtuuri on many-to-one: se ennustaa aina yhden seuraavan sanan kerrallaan ja tulosta sy\u00f6tet\u00e4\u00e4n takaisin mallille (autoregressio).</p>"},{"location":"kieli/rnn/#vector-to-sequence","title":"Vector-to-Sequence","text":"<p>T\u00e4m\u00e4 \"one-to-many\" -arkkitehtuuri ottaa sy\u00f6tteen\u00e4\u00e4n yhden vektorin, esimerkiksi kuvan piirrevektorin, ja tuottaa siit\u00e4 sarjan tuloksia, mik\u00e4 on yleist\u00e4 esimerkiksi kuvatekstien automaattisessa generoinnissa, jossa kuvasta luodaan sanajono. <sup>5</sup> Toinen esimerkki voisi olla nimen generointi, jossa sy\u00f6tteen\u00e4 on henkil\u00f6n kotimaa (vektoroituna One-Hot -esityksen\u00e4) ja mallin tavoitteena on tuottaa sarja merkkej\u00e4, jotka muodostavat sukunimen. T\u00e4h\u00e4n liittyy my\u00f6hemmin teht\u00e4v\u00e4.</p>"},{"location":"kieli/rnn/#sequence-to-sequence","title":"Sequence-to-Sequence","text":"<p>T\u00e4m\u00e4 on many-to-many -malli, joka on Karparthyn sanoin synced sequence input and output. Toisin sanoen sis\u00e4\u00e4n menee \\(n\\)-mittarinen sekvenssi ja ulos tulee \\(n\\)-mittarinen sekvenssi \u2013 eli yht\u00e4 pitk\u00e4 sy\u00f6te ja tuloste. Sin\u00e4ns\u00e4 se siis on seq2seq, mutta k\u00e4yt\u00e4nn\u00f6ss\u00e4 t\u00e4t\u00e4 termi\u00e4 k\u00e4ytet\u00e4\u00e4n kokemukseni mukaan l\u00e4hinn\u00e4 sellaiseen malliin, jossa sy\u00f6te ja tuloste voivat olla eri mittaisia, kuten kielenk\u00e4\u00e4nn\u00f6ksess\u00e4. T\u00e4m\u00e4 on siis synced seq2seq, joka ei ole sama asia kuin encoder-decoder, joka esitell\u00e4\u00e4n alla.</p> <p>Esimerkkin\u00e4 many-to-many-malleista voisi olla videon kehysten luokittelu, jossa jokaiselle kehyssekvenssin kehykselle halutaan tuottaa luokitus <sup>5</sup>. Tai kenties sy\u00f6te on lista sanoja, ja ulos lista bin\u00e4\u00e4riluokittimen tuloksia, ett\u00e4 onko kyseinen sana verbi.</p>"},{"location":"kieli/rnn/#encoder-decoder","title":"Encoder-Decoder","text":"<p>Warning</p> <p>T\u00e4m\u00e4 on kurssin kannalta edistynyt k\u00e4site, ja sit\u00e4 k\u00e4sitell\u00e4\u00e4n G\u00e9ronin kirjassa koko luku 14. T\u00e4m\u00e4n 5 opintopisteen kurssin puitteissa emme ehdi syventy\u00e4 t\u00e4h\u00e4n aiheeseen. K\u00e4sitell\u00e4\u00e4n se vain maininnan tasolla. Harjoituksessa <code>712_seq2seq_translation_tutorial.py</code> tutustut t\u00e4h\u00e4n koodin kautta.</p> <p>Jos haluat tutustua aiheeseen syvemmin kurssin laajuuden ulkopuolella, esimerkiksi projektien yhteydess\u00e4, voit aloittaa lukemalla G\u00e9ronin kirjan loppuun ja tutustumalla julkaisuihin, joita kyseinen PyTorch tutoriaali suosittelee. Etsi sivulta v\u00e4liotsikko \"Recommended Reading\".</p> <p>Encoder-Decoder on toteutustavaltaan Sequence-to-Sequence -malli, mutta synced-ominaisuus on poistettu. Arkkitehtuuri on t\u00e4ten kaksivaiheinen: ensin Encoder lukee koko sy\u00f6tteen (esim. englanninkielisen lauseen) ja tiivist\u00e4\u00e4 sen yhdeksi kontekstivektoriksi (state), jonka j\u00e4lkeen Decoder purkaa tuon vektorin halutuksi tulosteeksi (esim. ranskankieliseksi lauseeksi), mahdollistaen n\u00e4in sy\u00f6tteen ja tulosteen eroavat pituudet ja irrelevanssin aikaj\u00e4rjestyksen suhteen. <sup>3</sup> Termist\u00f6n suhteen huomio, ett\u00e4 encoder-decoder v\u00e4liss\u00e4 vektori tunnetaan monilla nimill\u00e4. Voit t\u00f6rm\u00e4t\u00e4 ainakin seuraaviin termeihin: context vector, state vector, thought vector, latent vector.</p> <p>Arkkitehtuurissa on seq2vec -malli, encoder, jonka per\u00e4\u00e4n on kytketty vec2seq -malli, decoder. Encoder lukee koko sy\u00f6tteen ja tiivist\u00e4\u00e4 sen yhdeksi vektoriksi, joka tunnetaan nimell\u00e4 context vector. Yll\u00e4 (Kuvassa 2) vain Encoder-osuus saa sy\u00f6tteen: t\u00e4m\u00e4 johtuu siit\u00e4, ett\u00e4 piirroksessa kyseess\u00e4 on ulkoinen sy\u00f6te. Decoder toki saa sy\u00f6tteen, mutta se on oma edellisen aika-askeleensa ennuste. Koulutusvaiheessa Decoder saa toki ulkoisen sy\u00f6tteen (eli ground-truth-sekvenssin). T\u00e4m\u00e4 liittyy teacher forcing -tekniikkaan, jossa mallia ohjataan oikeaan suuntaan sy\u00f6tt\u00e4m\u00e4ll\u00e4 sille oikeat vastaukset, kun taas inferenssivaiheessa malli joutuu luottamaan omiin ennusteisiinsa. <sup>4</sup></p> <p>Danger</p> <p>Sekaannusvaara, taas.</p> <ul> <li>Synced many-to-many: Joka aika-askeleella tuotetaan output (esim. NER-taggaus, videon kehysluokittelu). T\u00e4m\u00e4 ei ole encoder-decoder.</li> <li>Encoder-Decoder: Encoder lukee ensin koko sy\u00f6tteen, sitten decoder tuottaa tulosteen. Sy\u00f6te ja tuloste voivat olla eri pituisia. Konvention mukaan t\u00e4m\u00e4 on synonyymi seq2seq:lle.</li> </ul> <p>Encoder-Decoder voidaan toteuttaa kahdella erillisell\u00e4 <code>nn.Module</code>-luokalla, kuten <code>EncoderRNN</code> ja <code>DecoderRNN</code> (ks. <code>712_seq2seq_translation_tutorial.py</code>), tai yhdell\u00e4 luokalla, jossa encoder- ja decoder-vaiheet ovat saman <code>forward()</code>-metodin sis\u00e4ll\u00e4. Se, onko tai eik\u00f6 ole kahta eri luokkaa, ei yksin m\u00e4\u00e4rittele arkkitehtuuria \u2014 ero syntyy siit\u00e4, onko kyseess\u00e4 synced vai unsynced many-to-many.</p>"},{"location":"kieli/rnn/#rnnn-koulutus","title":"RNN:n koulutus","text":""},{"location":"kieli/rnn/#unrolling","title":"Unrolling","text":"<p>Yll\u00e4 k\u00e4ytetty <code>for</code>-loop on vastavirta eli backpropagation algoritmin kannalta huono. Muuttuja <code>hidden_state</code> on akkumulaattori, joka ylikirjoitetaan joka aika-askeleella, joten menneiden aika-askelten aktivointeja ei ole tallessa. RNN:n koulutuksessa k\u00e4ytet\u00e4\u00e4nkin unrolling -tekniikkaa, jossa verkko \"puretaan\" useiksi kopioiksi, jotka on kytketty toisiinsa. Kuinka useaksi kopioksi? Batchen suurimman sekvenssin pituuden verran. <sup>1</sup> <sup>3</sup></p> <p></p> <p>Kuva 3: RNN:n \"unrolling\" eli purkaminen. Katkoviivat edustavat sit\u00e4, ett\u00e4 verkko voi olla jonkin yll\u00e4mainitun taksonomien mukainen. Kustakin RNN-solusta l\u00e4htev\u00e4 arvo joko osallistuu tai ei osallistu lopulliseen l\u00e4ht\u00f6\u00f6n, riippuen siit\u00e4, mink\u00e4 tyyppisest\u00e4 ongelmasta on kyse. <sup>1</sup> <sup>3</sup></p>"},{"location":"kieli/rnn/#bptt","title":"BPTT","text":"<p>Kun verkko on avattu, se on tavallinen feedforward-verkko. Voimme siis k\u00e4ytt\u00e4\u00e4 tavallista backpropagation-algoritmia. Termi t\u00e4lle koko strategialle on Backpropagation Through Time (BPTT). Algoritmi on siis sama kuin ennenkin, mutta koska prosessiin liittyy temporaalinen elementti, sille on annettu nimi. <sup>1</sup> <sup>3</sup></p> <p></p> <p>Kuva 4: Muista, ett\u00e4 RNN on vain lineaarinen verkko, joka on avattu useiksi kopioiksi. Meill\u00e4 on yh\u00e4 jokin loss function, jonka haluamme minimoida, ja usein ennen t\u00e4t\u00e4 on Linear-kerros, joka muuttaa hidden state -vektorin halutun kokoiseksi outputiksi.</p>"},{"location":"kieli/rnn/#rajoitteet-ja-ongelmat","title":"Rajoitteet ja ongelmat","text":"<p>Syv\u00e4t verkot k\u00e4rsiv\u00e4t ongelmasta vanishing ja exploding gradient, johon olet t\u00f6rm\u00e4nnyt kurssin teht\u00e4viss\u00e4 aiemmin. Kun luku kerrotaan useita kertoja per\u00e4kk\u00e4in <code>&lt; 1</code> luvulla, kuten vaikka <code>0.25</code>, luku l\u00e4hestyy nollaa. Jos se kerrotaan useita kertoja <code>&gt; 1</code> luvulla, kuten <code>1.25</code>, luku kasvaa eksponentiaalisesti. RNN:ss\u00e4 t\u00e4m\u00e4 tapahtuu, koska sama painomatriisi, \\(W\\) tai \\(U\\), kerrotaan useita kertoja per\u00e4kk\u00e4in. Jos RNN:st\u00e4 tekee syv\u00e4n, kuten alla olevassa kuvassa, ongelma luonnollisesti pahenee. <sup>1</sup></p> <p></p> <p>Kuva 5: Monikerroksinen RNN. Violetilla ja punaisella v\u00e4rill\u00e4 on korostettu sit\u00e4, ett\u00e4 kaikki saman kerroksen neuronit jakavat \\(W_k\\) painon, kuten my\u00f6s \\(U_k\\) painon.<sup>1</sup> <sup>3</sup></p> <p>Syvyyden lis\u00e4\u00e4minen RNN:\u00e4\u00e4n pahentaa entisest\u00e4\u00e4n vanishing ja exploding gradient -ongelmia, jotka ovat RNN:n suurimpia haasteita. Kuvittele, ett\u00e4 haluat selvitt\u00e4\u00e4 \\(U_1\\):n eli ensimm\u00e4isen kerroksen jaettua painomatriisia, jolla \\(x^{(t)}\\) kerrotaan. T\u00e4m\u00e4 matriisi on mukana jokaisessa kerroksessa, joten gradientti kulkee l\u00e4pi kaikkien kerrosten, mik\u00e4 tarkoittaa, ett\u00e4 se kerrotaan useita kertoja per\u00e4kk\u00e4in. <sup>1</sup></p>"},{"location":"kieli/rnn/#ongelmien-mitigointi","title":"Ongelmien mitigointi","text":"<p>Alla on Learning Deep Learning -kirjan <sup>1</sup> taulukon suomennettu ja tiivistetty versio, jossa on esiteltyn\u00e4 yleisi\u00e4 tapoja yritt\u00e4\u00e4 mitigoida katoavia (engl. vanishing) ja r\u00e4j\u00e4ht\u00e4vi\u00e4 (engl. exploding) gradientteja RNN:iss\u00e4. Se, auttaako kyseinen tekniikka katoaviin vai r\u00e4j\u00e4ht\u00e4viin gradientteihin, on merkitty taulukossa emojein.</p> Tekniikka Katoava R\u00e4j\u00e4ht\u00e4v\u00e4 Huomiot Glorot tai He valinta \u2705 \u26d4 Riippuu aktivointifunktiosta. Batch Normalization \u2705 \u26d4 Puree piilotettuihin kerroksiin Ei-saturoituva aktivointi \u2705 \u26d4 Esim. ReLU Gradient Clipping \u26d4 \u2705 Puree kaikkiin kerroksiin CEC + Portit \u2705 \u2705 Lue alta LSTM:n kohdalta lis\u00e4\u00e4"},{"location":"kieli/rnn/#kehittyneemmat-rnn-arkkitehtuurit","title":"Kehittyneemm\u00e4t RNN-arkkitehtuurit","text":""},{"location":"kieli/rnn/#lstm","title":"LSTM","text":"<p>Hochreiter ja Schmidhuberin vuonna 1997 esittelem\u00e4 LSTM on RNN-variantti, joka on suunniteltu kevent\u00e4m\u00e4\u00e4n RNN:n vanishing gradient -ongelmaa sek\u00e4 parantamaan pitk\u00e4aikaista muistin s\u00e4ilytt\u00e4mist\u00e4. R\u00e4j\u00e4ht\u00e4v\u00e4t ja katoavat gradientit ovat oire siit\u00e4, ett\u00e4 \\(W\\)-painomatriisin arvot ovat erisuuria kuin \\(1\\). Ekman kirjoittaa: \"[...] with a large enough number of timesteps, the only way to avoid vanishing and exploding gradients is to use weights with a value of 1, which kind of defeats the purpose because we want to be able to adjust the weights\" <sup>1</sup>. Mallin kouluttamisen idea on s\u00e4\u00e4t\u00e4\u00e4 painoja, joten painojen pit\u00e4minen kiinte\u00e4sti arvossa 1 ei ole ratkaisu. T\u00e4st\u00e4 \u00e4\u00e4rimm\u00e4isen naiivista ajatuksesta on kuitenkin johdettavissa constant error carousel -tekniikka, joka on LSTM:n ydin. <sup>6</sup> Julkaisun tiivistelm\u00e4ss\u00e4 t\u00e4m\u00e4 avataan n\u00e4in: \"Multiplicative gate units learn to open and close access to the constant error flow\" <sup>6</sup>. Tyypillisen LSTM-solun kuvauksen sijasta, joka l\u00f6ytyy vaikkapa G\u00e9ronin kirjasta, alla on kuva, jossa korostetaan, kuinka kaksi LSTM-solua kytkeytyv\u00e4t toisiinsa. Kuvaa kannattaa tuijottaa siten, ett\u00e4 sinulla on saatavilla my\u00f6s tyypillinen LSTM-solun kuva (esim. Figure 13-12 G\u00e9ronin kirjasta). My\u00f6s alkuper\u00e4isen julkaisun Figure 1 on hy\u00f6dyllinen ymm\u00e4rryksen apuna, mutta sen kohdalla on syyt\u00e4 huomioida, ett\u00e4 esitelty malli on naiivi LSTM, jossa cell state -yhteyden paino on kiinte\u00e4sti 1 (constant error carousel), eli cell state kulkee muuttumattomana eteenp\u00e4in ilman kertoimen vaikutusta. <sup>6</sup> Alkuper\u00e4isest\u00e4 1997 LSTM:st\u00e4 et my\u00f6sk\u00e4\u00e4n l\u00f6yd\u00e4 forget gate -mekanismia, joka on my\u00f6hemmin lis\u00e4tty LSTM:\u00e4\u00e4n. <sup>7</sup></p> <p></p> <p>Kuva 6: LSTM-arkkitehtuuri. Kuvassa on kaksi LSTM-solua. Kuvaaja pyrkii yhdist\u00e4m\u00e4\u00e4n eri l\u00e4hteist\u00e4 vastaavien kuvaajien parhaat puolet <sup>3</sup> <sup>1</sup> <sup>6</sup>. Oikeanpuoleiseen soluun on merkitty pienin numeroin, <code>(1)...(6)</code>, vaiheet, jotka ovat alla matemaattisina kaavoina.</p> <p>LSTM:ss\u00e4 on kolme porttia ja lis\u00e4ksi candidate, jotka kaikki tuottavat \\(d_h\\) ulotteisia vektoreita, jotka osallistuvat laskentaan. Yhdess\u00e4 n\u00e4m\u00e4 nelj\u00e4 ovat:</p> <ul> <li>Forget gate: P\u00e4\u00e4t\u00f6s siit\u00e4, mit\u00e4 tietoa vanhasta cell state -vektorista s\u00e4ilytet\u00e4\u00e4n tai unohdetaan. K\u00e4ytet\u00e4\u00e4n sigmoid-aktivointia, joka tuottaa arvoja v\u00e4lill\u00e4 0 (unohtaa kaiken) ja 1 (s\u00e4ilytt\u00e4\u00e4 kaiken). <sup>3</sup></li> <li>Input gate: P\u00e4\u00e4t\u00f6s siit\u00e4, mit\u00e4 uutta tietoa sy\u00f6tteest\u00e4 lis\u00e4t\u00e4\u00e4n cell state -vektoriin. <sup>3</sup></li> <li>Output gate: P\u00e4\u00e4t\u00f6s siit\u00e4, mit\u00e4 tietoa cell state -vektorista k\u00e4ytet\u00e4\u00e4n nykyisen aika-askeleen outputiksi. <sup>3</sup></li> <li>Candidate: Tuottaa ehdotetun uuden informaation, joka voidaan lis\u00e4t\u00e4 cell state -vektoriin, perustuen nykyiseen sy\u00f6tteeseen ja edelliseen hidden stateen. <sup>1</sup></li> </ul> <p>Kuvasta ja l\u00e4hteist\u00e4 voi koostaa, ett\u00e4:</p> <ul> <li>LSTM-solut jakavat nelj\u00e4 painomatriisia: \\(W_f\\), \\(W_i\\), \\(W_o\\) ja \\(W_c\\). <sup>1</sup> <sup>3</sup></li> <li>\\(h\\) on hidden state vektori, jonka pituus on \\(d_h\\). <sup>1</sup> <sup>3</sup></li> <li>\\(c\\) on cell state vektori, joka toimii LSTM:n muistina, ja sen pituus on jaettu \\(h\\):n kanssa, eli \\(d_h\\). <sup>1</sup> <sup>3</sup></li> <li>\\(x\\) on sy\u00f6tevektori, jonka pituus on \\(d_x\\) (embedding_size).<ul> <li>On mahdollista tehd\u00e4 <code>concat(x, h)</code> ja k\u00e4ytt\u00e4\u00e4 t\u00e4t\u00e4 yhdistetty\u00e4 vektoria sy\u00f6tteen\u00e4 porttien laskentaan, jolloin painomatriisit \\(W_f\\), \\(W_i\\), \\(W_o\\) ja \\(W_c\\) olisivat muotoa \\((d_h + d_x) \\times d_h\\). <sup>1</sup></li> </ul> </li> <li>Muistin tarve skaalautuu \\(d_h\\) ja embedding-koon, \\(d_x\\), mukaan.</li> </ul> <p>Aiheeseen liittyvi\u00e4 kuvaajia ja selostusta l\u00f6ytyy netist\u00e4 reilusti. Yksi hyv\u00e4 l\u00e4hde on vastavirta-algoritmeista tuttu Christopher Olah. H\u00e4nen blogistaan l\u00f6yd\u00e4t kenties tyypillisimm\u00e4n tavan abstrahoida LSTM:n <sup>8</sup> \u2013 saman, jota G\u00e9ron k\u00e4ytt\u00e4\u00e4 kirjassaan \u2013 merkinn\u00e4st\u00e4 Understanding LSTM Networks</p> <p>LSTM on k\u00e4ytetyin RNN-variantti: sen hy\u00f6dyt ovat pitk\u00e4lti samat kuin RNN:n, mutta cell state ja gating -mekanismien ansiosta se kykenee paremmin s\u00e4ilytt\u00e4m\u00e4\u00e4n tietoa pitkiss\u00e4 sekvensseiss\u00e4. <sup>9</sup></p> <p>Matemaattiset kaavat</p> \\[ \\begin{align} f^{(t)} &amp;= \\sigma( W_f [ h^{(t-1)}, x^{(t)} ] + b_f ) \\tag{1} \\\\ i^{(t)} &amp;= \\sigma( W_i [ h^{(t-1)}, x^{(t)} ] + b_i ) \\tag{2} \\\\ \\tilde{C}^{(t)} &amp;= \\tanh ( W_c [ h^{(t-1)}, x^{(t)} ] + b_c ) \\tag{3} \\\\ C^{(t)} &amp;= f^{(t)} * C^{(t-1)} + i^{(t)} * \\tilde{C}^{(t)} \\tag{4} \\\\ o^{(t)} &amp;= \\sigma( W_o [ h^{(t-1)}, x^{(t)} ] + b_o ) \\tag{5} \\\\ h^{(t)} &amp;= o^{(t)} * \\tanh ( C^{(t)} ) \\tag{6} \\end{align} \\] <p>Yll\u00e4 olevat kaavat ovat kirjasta Learning Deep Learning <sup>1</sup>. L\u00f6yd\u00e4t G\u00e9ronin kirjasta vastaavat kaavat, mutta niiss\u00e4 on ei ole k\u00e4ytetty <code>concatenate</code>-tekniikkaa, joten painomatriiseja on tuplam\u00e4\u00e4r\u00e4 <sup>3</sup>. Kaavojen numerot vastaavat seuraavia vaiheita, ja ne on merkitty yll\u00e4 olevaan kuvaan (Kuva 6).</p>"},{"location":"kieli/rnn/#gru","title":"GRU","text":"<p>Kyunghyun Cho ja kollegat esitteliv\u00e4t GRU-arkkitehtuurin 2014 <sup>2</sup>. GRU on k\u00e4yt\u00e4nn\u00f6ss\u00e4 yksinkertaistettu LSTM, joka yksinkertaisuudestaan huolimatta suoriutuu LSTM:\u00e4\u00e4n verrattavalla tavalla <sup>3</sup>. Alkuper\u00e4inen Cho:n ja kumppaneiden julkaisu ei sis\u00e4ll\u00e4 lyhennett\u00e4 GRU laisinkaan. Julkaisun aihe on seq2seq Encoder-Decoder -arkkitehtuuri, mutta ik\u00e4\u00e4n kuin kylki\u00e4isen\u00e4 esitell\u00e4\u00e4n t\u00e4m\u00e4 uusi yksinkertaistettu LSTM-variaatio:</p> <p>\"In addition to a novel model architecture, we also propose a new type of hidden unit (f in Eq. (1)) that has been motivated by the LSTM unit but is much simpler to compute and implement\"</p> <p>\u2014 Cho et. al. <sup>2</sup></p>"},{"location":"kieli/rnn/#tehtavat","title":"Teht\u00e4v\u00e4t","text":"<p>Teht\u00e4v\u00e4: RNN videoiden avulla</p> <p>Jos yll\u00e4 oleva selostus ei selkeytt\u00e4nyt aihetta, etsi my\u00f6s muita l\u00e4hteit\u00e4. </p> <ul> <li>Yksi ehdotus on Lex Fridmanin MIT 6.S094: Recurrent Neural Networks for Steering Through Time-luento, joka on saatavilla YouTubessa. Videon alku on kertausta vastavirta-algoritmista, joten voit hyp\u00e4t\u00e4 suoraan 36:04 kohtaan, josta RNN:t alkavat. Erityisesti videon lopun Application-osiot ovat varsin korvaamattoman tasokasta sis\u00e4lt\u00f6\u00e4.</li> <li>My\u00f6s StatQuestin soittolista Neural Networks / Deep Learning sis\u00e4lt\u00e4\u00e4 useita videoita, joissa k\u00e4sitell\u00e4\u00e4n esim.:<ul> <li>RNN</li> <li>LSTM</li> <li>Word2Vec (viime viikon aihe)</li> <li>Seq2Seq Encoder-Decoder</li> <li>Attention</li> </ul> </li> </ul> <p>Teht\u00e4v\u00e4: Sukunimien luokittelu Pt.1</p> <p>Avaa Marimo Notebook <code>710_...py</code> ja tutustu koodiin. Kyseess\u00e4 on NLP From Scratch: Classifying Names with a Character-Level RNN-tutoriaali PyTorchin dokumentaatiosta, joka on k\u00e4\u00e4nnetty Marimo-malliin sopivaksi. Suorita koodi ja tarkastele tuloksia.</p> <p>Mallin koulutus vei Macbook Pro:lla MPS:\u00e4\u00e4 k\u00e4ytt\u00e4en 12 minuuttia. CUDA-PC:ll\u00e4 koulutus meni 2 minuutissa.</p> <p>Teht\u00e4v\u00e4: Sukunimien luokittelu Pt.2</p> <p>Palaa aiempaan <code>710</code>-alkuiseen Notebookiin. Kouluta malli uusiksi siten, ett\u00e4 se ymm\u00e4rt\u00e4\u00e4 my\u00f6s suomalaisia sukunimi\u00e4. K\u00e4yt\u00e4 t\u00e4ss\u00e4 apuna Avoidata.fi-palvelusta l\u00f6ytyv\u00e4\u00e4 Digi- ja v\u00e4est\u00f6viraston julkaisemaa datasetti\u00e4 V\u00e4est\u00f6tietoj\u00e4rjestelm\u00e4n suomalaisten nimiaineistot (CC BY). Tee siis seuraavat:</p> <ol> <li>Lataa Excel-tiedosto</li> <li>Valitse kaikki sukunimet, joita on 700 tai yli</li> <li>Kopioi valitut leikep\u00f6yd\u00e4lle</li> <li>Liit\u00e4 tiedostoon <code>data/names/Finnish.txt</code></li> </ol> <p>Nyt sinulle pit\u00e4isi olla datasetiss\u00e4 uusi label <code>Finnish</code>, joka sis\u00e4lt\u00e4\u00e4 toista tuhatta suomenkielist\u00e4 sukunime\u00e4. Kouluta malli uudestaan, kenties eri tiedostonimell\u00e4, ja tarkastele tuloksia. Tunnistaako se sinut oikein? Mahdoitko olla training- vai test-datassa vai et kummassakaan?</p> <p>Teht\u00e4v\u00e4: Sukunimien generointi</p> <p>Tutustu <code>711_char_rnn_generation_tutorial.py</code>-tiedostoon, joka on Marimo-muotoon k\u00e4\u00e4nnetty versio NLP From Scratch: Generating Names with a Character-Level RNN-tutoriaalista. T\u00e4ss\u00e4 tutoriaalissa k\u00e4ytet\u00e4\u00e4n samaa dataa kuin edellisess\u00e4, mutta nyt mallin tavoite on generoida uusia sukunimi\u00e4 eri kielille. Tutustu Notebookin koodiin ja selvit\u00e4, kuinka malli koulutetaan ja kuinka sit\u00e4 kutsutaan. Muista, ett\u00e4 tarkoituksena ei ole pelk\u00e4st\u00e4\u00e4n ajaa koodia, vaan ymm\u00e4rt\u00e4\u00e4, miten se toimii. Tee t\u00e4m\u00e4 ymm\u00e4rrys n\u00e4kyv\u00e4ksi oppimisp\u00e4iv\u00e4kirjassasi.</p> <p>Huomaa, ett\u00e4 dataset on sama kuin edellisess\u00e4 teht\u00e4v\u00e4ss\u00e4, joten sinun \u00e4skett\u00e4in lis\u00e4\u00e4m\u00e4si suomalaiset sukunimet ovat nyt mukana my\u00f6s t\u00e4ss\u00e4 mallissa. Generointiin voit k\u00e4ytt\u00e4\u00e4 Notebookissa olevia valmiita funktioita:</p> <pre><code>samples('Finnish', 'ABCDEFGHIJKL')\nArtinen\nBartanen\nCharinen\nDantalak\nEantara\nFintanen\n# + ???\n</code></pre> <p>Malli kouluttautui opettajan Macbook Pro:lla noin 1 minuutissa.</p> <p>Teht\u00e4v\u00e4: Konek\u00e4\u00e4nn\u00f6s (Seq2Seq + Attention)</p> <p>Tutustu <code>712_seq2seq_translation_tutorial.py</code>-tiedostoon, joka on Marimo-muotoon k\u00e4\u00e4nnetty versio NLP From Scratch: Translation with a Sequence to Sequence Network and Attention-tutoriaalista. T\u00e4ss\u00e4 teht\u00e4v\u00e4ss\u00e4 rakennetaan neuroverkko, joka k\u00e4\u00e4nt\u00e4\u00e4 ranskaa englanniksi.</p> <p>Malli hy\u00f6dynt\u00e4\u00e4 Sequence to Sequence (seq2seq) -arkkitehtuuria, jossa kaksi RNN-verkkoa toimivat yhdess\u00e4: toinen enkoodaa sy\u00f6tteen ja toinen dekoodaa sen k\u00e4\u00e4nn\u00f6kseksi. T\u00e4m\u00e4n lis\u00e4ksi mallissa k\u00e4ytet\u00e4\u00e4n Attention-mekanismia, joka antaa dekooderin keskitty\u00e4 sy\u00f6tteen tiettyihin osiin k\u00e4\u00e4nn\u00f6st\u00e4 generoidessaan. Attention k\u00e4yd\u00e4\u00e4n l\u00e4pi tarkemmin seuraavassa Transformers-osiossa, joten voit palata silt\u00e4 osin t\u00e4h\u00e4n Notebookiin my\u00f6hemmin.</p> <p>Teht\u00e4v\u00e4n\u00e4si on suorittaa Notebook, tutustua koodiin ja varmistaa, ett\u00e4 ymm\u00e4rr\u00e4t Attention-mekanismin perusperiaatteen.</p> <p>Malli kouluttautui opettajan Macbook Pro:lla noin 8 minuutissa.</p> <p>Teht\u00e4v\u00e4: Kielimalli ja sanaulottuvuudet</p> <p>Tutustu <code>713_nvidia_language_model_embedding.py</code>-tiedostoon. T\u00e4m\u00e4 on muokattu versio NVIDIA:n Learning Deep Learning -kirjan (ja videosarjan) esimerkist\u00e4. Teht\u00e4v\u00e4ss\u00e4 koulutetaan LSTM-pohjainen kielimalli, joka ennustaa seuraavaa sanaa annetun kontekstin perusteella. Samalla malli oppii sanaulottuvuudet (word embeddings).</p> <p>Teht\u00e4v\u00e4n\u00e4si on suorittaa Notebook ja tutustua koodiin. Kiinnit\u00e4 erityisesti huomiota siihen, miten mallin oppimia embedding-vektoreita voidaan lopuksi hy\u00f6dynt\u00e4\u00e4 etsim\u00e4ll\u00e4 sanoille merkityksellisesti l\u00e4himpi\u00e4 naapureita vektoriavaruudessa.</p> <p>Malli kouluttautui opettajan Macbook Pro:lla noin 4 minuutissa CPU:lla ja 50 sekunnissa MPS:ll\u00e4.</p> <p>Tip</p> <p>Huomaa, ett\u00e4 t\u00e4m\u00e4 ei siis ole encoder-decoder -malli vaan iteratiivisesti ajettu seq2vec. Jos haluat tutustua Magnus Ekmanin versioon encoder-decoder -arkkitehtuurista, joka on toteutettu LSTM:ll\u00e4, voit tutustua LDL:n repositoriosta l\u00f6ytyv\u00e4\u00e4n v7_3_neural_machine_translation.ipyn Jupyter Notebookiin. Malli on vastaava kuin <code>712_seq2seq_translation_tutorial.py</code>-tiedostossa, mutta kohtalaisen tiiviill\u00e4 koodilla toteutettu.</p>"},{"location":"kieli/rnn/#lahteet","title":"L\u00e4hteet","text":"<ol> <li> <p>Ekman, M. Learning Deep Learning: Theory and Practice of Neural Networks, Computer Vision, NLP, and Transformers using TensorFlow. Addison-Wesley. 2025.\u00a0\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9</p> </li> <li> <p>Cho, K., van Merri\u00ebnboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H., &amp; Bengio, Y. Learning phrase representations using RNN encoder-decoder for statistical machine translation. 2014. https://arxiv.org/abs/1406.1078\u00a0\u21a9\u21a9\u21a9</p> </li> <li> <p>G\u00e9ron, A. Hands-On Machine Learning with Scikit-Learn and PyTorch. O'Reilly. 2025.\u00a0\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9</p> </li> <li> <p>Raschka, S. Build a Large Language Model (From Scratch). Manning. 2024.\u00a0\u21a9\u21a9</p> </li> <li> <p>Karpathy, A. \"The Unreasonable Effectiveness of Recurrent Neural Networks\". 2015. https://karpathy.github.io/2015/05/21/rnn-effectiveness/\u00a0\u21a9\u21a9\u21a9\u21a9\u21a9</p> </li> <li> <p>Hochreiter, S., &amp; Schmidhuber, J. (1997). Long short-term memory. Neural computation. 1997. https://deeplearning.cs.cmu.edu/S23/document/readings/LSTM.pdf\u00a0\u21a9\u21a9\u21a9\u21a9</p> </li> <li> <p>Gers, F. A., Schmidhuber, J., &amp; Cummins, F. Learning to forget: Continual prediction with LSTM. Neural computation. 2000. doi: 10.1049/cp:19991218\u00a0\u21a9</p> </li> <li> <p>Olah, C. Understanding LSTM Networks. 2015. https://colah.github.io/posts/2015-08-Understanding-LSTMs/\u00a0\u21a9</p> </li> <li> <p>Dancker, J. A Brief Introduction to Recurrent Neural Networks. Towards Data Science. 2022. https://towardsdatascience.com/a-brief-introduction-to-recurrent-neural-networks-638f64a61ff4/\u00a0\u21a9</p> </li> </ol>"},{"location":"kieli/transformers/","title":"Transformers","text":"<p>Aloitetaan t\u00f6ks\u00e4ytt\u00e4m\u00e4ll\u00e4 heti alkuun m\u00e4\u00e4ritelm\u00e4 siit\u00e4, mik\u00e4 transformer on: se on Attention is All You Need-artikkelissa vuonna 2017 esitelty neuroverkkopohjainen arkkitehtuuri, joka on suunniteltu erityisesti k\u00e4sittelem\u00e4\u00e4n kielt\u00e4, mutta arkkitehtuuri on sittemmin taipunut my\u00f6s muun datan k\u00e4sittelyyn. Artikkelin tiivistelm\u00e4 kertoo paljon:</p> <p>\"We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train.\"</p> <p>\u2013 Ashish Vaswani et. al. <sup>1</sup></p> <p>Danger</p> <p>Termeiss\u00e4 sekaannusvaara. Yleisesti k\u00e4ytetty Hugging Facen Python-kirjasto on nimelt\u00e4\u00e4n <code>transformers</code>, mutta se ei ole sama asia kuin transformer-arkkitehtuuri. Hugging Facen <code>transformers</code>-kirjasto on nimetty sen mukaan, ett\u00e4 se tarjoaa ty\u00f6kaluja transformer-pohjaisten mallien rakentamiseen ja hy\u00f6dynt\u00e4miseen.</p>"},{"location":"kieli/transformers/#motivaatio-rnnn-haasteet","title":"Motivaatio: RNN:n haasteet","text":"<p>\"The big limitation of encoder\u2013decoder RNNs is that the RNN can\u2019t directly access earlier hidden states from the encoder during the decoding phase. Consequently, it relies solely on the current hidden state, which encapsulates all relevant information. This can lead to a loss of context, especially in complex sentences where dependencies might span long distances.\"</p> <p>\u2014 Sebastian Raschka <sup>2</sup></p> <p>Edellisess\u00e4 luvussa opit, ett\u00e4 LSTM ja GRU mallit paikkasivat RNN:n ongelmia, mutta eiv\u00e4t t\u00e4ysin ratkaisseet niit\u00e4. Erityisesti pitk\u00e4t riippuvuudet ja kontekstin vaikutus sanan merkitykseen aiheuttivat haasteita. Palaako se kuusi vai palaako kuusi? J\u00e4\u00e4neit\u00e4 ongelmia olivat siis ainakin <sup>3</sup>:</p> <ul> <li>Kohdistus (engl. alignment): K\u00e4\u00e4nn\u00f6ksess\u00e4 eri kielten sanaj\u00e4rjestys ja rakenteet vaativat kohdennusta. Esimerkiksi <code>the cat</code> kummatkin sanat viittaavat suomenkielisess\u00e4 k\u00e4\u00e4nn\u00f6ksess\u00e4 many-to-one -hengess\u00e4 sanaan <code>kissa</code>.</li> <li>Katoavat tai r\u00e4j\u00e4ht\u00e4v\u00e4t gradientit: Vaikka LSTM toi ratkaisuja, ongelma ei poistunut.</li> <li>Ei-parallelisoitavuus: RNN:n aikaisemmat tilat vaikuttavat nykyiseen tilaan, mik\u00e4 est\u00e4\u00e4 tehokkaan rinnakkaisprosessoinnin.</li> </ul> <p>Transformer-arkkitehtuuri, esitelty vuonna 2017, mullisti t\u00e4t\u00e4 siten, ett\u00e4 attention-mekanismilla korvattiin recurrence eli RNN:st\u00e4 tuttu syklisyys kokonaan. <sup>4</sup> Attention ei itsess\u00e4\u00e4n ole uusi keksint\u00f6: voit kurkata siihen liittyv\u00e4\u00e4 historiaa Attention (machine learning)-Wikipedia-artikkelista. Tutustutaan alla tarkemmin siihen, mit\u00e4 attention on.</p>"},{"location":"kieli/transformers/#attention","title":"Attention","text":"<p>On hyv\u00e4 pohtia heti alkuun motivaatiota: miksi tarvitsemme attentionia? Olet tutustunut RNN:n kohdalla encoder-decoder-arkkitehtuuriin, jossa encoderin teht\u00e4v\u00e4n\u00e4 on tiivist\u00e4\u00e4 koko sy\u00f6tesekvenssi yhdeksi vektoriksi, joka sitten dekoodataan tulosteeksi. T\u00e4m\u00e4n tiivistyksen tulisi sis\u00e4lt\u00e4\u00e4 kaikki oleennainen informaatio sy\u00f6tteest\u00e4. <sup>5</sup></p> <pre><code>graph LR\n    A[Input Sequence] --&gt; B[Encoder RNN]\n    B --&gt; C[Context Vector]\n    C --&gt; D[Decoder RNN]\n    D --&gt; E[Output Sequence]\n\n    %% styling\n    classDef orange fill:#F39C12,color:#000,stroke:#F39C12;\n    class C orange;</code></pre> <p>Sanan kohdalla embedding tai context vector on jo t\u00e4m\u00e4n kurssin harjoituksissa osoittautunut hy\u00f6dylliseksi, viitaten siihen, ett\u00e4 Zellig Harrisin distribution hypothesis-teorialla on paikkansa maailmassa. Ent\u00e4p\u00e4 kun pit\u00e4\u00e4 tiivist\u00e4\u00e4 kokonaisuus, joka on merkitt\u00e4v\u00e4sti monimutkaisempi kuin yksitt\u00e4inen sana (tai sanan osatekij\u00e4, wordpiece)? Tarkastellaan seuraavaa kaoottista virkett\u00e4:</p> <p>\"Nimikirjassa oleva merkint\u00e4 virantoimituksesta pid\u00e4tt\u00e4misest\u00e4 on poistettava, jos virantoimituksesta pid\u00e4tt\u00e4mist\u00e4 koskeva p\u00e4\u00e4t\u00f6s tai virantoimituksesta pid\u00e4tt\u00e4misen perusteena ollut irtisanominen tai virkasuhteen purkamista koskeva p\u00e4\u00e4t\u00f6s kumotaan taikka virkamiehen virantoimituksesta pid\u00e4tt\u00e4misen syyn\u00e4 olleessa oikeudenk\u00e4ynniss\u00e4 ei ole todettu syyllistyneen rangaistavaan tekoon.\"</p> <p>\u2014 1322/89, \u00a7 3 <sup>6</sup></p> <p>Kykenetk\u00f6 tulkitsemaan lauseen sis\u00e4ll\u00f6n kertalukemalla vasemmalta oikealle, vai joudutko v\u00e4lill\u00e4 palaamaan taaksep\u00e4in? Enkooder-dekooder-malli ja sen context embedding ei v\u00e4ltt\u00e4m\u00e4tt\u00e4 juuri edusta sit\u00e4, kuinka ihminen tulkitsee tekstikokonaisuuden. Ihminen esimerkiksi silm\u00e4ilee edes-takaisin ja tulkitsee yksitt\u00e4isten sanojen merkityksen kontekstin valossa. Attention voidaan n\u00e4hd\u00e4 t\u00e4m\u00e4n prosessin mimikointina. <sup>5</sup></p> <p>Tip</p> <p>Kyseinen lause on poimittu Kielikellon artikkelista, jossa k\u00e4sitell\u00e4\u00e4n s\u00e4\u00e4d\u00f6skielen virke- ja lauserakenteen ongelmia. K\u00e4y kurkkaamassa, kuinka Kielikellon artikkelissa sama lause on selkeytetty listan avulla. <sup>7</sup></p> <p>Tavallisen, aiemmin kurssilta tutun seq2seq RNN:n kiinte\u00e4n pituuden kontekstivektorista tulee siis pullonkaula <sup>8</sup> <sup>2</sup>. Attention-mekanismi tarjoaa t\u00e4h\u00e4n ratkaisuna dynaamisen kontekstivektorin, joka lasketaan uudestaan joka ikiselle dekooderin aika-askeleelle <sup>3</sup>. T\u00e4ll\u00f6in Attention Decoder voi itsen\u00e4isesti p\u00e4\u00e4tt\u00e4\u00e4, mihin se keskitt\u00e4\u00e4 huomionsa dekoodatessaan k\u00e4\u00e4nn\u00f6st\u00e4.</p> <p>\"In simple words, during translation, we have a context vector that is dynamically updated and tells us how much attention we should give to each part of the input sequence.\"</p> <p>\u2014 Raieli &amp; Iuculano <sup>3</sup></p> <p></p> <p>Kuva 1: Kuvassa n\u00e4kyy vasemmalla enkooderi-RNN ja oikealla dekooderi-RNN. N\u00e4iden v\u00e4liss\u00e4 on attention-mekanismi, joka saa sy\u00f6tteen\u00e4 kaikkien aika-askeleiden piilotetut tilat (ks. koodi yll\u00e4). Kullekin dekooderin aika-askeleelle lasketaan kohdistuspisteet (alignment scores), jotka kuvaavat sit\u00e4, kuinka hyvin dekooderin nykyinen tila vastaa kutakin enkooderin tilaa. Kohdistuspisteet voidaan laskea monella tavalla, joista yksi on pistetulo (eli cosine similarity ilman magnitude-jakajaa). <sup>5</sup></p>"},{"location":"kieli/transformers/#query-key-ja-value-q-k-v","title":"Query, Key ja Value (Q, K, V)","text":"<p>Attention-mekanismissa k\u00e4ytetyt termit Query, Key ja Value on lainattu tiedonhaun ja tietokantojen maailmasta, joissa niit\u00e4 k\u00e4ytet\u00e4\u00e4n informaation j\u00e4rjest\u00e4miseen ja hakemiseen. Kuten G\u00e9ron kirjoittaa, n\u00e4m\u00e4 termit ovat modernin implementaation mukaisia termej\u00e4 aiemmin esitellylle. <sup>9</sup></p> <pre><code>def attention(QUERY, KEY, VALUE):\n    # Calculate alignment scores (e.g., dot product)\n    scores = np.dot(QUERY, KEY.T) # (1)!\n\n    # Normalize scores to get attention weights\n    attention_weights = softmax(scores)\n\n    # Compute the attention vector as a weighted sum of values\n    return np.dot(attention_weights, VALUE) # (2)!\n</code></pre> <ol> <li>Query on sama kuin \\(h_t\\) dekooderin nykyisess\u00e4 aika-askeleessa. Key on sama kuin \\(h_s\\) enkooderin aika-askeleissa.</li> <li>Value on \\(h_s\\) enkooderin aika-askeleissa, aivan kuten Key, mutta se edustaa sit\u00e4 informaatiota, jota dekooderi hy\u00f6dynt\u00e4\u00e4.</li> </ol> <p>Intuition tasolla n\u00e4m\u00e4 kolme termi\u00e4 voidaan ymm\u00e4rt\u00e4\u00e4 seuraavasti:</p> <ul> <li>Query (Kysely): Vastaa tietokantahakua. <sup>2</sup></li> <li>Key (Avain): Toimii kuten tietokannan avain indeksoinnissa. Sekvenssin kaikilla j\u00e4senill\u00e4 on oma avain. <sup>2</sup></li> <li>Value (Arvo):  Vastaa avain-arvo -parin varsinaista sis\u00e4lt\u00f6\u00e4 tietokannassa. <sup>2</sup></li> </ul> <p>Value edustaa siis haluttua informaatiota. Kun malli on avainten perusteella p\u00e4\u00e4tellyt, mitk\u00e4 sy\u00f6tteen osat ovat olennaisimpia kyselylle, se hakee hy\u00f6dynnett\u00e4v\u00e4ksi niit\u00e4 vastaavat arvot. (BY-NC-ND) <sup>2</sup></p> <p></p> <p>Kuva 2: Kuvan Q, V ja K laskelmat ovat Transformers-arkkitehtuurista, mutta sama logiikka p\u00e4tee my\u00f6s RNN:n enkooderi-dekooderi-arkkitehtuurissa. Huomaa, ett\u00e4 Q, K ja V lasketaan lineaarisella projektiolla sy\u00f6te-embeddingeist\u00e4. T\u00e4ss\u00e4 laskelma on matriisimuodossa. \\(N\\) on input-vektorin dimensio eli sanojen m\u00e4\u00e4r\u00e4. \\(D\\) on embedding-koko. Softmax ajetaan sarakekohtaisesti. <sup>10</sup></p> <p>N\u00e4ill\u00e4 kaikilla kolmella \u2013 Q, K, V \u2013 on erilaiset roolit, mutta niiden kaikkien laskenta on samankaltaista: ne saadaan lineaarisella projektiolla sy\u00f6te-embeddingeist\u00e4. T\u00e4m\u00e4 tarkoittaa, ett\u00e4 sy\u00f6tteen embeddingit muunnetaan kolmeen eri avaruuteen (Q, K ja V) k\u00e4ytt\u00e4m\u00e4ll\u00e4 kolmea erillist\u00e4 painomatriisia. N\u00e4in malli oppii erottamaan, miten se hakee tietoa (Q), miten se vertaa sit\u00e4 sy\u00f6tteeseen (K) ja mit\u00e4 tietoa se lopulta hy\u00f6dynt\u00e4\u00e4 (V). <sup>11</sup></p>"},{"location":"kieli/transformers/#transformer-arkkitehtuuri","title":"Transformer-arkkitehtuuri","text":"<p>Alkuper\u00e4isen Attention is All you Need -julkaisun transformer-arkkitehtuuri on p\u00e4hkin\u00e4nkuoressa <sup>5</sup> <sup>1</sup>:</p> <ul> <li>Encoder-Decoder-arkkitehtuuri, jossa on attention-mekanismi.</li> <li>... tarkemmin multi-head self-attention.</li> <li>Positionaalinen koodaus mallintaa sanaj\u00e4rjestyst\u00e4.</li> <li>Ei rekurrenssia, vaan kaikki laskelmat tehd\u00e4\u00e4n rinnakkain.</li> </ul> <p>Tutustutaan alla sen pariin merkitt\u00e4vimp\u00e4\u00e4n osatekij\u00e4\u00e4n otsikko kerrallaan.</p>"},{"location":"kieli/transformers/#self-attention","title":"Self-Attention","text":"<p>Attention-mekanismin menestys on synnytt\u00e4nyt useita variaatioita eri tappiofunktioita k\u00e4ytt\u00e4en. N\u00e4ist\u00e4 erityisesti self-attention on merkitt\u00e4v\u00e4, sill\u00e4 se poimii informaatiota suoraan sy\u00f6tteest\u00e4 itsest\u00e4\u00e4n ilman tarvetta verrata sit\u00e4 mihink\u00e4\u00e4n ulkoiseen tietoon. <sup>3</sup> Toisin sanoen linkki dekooderiin katkaistaan: my\u00f6s \\(Q\\) tulee sy\u00f6tteest\u00e4; ei enkooderin piilotiloista.</p> <p>\"Self-attention is the key component of transformer architecture. A transformer is a Seq2Seq model that uses attention in the encoder as well as the decoder, thus eliminating the need for RNNs\"</p> <p>\u2014 Smolyakov <sup>8</sup></p> <p></p> <p>Kuva 3: Self-attention-mekanismissa sama sekvenssi toimii sek\u00e4 queryn, keyn ett\u00e4 valuen laskennan perustana. T\u00e4m\u00e4 katkaisee kytk\u00f6ksen decoderiin. (BY-NC-ND) <sup>10</sup></p> <p>Self-attentionin perusajatusta voidaan havainnollistaa kirjastometaforalla. Kuvittele, ett\u00e4 etsit kirjastosta tietoa Marsin kolonialisointia k\u00e4sittelev\u00e4\u00e4 esseet\u00e4 varten (Query). Sinun ei tarvitse lukea jokaista hyllyss\u00e4 olevaa kirjaa kannesta kanteen (Value) l\u00f6yt\u00e4\u00e4ksesi oikean teoksen. Sen sijaan selaat kirjojen selk\u00e4myksi\u00e4 ja otsikoita (Key) l\u00f6yt\u00e4\u00e4ksesi ne, jotka vastaavat hakua. Toisin sanoen, self-attention on menetelm\u00e4, jonka avulla malli voi etsi\u00e4 kontekstista juuri sen tiedon tai \"edustuksen\", jota se sill\u00e4 hetkell\u00e4 tarvitsee. <sup>3</sup></p> <p>Danger</p> <p>Termien sekaannusvaara. Attention-mekanismit mahdollistavat mallien keskittymisen eri osiin sekvenssej\u00e4, joita kutsutaan queryksi, keyksi ja valueksi. Self-attention puolestaan viittaa erityisesti mekanismiin, jossa sama sekvenssi toimii queryn, keyn ja valuen laskennan perustana, mik\u00e4 mahdollistaa sis\u00e4isten suhteiden ymm\u00e4rt\u00e4misen sekvenssin sis\u00e4ll\u00e4. <sup>12</sup></p>"},{"location":"kieli/transformers/#multi-head-self-attention","title":"Multi-Head Self-Attention","text":"<p>Jos kytket samaan inputtiin monta paralleelia self-attention blokkia, sinulla on multi-head-ratkaisu k\u00e4siss\u00e4si. Kullakin niist\u00e4 on oma \\(Q\\), \\(K\\) ja \\(V\\) matriisi ja kukin oppii omat painonsa. Lopuksi l\u00e4hd\u00f6t ketjutetaan (engl. concatenate) ja yhdistet\u00e4\u00e4n taas kerran uudella lineaarisella projisiolla \u2013 eli tarvitaan uusia koulutettavia parametreja. Kurssikirjassa multi-headin merkityst\u00e4 kuvataan n\u00e4in: \"Multiple heads seem to be necessary to make self-attention work well. It has been speculated that they make the self-attention network more robust to bad initializations.\" <sup>10</sup></p> <p>Voita ja kumppanit tutkivat 2019 asiaa, ja p\u00e4\u00e4tteliv\u00e4t, ett\u00e4 \"only a small subset of heads appear to be important for the translation task. Important heads have one or more interpretable functions in the model, including attending to adjacent words and tracking specific syntactic relations. <sup>13</sup>. Eli eri p\u00e4\u00e4t l\u00f6yt\u00e4v\u00e4t erilaisia tokeneiden v\u00e4lisi\u00e4 kytk\u00f6ksi\u00e4, mutta kaikki niist\u00e4 eiv\u00e4t ole v\u00e4ltt\u00e4m\u00e4tt\u00e4 merkityksellisi\u00e4, joten mallin parametrikokoa voi pienent\u00e4\u00e4 pruning-tekniikalla: eli katkomalla p\u00e4it\u00e4 kuin Hercules Hydralta.</p> <p></p> <p>Kuva 4: T\u00e4h\u00e4n menness\u00e4 vastaan tulleet osatekij\u00e4t kun kytkee yhteen, ja ujuttaa v\u00e4liin layer normalizationit regulaatoimaan, samme kuvassa n\u00e4kyv\u00e4n transformer-blokin: multi-head self-attention, layer normalization, MLP sek\u00e4 viel\u00e4 yksi layer normalization. N\u00e4it\u00e4 voi kytke\u00e4 per\u00e4kk\u00e4in samalla tavalla kuin vaikkapa aiemmin n\u00e4htyj\u00e4 Conv2D-blokkeja. (BY-NC-ND) <sup>10</sup></p> <p>Se, mit\u00e4 t\u00e4ss\u00e4 materiaaleissa ei k\u00e4sitell\u00e4, on masked multi-head self-attention, joka on osa Transformer-dekoorin rakennetta.</p>"},{"location":"kieli/transformers/#positional-encoding","title":"Positional Encoding","text":"<p>Transformer-arkkitehtuurissa kaikki laskennat tehd\u00e4\u00e4n rinnakkain, paralleelisti, mik\u00e4 ajaa siihen, ett\u00e4 RNN:n sekvenssij\u00e4rjestyksen tuoma sanaj\u00e4rjestys kadotetaan. Ongelma ratkaistaan lis\u00e4\u00e4m\u00e4ll\u00e4 positional encoding kuhunkin embedding-vektoriin. T\u00e4m\u00e4 encoding on vektori, joka ynn\u00e4t\u00e4\u00e4n elementti elementilt\u00e4 sy\u00f6tteeseen. Eli jos sy\u00f6tteen embedding on \\(e\\) ja positionaalinen encoding on \\(p\\), sy\u00f6tteen embedding muunnetaan \\(e' = e + p\\). <sup>5</sup> T\u00e4m\u00e4n j\u00e4rjestyst\u00e4 kuvaavan vektorin voi joko oppia koulutuksessa tai laskea. Alkuper\u00e4isess\u00e4 artikkelissa k\u00e4ytettiin laskukaavaa, joka hy\u00f6dynt\u00e4\u00e4 sinin ja kosinin funktioita eri taajuuksilla. <sup>1</sup> T\u00e4m\u00e4 kaava on poikkeaa hieman parillisten ja parittomien indeksien osalta, mutta perusidea on sama: eri taajuuksilla olevat sinit ja kosinit luovat uniikkeja positionaalisia koodeja, jotka auttavat mallia erottamaan sanojen j\u00e4rjestyksen. Kaava on seuraava:</p> \\[ element_{(pos, i)} = \\begin{cases} \\sin\\left(\\frac{pos}{10000^{\\frac{i}{d}}}\\right) &amp; \\text{if } i \\text{ is even} \\\\ \\cos\\left(\\frac{pos}{10000^{\\frac{i-1}{d}}}\\right) &amp; \\text{if } i \\text{ is odd} \\end{cases} \\] <p>Jossa:</p> <ul> <li>\\(pos\\) on sanan paikka sekvenssiss\u00e4 (esim. 0, 1, 2, ...)</li> <li>\\(i\\) on embedding-vektorin elementin indeksi (esim. 0, 1, 2, ...)</li> <li>\\(d\\) on embedding-vektorin koko (esim. 512)</li> </ul>"},{"location":"kieli/transformers/#toiminta-kokonaisuutena","title":"Toiminta kokonaisuutena","text":"<p>3Blue1Brown on tehnyt sen verran hyv\u00e4\u00e4 ty\u00f6t\u00e4 transformer-arkkitehtuurin kokonaisuuden toiminnasta, joten viiton sinut suoraan katsomaan h\u00e4nen videotaan. Video on upotettu alle.</p> <p>Video 1: 3Blue1Brownin video, Attention in transformers, step-by-step | Deep Learning Chapter 6, selvent\u00e4\u00e4 hyvin attention-mekanismia transformer-arkkitehtuurissa</p> <p>On \u00e4\u00e4rimm\u00e4isen suositeltavaa katsoa my\u00f6s soittolistan seuraava video, How might LLMs store facts | Deep Learning Chapter 7, joka selvent\u00e4\u00e4, mihin (kenties) tieto tallentuu transformer-mallissa. Eli siis: kuinka malli kykenee jatkamaan lausetta, joka vaatii tosiel\u00e4m\u00e4n faktatietoa, kuten \"Mika H\u00e4kkinen on kuuluisa urheilija lajissa...\".</p> <p>On syyt\u00e4 huomata, ett\u00e4 vaikka Transformer ei sis\u00e4ll\u00e4 rekursiivisia tai konvoluutiokerroksia perinteisess\u00e4 mieless\u00e4, dekooderi toimii autoregressiivisesti \u2013 se tuottaa sanoja yksi kerrallaan ja sy\u00f6tt\u00e4\u00e4 edellisen tulosteen takaisin seuraavan askeleen sy\u00f6tteeksi. T\u00e4m\u00e4 muistuttaa RNN:n takaisinkytkent\u00e4\u00e4, mutta liittyy mallin k\u00e4ytt\u00f6tapaan eik\u00e4 itse arkkitehtuuriin. <sup>5</sup></p> <p>Jos arkkitehtuuria vertaa konvoluutioverkkoihin, on kiintoisaa, ett\u00e4 vaikka Transformer ei eksplisiittisesti hy\u00f6dynn\u00e4 konvoluutioita, self-attention-kerrokset oppivat k\u00e4yt\u00e4nn\u00f6ss\u00e4 usein konvoluutiomaisia operaatioita painojen jakamisen kautta. Oleellinen ero kuitenkin on, ett\u00e4 self-attention voi kohdistua mihin tahansa sy\u00f6tteen kohtaan, kun taas konvoluutio rajautuu vain ytimen (engl. kernel) kattamiin naapuripositioihin. <sup>5</sup></p> <p>Lopulta t\u00e4t\u00e4 kokonaisuutta voi tiivist\u00e4\u00e4 siten, ett\u00e4 kyseess\u00e4 on yh\u00e4 enkooderi-dekooderi-arkkitehtuuri, mutta rinnakkaistettavuus erottaa sen RNN-pohjaisista malleista. Alkuper\u00e4isess\u00e4 julkaisussa arkkitehtuuria k\u00e4ytettiin nimenomaan k\u00e4\u00e4nt\u00e4miseen, mutta Transformer suoriutuu my\u00f6s muista teht\u00e4v\u00e4st\u00e4. Pelk\u00e4st\u00e4\u00e4n kielen k\u00e4sittelyss\u00e4 siit\u00e4 l\u00f6ytyy muunnelmia, kuten GPT ja BERT. <sup>5</sup></p>"},{"location":"kieli/transformers/#arkkitehtuurin-variaatiot","title":"Arkkitehtuurin variaatiot","text":"<p>!TODO! N\u00e4m\u00e4 voisi k\u00e4yd\u00e4 lyhyesti l\u00e4pi, ehk\u00e4. Encoder-only BERT, Decoder-only GPT, Encoder-Decoder T5 eli th\u00f6 \u00f6rigin\u00e4\u00e4l thing.</p>"},{"location":"kieli/transformers/#mallien-arviointi-metriikat","title":"Mallien arviointi (Metriikat)","text":"<p>Teksti\u00e4 tuottavien tai k\u00e4\u00e4nt\u00e4vien mallien laadun mittaaminen on vaikeampaa kuin luokittelun, sill\u00e4 \"oikeita\" vastauksia voi olla useita, ja siksi yksinkertainen tarkkuusprosentti (accuracy) ei riit\u00e4 \u2013 tai ei ole edes m\u00e4\u00e4ritelt\u00e4viss\u00e4. Ihminen voi arvioida tuotetun tekstin laatua k\u00e4sin, mutta t\u00e4m\u00e4 on aikaa viev\u00e4\u00e4 ja subjektiivista. <sup>14</sup> Joitakin suoritus kykymittareita siis tarvitaan, mutta on ymm\u00e4rrett\u00e4v\u00e4, ett\u00e4 ne eiv\u00e4t tulkitse laatua kuten ihminen. Suorituskykymittarit voidaan jakaa kahteen kategoriaan:</p> <ul> <li>Ulkoiset (engl. extrinsic): Mittaavat mallin suorituskyky\u00e4 todellisessa teht\u00e4v\u00e4ss\u00e4 vertaamalla mallin tuottamaa tulosta ihmisen tuottamaan referenssiin. Esimerkkej\u00e4 ovat BLEU, ROUGE ja BertSCORE.</li> <li>Sis\u00e4iset (engl. intrinsic): Mittaavat mallin tuottaman tekstin sis\u00e4isten ominaisuuksien perusteella, ilman ulkoista sovellusta tai teht\u00e4v\u00e4\u00e4. T\u00e4t\u00e4 edustaa alla Perplexity.</li> </ul> <p>Perplexity, sis\u00e4inen suorituskykymittari, voidaan rinnastaa luokittelussa k\u00e4ytett\u00e4v\u00e4\u00e4n ristientropia-tappiofunktioon. Mit\u00e4 matalampi perplexity, sit\u00e4 v\u00e4hemm\u00e4n malli \"h\u00e4mmentyy\" ennustaessaan seuraavaa sanaa. Se ei kuitenkaan suoraan kerro, kuinka hyv\u00e4 malli on tuottamaan ihmism\u00e4ist\u00e4 teksti\u00e4 tietyss\u00e4 teht\u00e4v\u00e4ss\u00e4.</p> <p>Vastaavasti BLEU ja ROUGE ovat ulkoisia mittareita, jotka vertautuvat kuvantunnistuksen tarkkuusprosenttiin (accuracy). Ne mittaavat mallin suorituskyky\u00e4 loppuk\u00e4ytt\u00e4j\u00e4n n\u00e4k\u00f6kulmasta vertaamalla tulosta ihmisen tekem\u00e4\u00e4n mallivastaukseen. BLEU on luonteeltaan tarkkuuspainotteinen (precision) ja soveltuu hyvin konek\u00e4\u00e4nn\u00f6sten arviointiin, kun taas ROUGE on saantipainotteinen (recall) ja on yleinen tiivistelmien laadun mittari. Vaikka mallia koulutetaan minimoimaan perplexity\u00e4 (tai tappiofunktiota), lopullinen tavoite on usein maksimoida n\u00e4m\u00e4 ulkoiset laatumittarit. <sup>14</sup></p>"},{"location":"kieli/transformers/#perplexity","title":"Perplexity","text":"<p>Perplexity on sukua koulutuksen aikana minimoitavaan ristientropiaan (cross-entropy). K\u00e4yt\u00e4nn\u00f6ss\u00e4 se mittaa mallin ep\u00e4varmuutta. Toisin p\u00e4in sanottuna: se mittaa, kuinka yll\u00e4ttynyt (engl. surprised tai.. wait for it.. perplexed) malli on n\u00e4hdess\u00e4\u00e4n oikean sanan. <sup>11</sup> Se on IBM:n tutkijoiden vuonna 1977 julkaisema mittari, mutta: \"Perplexity remains a primary benchmark to this day and is a popular metric for evaluating sequential neural networks (including the GPT family of models).\" <sup>15</sup></p> <p>Matemaattisesti perplexity lasketaan ennustettujen todenn\u00e4k\u00f6isyyksien perusteella ja normalisoidaan lauseen pituudella. Jos malli antaa oikeille sanoille korkeita todenn\u00e4k\u00f6isyyksi\u00e4, perplexity on matala (l\u00e4hell\u00e4 ykk\u00f6st\u00e4). Kaava sille on seuraava: <sup>14</sup></p> \\[ Perplexity(s) = 2^{-\\frac{1}{N} \\log_2 p(s)} \\] <p>...jossa \\(s\\) on sy\u00f6tesekvenssi, \\(N\\) on sekvenssin pituus ja \\(p(s)\\) on mallin ennustama todenn\u00e4k\u00f6isyys sekvenssille. Tuo kaava ei paljasta, kuinka mallin ennustama todenn\u00e4k\u00f6isyys sekvenssille itsess\u00e4\u00e4n lasketaan. Se on:</p> \\[ p(s) = \\prod_{i=1}^{N} P(w_i | w_1, w_2, ..., w_{i-1}) \\] <p>Eli lause <code>s = \"Pizza may be life\"</code> voidaan purkaa sanoiksi <code>w_1 = \"Pizza\"</code>, <code>w_2 = \"may\"</code>, <code>w_3 = \"be\"</code> ja <code>w_4 = \"life\"</code>. Malli ennustaa todenn\u00e4k\u00f6isyyden jokaiselle sanalle, ottaen huomioon kaikki aiemmat sanat. Eli siis:</p> \\[ \\begin{align*} P(w_1 | \\text{start}) &amp; = P(\\text{\"Pizza\"} | \\text{start}) \\\\ P(w_2 | w_1) &amp; = P(\\text{\"may\"} | \\text{\"Pizza\"}) \\\\ P(w_3 | w_1, w_2) &amp; = P(\\text{\"be\"} | \\text{\"Pizza\"}, \\text{\"may\"}) \\\\ P(w_4 | w_1, w_2, w_3) &amp; = P(\\text{\"life\"} | \\text{\"Pizza\"}, \\text{\"may\"}, \\text{\"be\"}) \\end{align*} \\] <p>N\u00e4m\u00e4 todenn\u00e4k\u00f6isyydet saadaan mallin outputista (softmax). Merkint\u00e4 <code>P(word|context)</code>, joka esiintyy Hugging Facen Perplexity of fixed-length models-dokumentissa, muistuttanee sinua Naive Bayes -mallin todenn\u00e4k\u00f6isyyslausekkeista, kuten my\u00f6s ep\u00e4varmuus tai entropia. Perplexity on siis er\u00e4\u00e4nlainen \"k\u00e4\u00e4nteinen\" todenn\u00e4k\u00f6isyys, joka mittaa mallin ep\u00e4varmuutta ennustuksistaan.</p> <p>Suosittelen tutustumaan Machine Learning Q and AI -kirjan repositoriosta l\u00f6ytyv\u00e4\u00e4n perplexity.ipynb-tiedostoon, jossa on esimerkkej\u00e4 siit\u00e4, kuinka perplexity lasketaan k\u00e4yt\u00e4nn\u00f6ss\u00e4. <sup>14</sup>. Jos haluat selke\u00e4sti kommentoidun koodiesimerkin, katso Cometin blogilta Perplexity for LLM Evaluation.</p>"},{"location":"kieli/transformers/#bleu","title":"BLEU","text":"<p>BLEU (Bilingual Evaluation Understudy) on kenties tunnetuin ja laajimmin k\u00e4ytetty mittari konek\u00e4\u00e4nn\u00f6sten laadun arviointiin. Sit\u00e4 hy\u00f6dynt\u00e4v\u00e4t l\u00e4hes kaikki kielen k\u00e4\u00e4nt\u00e4miseen kykenev\u00e4t kielimallit, mukaan lukien OpenAI:n Whisper ja GPT-mallit. Menetelm\u00e4 perustuu vertailuun: mallin tuottamaa teksti\u00e4 verrataan ihmisen tekem\u00e4\u00e4n referenssik\u00e4\u00e4nn\u00f6kseen. K\u00e4yt\u00e4nn\u00f6ss\u00e4 BLEU mittaa sanastollista p\u00e4\u00e4llekk\u00e4isyytt\u00e4 laskemalla tarkkuutta (precision) eli sit\u00e4, kuinka moni mallin tuottama sana tai sanajono (n-grammi) esiintyy my\u00f6s referenssit tekstiss\u00e4 <sup>14</sup>. Sen kaava on:</p> \\[ \\begin{align*} BP &amp; = \\begin{cases} 1 &amp; \\text{if } c &gt; r \\\\ e^{(1 - \\frac{r}{c})} &amp; \\text{if } c \\leq r \\end{cases} \\\\ BLEU &amp; = BP \\cdot \\exp\\left( \\sum_{n=1}^{N} w_n \\log p_n \\right) \\end{align*} \\] <p>...jossa:</p> <ul> <li>\\(c\\) on mallin tuottaman tekstin pituus</li> <li>\\(r\\) on referenssitekstin pituus</li> <li>\\(N\\) on n-grammin range (usein 4-grammi)</li> <li>\\(w_n\\) on painoarvo n-grammille (usein tasapainotettu, eli \\(w_n = \\frac{1}{N}\\))</li> <li>\\(p_n\\) on <code>correct_n-grams / tota_n_grams</code> eli mallin tuottamien n-grammien tarkkuus</li> </ul> <p>Alla Pekka Huttusen aiemmasta kurssitoteutuksesta lainattu esimerkki:</p> <ul> <li>Original: Rakastan oppia uusia asioita teko\u00e4lyst\u00e4.</li> <li>Reference: I love to learn new things about AI.</li> <li>Candidate 1: I love love new AI.</li> <li>Candidate 2: I love to learn ride a bike .</li> <li>Candidate 3: I love learning about artificial intelligence .</li> </ul> <p>Info</p> <p>Lukuohje: keltaisella korostetut osat ovat n-grammeja, jotka esiintyv\u00e4t referenssiss\u00e4. Ensimm\u00e4isen lauseen toista <code>love</code>-sanaa ei lasketa, koska se on jo laskettu ensimm\u00e4isen <code>love</code>-sanan kohdalla. T\u00e4ten <code>len(I, love, new, AI, .</code>) on 5 ja <code>len(Candidate_1)</code> on 6, joten 1-grammien tarkkuus on 5/6.</p> Metric Candidate 1 Candidate 2 Candidate 3 1-grams 5/6 5/8 4/7 2-grams 2/5 3/7 1/6 3-grams 0/4 2/6 0/5 4-grams 0/3 1/5 0/4 lenght \\(c\\) 6 8 7 Tarkemmat laskelmat (klikkaa auki) <p>Alla viel\u00e4 laskennat:</p> <p>Candidate 1</p> \\[ \\begin{align*} BP &amp; = e^{(1 - \\frac{9}{6})} = 0.6065 \\\\ BLEU &amp; = 0.6065 \\cdot \\exp\\left( \\frac{1}{4} (\\log \\frac{5}{6} + \\log \\frac{2}{5} + \\log \\frac{0}{4} + \\log \\frac{0}{3}) \\right) \\\\ BLEU &amp; = 0.6065 \\cdot \\exp\\left( -0.1823 - 0.9162 - \\infty - \\infty \\right) \\\\ BLEU &amp; = 0.6065 \\cdot 0 = 0 \\end{align*} \\] <p>Candidate 2</p> \\[ \\begin{align*} BP &amp; = e^{(1 - \\frac{9}{8})} = 0.8825 \\\\ BLEU &amp; = 0.6065 \\cdot \\exp\\left( \\frac{1}{4} (\\log \\frac{5}{8} + \\log \\frac{3}{7} + \\log \\frac{2}{6} + \\log \\frac{1}{5}) \\right) \\\\ BLEU &amp; = 0.6065 \\cdot \\exp\\left(\\frac{1}{4} (-0.4700 - 0.8472 -1.0986 - 1.6094) \\right) \\\\ BLEU &amp; = 0.6065 \\cdot 0.3655 = 0.323 \\end{align*} \\] <p>Candidate 3</p> \\[ \\begin{align*} BP &amp; = e^{(1 - \\frac{9}{7})} = 0.7515 \\\\ BLEU &amp; = 0.6065 \\cdot \\exp\\left( \\frac{1}{4} (\\log \\frac{4}{7} + \\log \\frac{1}{6} - \\infty - \\infty) \\right) \\\\ BLEU &amp; = 0.7515 \\cdot 0 = 0 \\end{align*} \\] <p>Kyseess\u00e4 on merkkijonojen vertailuun perustuva mittari. Se ei ymm\u00e4rr\u00e4 sanojen merkityksi\u00e4 tai kielioppia. Esimerkiksi synonyymien k\u00e4ytt\u00f6 tai sanaj\u00e4rjestyksen muutos voi laskea pisteit\u00e4, vaikka k\u00e4\u00e4nn\u00f6s olisi sis\u00e4ll\u00f6llisesti oikein. Toisaalta merkitykselt\u00e4\u00e4n v\u00e4\u00e4r\u00e4 lause voi saada korkeat pisteet, jos se sis\u00e4lt\u00e4\u00e4 oikeat sanat. <sup>14</sup></p> <p>Nykyk\u00e4sityksen mukaan BLEU onkin hy\u00f6dyllinen ty\u00f6kalu ensisijaisesti mallin kehityksen seurantaan (model selection) koulutuksen aikana, jossa se toimii sujuvuuden indikaattorina. Lopulliseen laadunvarmistukseen (model evaluation) tai virheiden etsint\u00e4\u00e4n se ei sovellu yht\u00e4 hyvin, ja nyky\u00e4\u00e4n sen rinnalle tai tilalle on noussut kehittyneempi\u00e4 vaihtoehtoja, kuten METEOR ja COMET.<sup>14</sup>.</p> <p>Aivan kuten Perplexity, my\u00f6s BLEU:n k\u00e4yt\u00f6st\u00e4 l\u00f6ytyy bleu.ipynb-tiedostosta lis\u00e4tietoa aiemmin mainitun kirjan reposta.</p>"},{"location":"kieli/transformers/#rouge","title":"ROUGE","text":"<p>TODO! Obvious.</p>"},{"location":"kieli/transformers/#bertscore","title":"BERTScore","text":"<p>TODO! Obvious.</p>"},{"location":"kieli/transformers/#tehtavat","title":"Teht\u00e4v\u00e4t","text":"<p>Teht\u00e4v\u00e4: Perplexity</p> <p>Aja tiedosto <code>720_perplexity.py</code>. Kyseess\u00e4 on Transformers - The definitive Guide -kirjan <sup>11</sup> esimerkki, joka on toteutettu PyTorchilla. Koodi on muutoin samaa, mutta se on saatettu yhteen Suomen kielen kanssa. Tutustu koodiin ja k\u00e4yt\u00e4 sit\u00e4 leikkikentten\u00e4. Lopussa on soluja, jotka sallivat sinun selvitt\u00e4\u00e4 jonkin keksim\u00e4si lauseen PPL-arvon, n\u00e4in:</p> <pre><code>Perplexity(\"Ainola on s\u00e4velt\u00e4j\u00e4 Jean Sibeliuksen ja h\u00e4nen puolisonsa Aino Sibeliuksen asuintalo, joka on vuodesta 1974 alkaen toiminut kotimuseona\")\n</code></pre> <p>Lause on lainaus Ainola-artikkelista suomenkielisest\u00e4 Wikipediasta. Wikipediaa on k\u00e4ytetty yhten\u00e4 l\u00e4hteen\u00e4 k\u00e4ytt\u00e4m\u00e4mme mallin <code>LumiOpen/Viking-7B</code> koulutuksessa. Huomaa, ett\u00e4 mallin ajaminen GPU:lla vaatii noin 16 GB VRAM:ia. CPU:lla ajettaessa et saa Out Of Memory -varoituksia, mutta malli on toki hieman hidas.</p> <p>Teht\u00e4v\u00e4: ???</p> <p>Tutustu <code>721_neural_machine_translation_transformer.py</code>-tiedostoon. T\u00e4m\u00e4 on muokattu versio NVIDIA:n Learning Deep Learning -kirjan (ja videosarjan) esimerkist\u00e4. Teht\u00e4v\u00e4ss\u00e4 koulutetaan Transformers-malli k\u00e4\u00e4nt\u00e4m\u00e4\u00e4n yhdest\u00e4 kielest\u00e4 toiseen.</p> <p>20 epookin koulutus kesti opettajan Macbook:lla noin 12.5 minuuttia. Huomaa, ett\u00e4 MPS ei ole tuettu, joten koulutus tapahtui CPU:lla. Ubuntu-koneella meni noin 1.5 minuuttia GPU:lla.</p>"},{"location":"kieli/transformers/#lahteet","title":"L\u00e4hteet","text":"<ol> <li> <p>Vaswani, A. et. al. Attention is All You Need. 2017. https://arxiv.org/abs/1706.03762\u00a0\u21a9\u21a9\u21a9</p> </li> <li> <p>Raschka, S. Build a Large Language Model (From Scratch). Manning. 2024.\u00a0\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9</p> </li> <li> <p>Raieli, S. &amp; Iuculano, G. Building AI Agents with LLMs, RAG, and Knowledge Graphs. Packt. 2025.\u00a0\u21a9\u21a9\u21a9\u21a9\u21a9</p> </li> <li> <p>Watson, M &amp; Chollet, F. Deep Learning with Python, Third Edition. Manning. 2025.\u00a0\u21a9</p> </li> <li> <p>Ekman, M. Learning Deep Learning: Theory and Practice of Neural Networks, Computer Vision, NLP, and Transformers using TensorFlow. Addison-Wesley. 2025.\u00a0\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9</p> </li> <li> <p>1322/1989. Nimikirjan pit\u00e4minen er\u00e4ist\u00e4 henkil\u00f6st\u00f6ryhmist\u00e4. https://www.finlex.fi/fi/lainsaadanto/1989/1322\u00a0\u21a9</p> </li> <li> <p>Virtaniemi, A. Kiiloja ja sokkeloita. S\u00e4\u00e4d\u00f6skielen virke- ja lauserakenteen ongelmia. 1992. https://kielikello.fi/kiiloja-ja-sokkeloita-saadoskielen-virke-ja-lauserakenteen-ongelmia/\u00a0\u21a9</p> </li> <li> <p>Smolyakov, V. Machine Learning Algorithms in Depth. Manning. 2025.\u00a0\u21a9\u21a9</p> </li> <li> <p>G\u00e9ron, A. Hands-On Machine Learning with Scikit-Learn and PyTorch. O'Reilly. 2025.\u00a0\u21a9</p> </li> <li> <p>Prince, S. Understanding Deep Learning. The MIT Press. 2023. https://udlbook.github.io/udlbook/\u00a0\u21a9\u21a9\u21a9\u21a9</p> </li> <li> <p>Koenigstein, N. Transformers: The Definitive Guide. O'Reilly. 2026.\u00a0\u21a9\u21a9\u21a9</p> </li> <li> <p>Esposito, F. Programming Large Language Models with Azure Open AI: Conversational programming and prompt engineering with LLMs. Microsoft Press. 2024.\u00a0\u21a9</p> </li> <li> <p>Voita, E., Talbot, D., Moiseev, F., Sennrich, R. &amp; Titov, I. Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned. 2019. https://arxiv.org/abs/1905.09418\u00a0\u21a9</p> </li> <li> <p>Raschka, S. Machine Learning Q and AI. No Starch Press. 2024.\u00a0\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9</p> </li> <li> <p>Morgan, A. Perplexity for LLM Evaluation. 2024. https://www.comet.com/site/blog/perplexity-for-llm-evaluation/\u00a0\u21a9</p> </li> </ol>"},{"location":"konvoluutio/cnn/","title":"Konvoluutioverkot","text":""},{"location":"konvoluutio/cnn/#perusteet","title":"Perusteet","text":"<p>T\u00f6ks\u00e4ytet\u00e4\u00e4n heti alkuun kolme merkitt\u00e4vint\u00e4 hy\u00f6ty\u00e4 konvoluutioverkoista (CNN) verrattuna perinteisiin t\u00e4ysin kytkettyihin verkkoihin (FCNN):</p> <ol> <li>Parametritehokkuus. Konvoluutioverkot jakavat painot paikallisesti. T\u00e4m\u00e4 shared weights k\u00e4site tulee my\u00f6hemmin tutuksi my\u00f6s kielimalleissa. <sup>1</sup></li> <li>Paikallisuus. Konvoluutioverkot s\u00e4ilytt\u00e4v\u00e4t kuvan 2D-rakenteen. FCNN:n kohdalla kuva litistettiin pitk\u00e4ksi vektoriksi, mik\u00e4 tuhosi spatiaalisen informaation. <sup>1</sup></li> <li>Hierarkiset piirteet. Monimutkainenkin visuaalinen tuotos koostuu pohjimmiltaan yksinkertaisista piirteist\u00e4 (reunat, kulmat, tekstuurit). T\u00e4m\u00e4 malli on CNN:n ydin. <sup>1</sup></li> </ol>"},{"location":"konvoluutio/cnn/#parametritehokkuus","title":"Parametritehokkuus","text":"<p>Olet tutustunut kurssilla FCNN-verkkoihin, ja niiden rajat alkoivat l\u00f6yty\u00e4 Cifar10-datasetin kohdalla. Edellisen luvun teht\u00e4v\u00e4ss\u00e4 koulutit FCNN-verkon \u2013 kenties arkkitehtuurilla <code>3072-1024-512-10</code> \u2013, ja p\u00e4\u00e4sit noin 55% tarkkuuteen. Tutustuessasi wikipedian Cifar10-sivuun huomasit, ett\u00e4 jo 2010-luvun alkupuolella verkot kykeniv\u00e4t yli 95 % tarkkuuteen. On hyv\u00e4 muistaa, ett\u00e4 95 % on jo merkitt\u00e4v\u00e4n suuri tarkkuus. Graham lainaa Karpathy\u00e4, ett\u00e4: \"For comparison, human performance on CIFAR-10 is estimated to be 6%.\" <sup>2</sup> Lukema on siis error rate, ei accuracy.</p> <p>Miten t\u00e4m\u00e4 on mahdollista? Lienee selv\u00e4\u00e4, ett\u00e4 2010-luvun alussa ratkaisu tuskin oli kasvattaa verkkoa ilman arkkitehtuurimuutoksia. Alla on taulukossa esiteltyn\u00e4 <code>3072-1024-512-10</code> FCNN-verkon parametrien lukum\u00e4\u00e4r\u00e4. </p> Layer Shape Count fc1.weight torch.Size([1024, 3072]) 3,145,728 fc1.bias torch.Size([1024]) 1,024 fc2.weight torch.Size([512, 1024]) 524,288 fc2.bias torch.Size([512]) 512 fc3.weight torch.Size([10, 512]) 5,120 fc3.bias torch.Size([10]) 10 Total 3,676,682 <p>Olet varmasti kokeillut t\u00e4t\u00e4 ratkaisua itsekin: verkon kokoa kasvattamalla ei p\u00e4\u00e4st\u00e4 kovin pitk\u00e4lle. Mik\u00e4 siis avuksi? Historiasta l\u00f6ytyy vastaus: konvoluutioverkot (Convolutional Neural Networks, CNN). Alla n\u00e4kyy kurssikirjasta kuva, joka havainnollistaa konvoluutioverkkojen suorituskyky\u00e4 MNIST-datasetin avulla <sup>3</sup>.</p> <p></p> <p>Kuva 1: MNIST konvoluutioverkolla (2050 parametria) vs. FCNN:ll\u00e4 (150,185 parametria). <sup>3</sup></p> <p>Ihmiseen kun vertaa, niin jo vuonna 2014 Grahamin Fractional Max-Pooling -malli saavutti huimat tulokset: \"we obtained test errors of 4.50% (1 test), 3.67% (12 tests) and 3.47% (100 tests)\" <sup>2</sup>. Konvoluutioverkot mahdollistavat siis huomattavan tehokkaan tavan k\u00e4sitell\u00e4 kuvia. Ja mik\u00e4 oli Grahamin mallin parametrien m\u00e4\u00e4r\u00e4? 74 miljoonaa parametria (jos <code>filter_growth_rate = 160</code>). Tosin paperissa mainitaan my\u00f6s 12M parametria k\u00e4ytt\u00e4nyt malli (<code>filter_growth_rate = 64</code>). T\u00e4m\u00e4 pienempi malli on se, mik\u00e4 on toteutettu kurssin koodissa.</p> <p>\\(74 \\text{M}\\) parametrin malli ylsi Grahamin paperin mukaan \\(3.47 \\%\\) virheeseen CIFAR-10 datasetin kanssa. Opettajan kouluttamalla, pienemm\u00e4ll\u00e4 \\(12 \\text{M}\\) parametrin mallilla p\u00e4\u00e4stiin noin \\(92 \\%\\) tarkkuuteen eli \\(8 \\%\\) virheeseen. Tutustut t\u00e4h\u00e4n toteutukseen my\u00f6hemmin teht\u00e4v\u00e4osiossa, ja t\u00e4h\u00e4n tutustutaan my\u00f6s Case Study: Fractional Max-Pooling (Graham, 2014)-otsikon alla hieman tarkemmin.</p> <p></p> <p>Kuva 2: 300 epookin koulutuksen aikaiset tarkkuus- ja virhek\u00e4yr\u00e4t Grahamin Fractional Max-Pooling -mallille (12M parametria).</p>"},{"location":"konvoluutio/cnn/#miten-paljon-muistia-saastyy","title":"Miten paljon muistia s\u00e4\u00e4styy?","text":"<p>Vuonna 2014 olisi ollut mahdollista k\u00e4ytt\u00e4\u00e4 esimerkiksi GeForce GTX TITAN -korttia, jossa on 6 GB muistia. Muistiin mahtuisi \\(\\frac{6 \\times 1024^3}{4} \\approx 1600 \\text{M}\\) miljoonaa <code>float32</code>-liukulukua (4 tavua per luku). T\u00e4t\u00e4 tilaa ei kuitenkaan voi k\u00e4ytt\u00e4\u00e4 pelk\u00e4st\u00e4\u00e4n verkon parametreille. Koulutuksen aikana muistia tarvitaan:</p> <ol> <li>Parametreille (weights &amp; biases)</li> <li>Gradienteille (yleens\u00e4 yht\u00e4 paljon tilaa kuin parametreille)</li> <li>Optimoijan tiloille (esim. Adam-optimoija tallettaa kaksi lis\u00e4arvoa per parametri)</li> <li>Aktivoinneille (v\u00e4litulokset verkon kerroksissa, n\u00e4m\u00e4 riippuvat suoraan batch-koosta)</li> </ol> <p>Alla on typistetty <code>nvidia-smi</code>-komennon tulos Fractional Max-Pooling -mallin koulutuksen aikana (GeForce RTX 3060 Ti, 8 GB muistia):</p> <pre><code>+-------------------------------------------------------------------+\n| Processes:                                                        |\n|  GPU   GI   Type   Process name                        GPU Memory |\n|        ID                                              Usage      |\n|===================================================================|\n|    0   N/A     C   ...n/notebooks/.venv/bin/python3       2650MiB |\n+-------------------------------------------------------------------+\n</code></pre> <p>Jos 12M parametria vie 32-kokoisella er\u00e4ll\u00e4 <code>2650 MiB</code> muistia, niin suuremman mallin (<code>filter_growth_rate = 160</code>) huimat 74M parametria veisi hyvin karkeiden oletusten kera <code>74/12 * 2650 \u2248 16342 MiB</code> \u2013 eli noin 16 GB muistia. Termi <code>filter_growth_rate</code> selitet\u00e4\u00e4n alla MaxPooling-mallin yhteydess\u00e4. Jos t\u00e4m\u00e4n suuremman mallin halutaan mahtuvan 6 GB VRAM:iin, niin batch-kokoa pit\u00e4isi pienent\u00e4\u00e4: parametrien m\u00e4\u00e4r\u00e4\u00e4 t\u00e4m\u00e4 ei v\u00e4henn\u00e4, mutta aktivaatioiden m\u00e4\u00e4r\u00e4\u00e4 kyll\u00e4kin.</p> <p>12M mallin kouluttamiseen kului opettajan GeForce RTX 3060 Ti:ll\u00e4 yli 11 tuntia (300 epookkia, noin 2 min 17 sek per epookki).</p> <p>Sy\u00f6tekuva ja parametrien m\u00e4\u00e4r\u00e4</p> <p>VGG-16-konvoluutioverkossa k\u00e4ytet\u00e4\u00e4n tyypillisesti kuvia koossa 224\u00d7224\u00d73 (RGB, 3 kanavaa). Dataset on nimelt\u00e4\u00e4n ImageNet, jossa on 1000 eri luokkaa ja miljoonia kuvia. Konvoluutioverkossa VGG-16 on t\u00e4st\u00e4 huolimatta kokonaisuudessaan vain 138M parametria.</p> <p>Kuinka olisi FCNN-verkon laita, jos input on <code>224x224x3</code> ja ensimm\u00e4inen piilotettu kerros <code>4096</code> neuronia? Input olisi siis <code>150,528</code>-pituinen vektori. T\u00e4ll\u00f6in pelk\u00e4st\u00e4\u00e4n ensimm\u00e4isen piilotetun kerrokset olisivat parametrim\u00e4\u00e4r\u00e4lt\u00e4\u00e4n:</p> \\[ 150,528 \\times 4096 \\approx 617 \\text{M} \\]"},{"location":"konvoluutio/cnn/#lyhyt-historia","title":"Lyhyt historia","text":"<p>Alla olevan historian parametriluvut ovat hyvinkin suuntaa-antavia, sill\u00e4 useimmista arkkitehtuureista voi muovata eri kokoisia malleja. Lukema liittyy usein alkuper\u00e4iseen julkaisuun.</p> <ul> <li>1980: Konvoluutioverkkojen juuret ulottuvat 1980-luvulle, jolloin Kunihiko Fukushima esitteli Neocognitron-mallin, josta polveutuvat my\u00f6hemm\u00e4t konvoluutioverkot. <sup>4</sup> </li> <li>1998: LeNet-5, tunnetuin n\u00e4ist\u00e4 LeNet-X -malleista. ~60k parametria <sup>5</sup>.</li> <li>2012: AlexNet, merkitt\u00e4v\u00e4 edistysaskel syvien konvoluutioverkkojen koulutuksessa, joka voitti ImageNet-kilpailun ylivoimaisesti. <sup>6</sup>.</li> <li>2014: GoogLeNet (Inception v1), joka esitteli Inception-kerroksen ja syv\u00e4n arkkitehtuurin. ~6.8 M parametria. <sup>7</sup>.</li> <li>2015: VGG-16, syv\u00e4 konvoluutioverkko, joka k\u00e4ytti nimens\u00e4 mukaisesti 16 kerrosta. ~138 M parametria. <sup>8</sup> <sup>9</sup>.</li> <li>2015: ResNet, esitteli \"residual connections\", jotka mahdollistivat eritt\u00e4in syvien verkkojen koulutuksen. ~19 M parametria. <sup>10</sup> <sup>11</sup>.</li> <li>2015: U-Net, erityisen mielenkiintoinen arkkitehtuuri segmentointiin. ~31 M parametria. <sup>12</sup>.</li> <li>2017: Mask R-CNN, joka yhdisti objektin tunnistuksen ja segmentoinnin. ~44 M parametria. <sup>13</sup>.</li> <li>2018: DenseNet, joka k\u00e4ytti tiheit\u00e4 yhteyksi\u00e4 kerrosten v\u00e4lill\u00e4 parantaakseen tiedonsiirtoa ja v\u00e4hent\u00e4\u00e4kseen gradientin katoamista. ~28 M parametria. <sup>14</sup>.</li> <li>2020: Vision Transformer (ViT), joka sovelsi transformer-arkkitehtuuria kuvantunnistukseen, tarjoten vaihtoehdon perinteisille konvoluutioverkoille. ~86 M parametria (ViT-Base). <sup>15</sup>.</li> </ul>"},{"location":"konvoluutio/cnn/#piirrevektorit-kasin","title":"Piirrevektorit k\u00e4sin","text":"<p>On hy\u00f6dyksi pohtia, miten kuvia k\u00e4sitell\u00e4\u00e4n perinteisiss\u00e4 tietokonen\u00e4\u00f6n sovelluksissa ennen konvoluutioverkkojen aikakautta. Yksi keskeinen k\u00e4site on feature vector eli piirrevektori, joka tiivist\u00e4\u00e4 kuvan olennaiset piirteet matemaattiseen muotoon. Piirrevektori voi n\u00e4yt\u00e4\u00e4 vaikka t\u00e4lt\u00e4:</p> <pre><code># Piirrevektoreita\nfeatures = [\n    [0.1, 0.5, 0.3, ..., 0.7], # kuva 1\n    [0.3, 0.6, 0.1, ..., 0.4], # kuva 2\n    ...,\n]\n\n# Nyt voisimme kouluttaa esimerkiksi bin\u00e4\u00e4riluokittelijan\nlabels = [0, 1, ..., 0]  # 1 = kissa, 0 = koira\nmodel.fit(features, labels)\n</code></pre> <p>Vektoreita voi etsi\u00e4 monin eri tavoin, ja n\u00e4m\u00e4 tavat voidaan jakaa kahteen p\u00e4\u00e4kategoriaan:</p> <ul> <li>Image descriptor: Koko kuva-alueen v\u00e4rijakauma histogrammina, mediaaniv\u00e4ri tai jokin/jotkin muut globaalit ominaisuudet.<ul> <li>1 kuva sis\u00e4\u00e4n, 1 vektori ulos.</li> </ul> </li> <li>Feature descriptor: Kuvaa kuvan paikallisia piirteit\u00e4, kuten reunat, kulmat tai tekstuurit.<ul> <li>1 kuva sis\u00e4\u00e4n, N vektoria ulos (N on paikallisten alueiden m\u00e4\u00e4r\u00e4).</li> </ul> </li> </ul> <p>Koko kuvan pinta-alaa kuvaavat piirteet voivat olla harvoissa tapauksissa hy\u00f6dyllisi\u00e4, mutta usein paikalliset piirteet tarjoavat enemm\u00e4n informaatiota. Kuvan voi my\u00f6s jakaa pienempiin osiin (esim. 100x100 pikselin kuva -&gt; 10x10 pikselin ruudukko) ja laskea kullekin osalle (engl cell) piirrevektori.</p> <p>Muista, ett\u00e4 t\u00e4m\u00e4n kurssin aiheena eiv\u00e4t ole perinteiset tietokonen\u00e4\u00f6n menetelm\u00e4t, vaan konvoluutioverkot. Eth\u00e4n siis k\u00e4yt\u00e4t t\u00e4h\u00e4n osioon kymmeni\u00e4 tunteja, ellei kalenterisi ole harvinaisen v\u00e4lj\u00e4. Riitt\u00e4\u00e4, ett\u00e4 tunnistat perusidean, mik\u00e4 tarjoaa mahdollisuuden ymm\u00e4rt\u00e4\u00e4 konvoluutioverkkojen hy\u00f6tyj\u00e4 paremmin.</p> <p>Tutustutaan alla lyhyesti kahteen globaaliin image descriptor -menetelm\u00e4\u00e4n: LBP ja HOG.</p>"},{"location":"konvoluutio/cnn/#lbp","title":"LBP","text":"<p>Tekstuureita voi kuvastaa esimerkiksi Local Binary Patterns (LBP) -menetelm\u00e4ll\u00e4, jonka esitteliv\u00e4t Ojala et al. vuonna 2002 Oulun yliopiston julkaisussa \"Multiresolution Gray Scale and Rotation Invariant Texture Classification with Local Binary Patterns\" <sup>16</sup>. Paperi on ladattavissa kirjautumatta Stanfordin CS216B kurssin linkist\u00e4. LBP perustuu pikselin vertailuun sit\u00e4 ymp\u00e4r\u00f6ivien pikseleiden kanssa. Naiivi toteutus vertailee 3x3 alueen keskustaa muihin. Jos ymp\u00e4r\u00f6iv\u00e4 pikseli on kirkkaampi tai yht\u00e4 kirkas kuin keskuspikseli, sille annetaan arvo 1, muuten 0. N\u00e4in muodostuu 8-bittinen binaariluku, joka voidaan muuntaa desimaaliluvuksi. Kellonvastaisesti oletetaan siis, ett\u00e4 ymp\u00e4r\u00f6iv\u00e4t pikselit ovat arvoltaan \\(x_0 \\times 2^0 + x_1 \\times 2^1 + ... + x_7 \\times 2^7\\). T\u00e4m\u00e4 luku kuvaa kyseisen pikselin tekstuuria. Monimutkaisemmassa esimerkiss\u00e4 voidaan valita s\u00e4de, jolloin ymp\u00e4r\u00f6iv\u00e4t pisteet eiv\u00e4t olekaan v\u00e4litt\u00f6m\u00e4sti keskuspikselin vieress\u00e4, vaan kauempana. Katso Kuva 3, jossa t\u00e4m\u00e4 toteutus on havainnollistettu.</p> <p></p> <p>Kuva 3: Local Binary Patterns (LBP) -menetelm\u00e4 vertailee keskuspikseli\u00e4 sit\u00e4 ymp\u00e4r\u00f6iviin pikseleihin. Kuva: By Xiawi - Own work, CC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=11743214</p> <p>K\u00e4yt\u00e4nn\u00f6ss\u00e4?</p> <p>Jos haluat kokeilla LBP:t\u00e4 Pythonissa, niin <code>skimage</code>-kirjasto tarjoaa valmiin toteutuksen: Local Binary Pattern for texture classification. Jos haluat n\u00e4hd\u00e4 kokonaisemman esimerkin, Adrian Rosebrockin blogipostaus Face Recognition with Local Binary Patterns (LBPs) and OpenCV on hyv\u00e4 paikka aloittaa. Huomaa, ett\u00e4 n\u00e4iss\u00e4kin tapauksissa on vahva oletus, ett\u00e4 sinulla on jokin tapa rajata kiinnostava alue kuvasta (esim. kasvot). T\u00e4h\u00e4n voi k\u00e4ytt\u00e4\u00e4 perinteisi\u00e4 tietokonen\u00e4\u00f6n menetelmi\u00e4, kuten Haar-cascade -luokittelijoita tai HOG+SVM -yhdistelm\u00e4\u00e4.</p>"},{"location":"konvoluutio/cnn/#hog","title":"HOG","text":"<p>HOG (Histogram of Oriented Gradients) on toinen suosittu piirrevektorin muodostamismenetelm\u00e4. Dalal ja Triggs esitteliv\u00e4t HOG:n vuonna 2005 julkaistussa artikkelissaan \"Histograms of Oriented Gradients for Human Detection\". Artikkeli on ladattavissa Inria:n sivuilta. Termin \"oriented gradients\" voi suomentaa suunnatuiksi kaltevuuksiksi. Sinulle on jo aiemmin kurssilta tuttu k\u00e4site gradientti, joka kuvaa funktion muutosnopeutta. T\u00e4ss\u00e4 muutoksella tarkoitetaan pikselin kirkkausarvon muutosta. T\u00e4m\u00e4 muutos selvitet\u00e4\u00e4n \u2013 laita seuraava sana korvan taakse \u2013 konvoluutiosuodattimilla (esim. Sobel), jotka laskevat pikselin kirkkausarvon muutoksen horisontaalisesti (x-suunta) ja vertikaalisesti (y-suunta). N\u00e4in saadaan jokaiselle pikselille kaksi arvoa: \\(G_x\\) ja \\(G_y\\). N\u00e4iden avulla voidaan laskea gradientin suuruus ja suunta:</p> \\[ \\text{magnitude} = \\sqrt{G_x^2 + G_y^2} \\] <p>Kuva jaetaan soluihin (engl. cells), esimerkiksi 10x10 pikselin alueisiin. Kustakin solusta lasketaan histogrammi, jossa on esimerkiksi 9 laaria (esim. 0-19\u00b0, 20-39\u00b0, ..., 160-179\u00b0). Pikselin gradientin kontribuutio painotetaan sen suuruudella, eli jyrkemm\u00e4t muutokset vaikuttavat enemm\u00e4n. N\u00e4m\u00e4 laarit osallistuvat lohkoihin (engl. blocks), jotka liukuvat kuvan yli askelein siten, ett\u00e4 lohkojen alueet voivat olla p\u00e4\u00e4llekk\u00e4isi\u00e4. Jokaisesta lohkosta saadaan normaaliarvoitu histogrammi, joka yhdistet\u00e4\u00e4n lopulta yhdeksi pitk\u00e4ksi piirrevektoriksi koko kuvalle. Piirrevektorin pituus riippuu solujen ja lohkojen koosta sek\u00e4 histogrammin laarien m\u00e4\u00e4r\u00e4st\u00e4. Sen voi laskea n\u00e4in, jos meill\u00e4 on <code>200x200</code> kuva:</p> <pre><code>ppc = 10                       # pixels per cell\ncbp = 2                        # cells per block\ncells_xy = 200 // ppc          # 20 cells per dimension\nblocks_xy = cells_xy - 1       # 19 blocks per dimension (assuming stride 1)\nfeat_per_block = cbp ** 2 * 9  # 2x2 cells per block, 9 bins per histogram\nfd = blocks_xy ** 2 * feat_per_block\n# Output: 12996\n</code></pre> <p>Voi olla hy\u00f6dyllist\u00e4 silm\u00e4ill\u00e4 l\u00e4pi my\u00f6s: Medium.com | Katthik Mittal: A Gentle Introduction Into The Histogram Of Oriented Gradients</p> <p></p> <p>Kuva 4: HOG-piirteiden visualisointi. Kuva on 200x200 pikseli\u00e4 ja solun koko 10x10 (turkoosi viiva). Keltaiset neli\u00f6t n\u00e4ytt\u00e4v\u00e4t blockin (2x2 solua, yhteens\u00e4 20x20 pikseli\u00e4) kolme ensimm\u00e4ist\u00e4 sijaintia, kun block liukuu yhden solun askelin x-suunnassa. Opacity kasvaa (0.2 \u2192 0.3 \u2192 1.0) havainnollistamaan liukumisen etenemist\u00e4. HOG-kuvassa gradientti m\u00e4\u00e4r\u00e4\u00e4 viivan suunnan ja voimakkuus paksuuden. Kissakuva: Nanobanana.</p> <p>Mit\u00e4 t\u00e4ll\u00e4 siis tekee?</p> <p>Vastaavan HOG-piirrevektorin voisi sy\u00f6tt\u00e4\u00e4 esimerkiksi:</p> <ol> <li>SVM-luokittelijalle</li> <li>FCNN-verkolle</li> </ol> <p>Jos laskisit HOG-piirteet MNIST-numeroista, niin voisit k\u00e4ytt\u00e4\u00e4 FCNN:\u00e4\u00e4 kuten kurssilla aiemminkin on k\u00e4ytetty. Erona olisi, ett\u00e4 pelk\u00e4n pikselin intensiteetin sijaan sy\u00f6tteen\u00e4 olisi tietoa reunojen suunnista ja voimakkuuksista. Neuroverkkojen osalta t\u00e4m\u00e4 l\u00e4hestymistapa on kuitenkin vanhentunut, sill\u00e4 konvoluutioverkot pystyv\u00e4t oppimaan piirteet suoraan kuvista ilman erillist\u00e4 piirrevektorin laskentaa.</p>"},{"location":"konvoluutio/cnn/#fast-ja-sift","title":"FAST ja SIFT","text":"<p>Edell\u00e4 esitellyt LBP ja HOG laskevat piirteit\u00e4 koko kuvasta (tai rajatusta/ikkunoidusta osasta). Toinen l\u00e4hestymistapa on tunnistaa ensin kiinnostavat pisteet (keypoints) kuvasta ja laskea piirrevektori vain n\u00e4iden pisteiden ymp\u00e4rilt\u00e4. Ensimm\u00e4iseen vaiheeseen, jossa tunnistaan kiinnostavat pisteet, voidaan k\u00e4ytt\u00e4\u00e4 erilaisia algoritmeja, kuten: FAST, Harris tai DoG. J\u00e4lkimm\u00e4iseen vaiheeseen, jossa lasketaan kustakin kiinnostavasta pisteest\u00e4 piirrevektori, voidaan k\u00e4ytt\u00e4\u00e4 menetelmi\u00e4 kuten SIFT tai SURF.</p> <p>K\u00e4sitell\u00e4\u00e4n lyhyesti n\u00e4ist\u00e4 kenties yksinkertaisin kombinaatio: FAST + SIFT.</p> <p>FAST (Features from Accelerated Segment Test): Etsii kiinnostavia pisteit\u00e4 vertaamalla pikselin kirkkausarvoa sit\u00e4 ymp\u00e4r\u00f6iviin pikseleihin. T\u00e4m\u00e4 ei ole erityisen kaukana siit\u00e4, miten LBP toimii.</p> <p></p> <p>Kuva 5: FAST-algoritmin pikselimalli. Keskuspikseli (kirkas) verrataan ymp\u00e4r\u00f6iviin pikseleihin (tummat). Jotta pikseli luokiteltaisiin kulmaksi, sen ymp\u00e4rill\u00e4 t\u00e4ytyy olla jatkuva kaari, jossa v\u00e4hint\u00e4\u00e4n n per\u00e4kk\u00e4ist\u00e4 pikseli\u00e4 (s\u00e4teell\u00e4 r) poikkeavat keskuspikselin kirkkaudesta samaan suuntaan \u2013 kaikki joko kirkkaampia tai tummempia \u2013 v\u00e4hint\u00e4\u00e4n kynnysarvon t verran. Kuva: Jingjin Huang, Guoqing Zhou, Xiang Zhou and Rongting Zhang, CC BY 4.0, via Wikimedia Commons</p> <p>SIFT (Scale-Invariant Feature Transform): Kun kiinnostavat pisteet on l\u00f6ydetty FAST:lla, seuraava vaihe on muodostaa piirrevektorit. SIFT:n esitteli David Lowe vuonna 2004 julkaistussa artikkelissaan \"Distinctive Image Features from Scale-Invariant Keypoints\" <sup>17</sup>. SIFT laskee kullekin kiinnostavalle pisteelle piirrevektorin, joka on tyypillisesti 128-ulotteinen. Toteutus ei juuri poikkea HOG:sta, sill\u00e4 SIFT k\u00e4ytt\u00e4\u00e4 my\u00f6s kaltevuuksia (oriented gradients) piirteiden laskentaan. SIFT ottaa 16x16 alueen kiinnostavan pisteen ymp\u00e4rilt\u00e4 ja jakaa sen 4x4 soluun (cells). Jokaisesta solusta lasketaan 8-bittinen histogrammi kaltevuuksista, k\u00e4ytt\u00e4en gaussian-painotusta, jolloin kaukana olevat pikselit vaikuttavat v\u00e4hemm\u00e4n. Lopuksi n\u00e4m\u00e4 histogrammit yhdistet\u00e4\u00e4n yhdeksi pitk\u00e4ksi piirrevektoriksi. 4x4 solua, joissa kussakin 8 laaria, antaa yhteens\u00e4 \\(4 \\times 4 \\times 8 = 128\\)-ulotteisen vektorin.</p> <p>Tip</p> <p>Voi olla hy\u00f6dyllist\u00e4 k\u00e4ytt\u00e4\u00e4 20 sekuntia el\u00e4m\u00e4st\u00e4\u00e4n katsoen kahta seuraavaa linkki\u00e4, joissa esitell\u00e4\u00e4n kombinaatioty\u00f6kalut, jotka hoitavat sek\u00e4 kiinnostavien pisteiden etsinn\u00e4n ett\u00e4 piirrevektorin laskennan. Katso erityisesti kuvat:</p> <ul> <li>scikit-image: ORB feature detector and binary descriptor</li> <li>scikit-image: SIFT feature detector and descriptor extractor</li> </ul> <p>Bonus: jos aihe kiinnostaa enemm\u00e4nkin, tutustu OpenCV:n dokumentaation osioon Feature Detection and Description. Jo pelkk\u00e4 kuvien katselu voi konkretisoida aihetta.</p> <p>Mit\u00e4 n\u00e4ill\u00e4 siis tekeek\u00e4\u00e4n?</p> <p>Jos j\u00e4i yh\u00e4 vaivaamaan, mit\u00e4 n\u00e4ill\u00e4 piirrevektoreilla tekee, ja ett\u00e4 eik\u00f6s n\u00e4it\u00e4 synny joka kuvasta eri m\u00e4\u00e4r\u00e4, niin lyhyt vastaus:</p> <ol> <li>Ker\u00e4t\u00e4\u00e4n kaikista kuvista kaikki piirrevektorit (esim. SIFT). T\u00e4m\u00e4 on vocabulary.</li> <li>Klusteroidaan vocabulary:n piirrevektorit (esim. K-means) ja m\u00e4\u00e4ritell\u00e4\u00e4n kunkin klusterin keskipiste \"visuaaliseksi sanaksi\".</li> <li>Lasketaan kullekin kuvalle histogrammi, joka kuvaa, kuinka monta kertaa kukin visuaalinen sana esiintyy kyseisess\u00e4 kuvassa.</li> </ol> <p>N\u00e4ist\u00e4 voi sitten rakentaa: </p> <ul> <li>Google Reverse Image Search -tyyppisen sovelluksen, jossa sy\u00f6tet\u00e4\u00e4n kuva ja haetaan samankaltaisia kuvia.</li> <li>...tai tyypillisen luokittelijan.</li> </ul> <p>Pidempi ja visuaalisempi vastaus: Pinecone | Bag of Visual Words</p>"},{"location":"konvoluutio/cnn/#piirrevektorit-konvoluutioverkoissa","title":"Piirrevektorit konvoluutioverkoissa","text":""},{"location":"konvoluutio/cnn/#arkkitehtuuri","title":"Arkkitehtuuri","text":"<p>Aiemmasta opitusta on hy\u00f6ty\u00e4, sill\u00e4 konvoluutioverkkojen head eli viimeiset kerrokset ovat tuttuja FC-kerroksia (eli fully connected). Mallin viimeiset kerrokset ovat siis tyypillinen FCNN, joka ottaa sy\u00f6tteen\u00e4\u00e4n piirrevektorin ja tuottaa luokitusennusteen. Konvoluutioverkkojen voima piilee kuitenkin niiden body-osassa, joka koostuu uudenlaisista termeist\u00e4: konvoluutiokerros (convolutional) ja koontikerros (pooling). Malli on toki yh\u00e4 eteenp\u00e4in kytketty (feedforward), mutta ei en\u00e4\u00e4 t\u00e4ysin kytketty (fully connected).</p> <p></p> <p>Kuva 6: Yksinkertainen konvoluutioverkon arkkitehtuuri. Kuva on luotu NN-SVG-ty\u00f6kalulla.</p> <p>Yll\u00e4 oleva kuva havainnollistaa konvoluutioverkon arkkitehtuuria yksinkertaistetusti. Sy\u00f6te on 224\u00d7224\u00d73 RGB-kuva. Verkko koostuu kolmesta p\u00e4\u00e4osasta:</p> <p>1. Konvoluutiokerrokset (body): Kolme suurta laatikkoa vasemmalla edustavat konvoluutiokerroksia, jotka tunnistavat kuvan piirteit\u00e4. Ensimm\u00e4inen kerros tuottaa 96 kappaletta 55\u00d755-kokoisia piirrekarttoja. Kolmannessa kerroksessa piirrekartat ovat kutistuneet 13\u00d713-kokoisiksi, mutta niit\u00e4 on enemm\u00e4n (384 kpl). Kerroksien v\u00e4liss\u00e4 n\u00e4kyv\u00e4 sini-punainen \"lyijykyn\u00e4\" kuvaa konvoluutio-operaatiota: lyijykyn\u00e4n runko edustaa \\(n \\times n\\) suodinta (kernel), joka liukuu sy\u00f6tteen yli, ja k\u00e4rki osoittaa kohtaan, johon suotimen tulos tallennetaan.</p> <p>2. Litist\u00e4minen (flatten): Konvoluutiokerrosten tuottamat 3D-piirrekartat litistet\u00e4\u00e4n yhdeksi pitk\u00e4ksi vektoriksi.</p> <p>3. T\u00e4ysin kytketyt kerrokset (head): Oikealla olevat kaksi pystysuoraa palkkia edustavat perinteisi\u00e4 FCNN-kerroksia. N\u00e4m\u00e4 ottavat litistetyn piirrevektorin sy\u00f6tteen\u00e4\u00e4n ja tuottavat lopulta 10-ulotteisen logit-vektorin (t\u00e4ss\u00e4 oletetaan 10 luokkaa).</p> <p>Warning</p> <p>T\u00e4m\u00e4 on AlexNet-tyyppinen visualisointi, jossa pooling-kerrokset on j\u00e4tetty pois yksinkertaisuuden vuoksi. Todellisuudessa pooling-kerrokset pienent\u00e4v\u00e4t piirrekarttojen kokoa konvoluutiokerrosten v\u00e4liss\u00e4.</p>"},{"location":"konvoluutio/cnn/#konvoluutiokerros","title":"Konvoluutiokerros","text":"<p>Kuva 7: 2D-konvoluutiokerros. Kukin l\u00e4ht\u00f6arvo on painotettu summa l\u00e4himmist\u00e4 3\u00d73 sy\u00f6tteist\u00e4 (plus bias ja aktivointi). Yl\u00e4rivin kuvat a ja b esittelev\u00e4t, kuinka suodin liikkuu kuvassa. Seuraava kerros (\\(H_1\\) eli k\u00e4yt\u00e4nn\u00f6ss\u00e4 piirrekartta eli feature map) syntyy 3x3 sy\u00f6tteen ja painojen pistetulosta. Alarivin kuvat c ja d esittelev\u00e4t, kuinka nollilla toppaamiinen (zero-padding) mahdollistavat reunapikseleiden arvojen k\u00e4yt\u00f6n. <sup>3</sup></p> <p></p> <p>Kuva 8: RGB-kuvassa, kuten my\u00f6s my\u00f6hemmiss\u00e4 piirrekartoissa, on enemm\u00e4n kuin 1 kanava. RGB-kuvan tapauksessa filtteri on kokoa \\(3 \\times 3 \\times 3\\) (leveys x korkeus x syvyys). Jokainen kanava (R, G, B) kerrotaan vastaavalla suotimella. N\u00e4m\u00e4 summataan yhteen, lis\u00e4t\u00e4\u00e4n bias, ja aktivoidaan jolloin saadaan yksi arvo piirrekarttaan. <sup>3</sup></p> <p>Pys\u00e4hdy t\u00e4ss\u00e4 v\u00e4liss\u00e4 ja lue t\u00e4m\u00e4 visuaalisesti ja selke\u00e4sti toteutettu selostus aiheesta: A Comprehensive Guide to Convolutional Neural Networks \u2014 the ELI5 way</p> <p>Konvoluutiokerros suorittaa sy\u00f6tteelle konvoluution, joka on matemaattinen operaatio, jossa pieni suodin (kernel/filter) liukuu sy\u00f6tteen yli ja laskee pistetulon (dot product) suotimen ja sy\u00f6tteen vastaavien osien v\u00e4lill\u00e4. T\u00e4m\u00e4 prosessi mahdollistaa paikallisten piirteiden, kuten reunojen, kulmien ja tekstuurien, tunnistamisen kuvasta. Aiheeseen tutustumiseen auttaa, jos tutkit, kuinka erilaiset suotimet (esim. reunojen tunnistamiseen tarkoitetut Sobel-suotimet) toimivat. T\u00e4h\u00e4n on mainio apusivusto: Setosa.io | Image Kernels explained visually.</p> <p>Per\u00e4kk\u00e4in kytketyt konvoluutiokerrokset mahdollistavat yh\u00e4 monimutkaisempien piirteiden oppimisen. Alkuvaiheen kerrokset saattavat tunnistaa yksinkertaisia piirteit\u00e4, kuten reunat ja kulmat, kun taas syvemm\u00e4t kerrokset voivat yhdistell\u00e4 n\u00e4it\u00e4 piirteit\u00e4 muodostaakseen monimutkaisempia kuvioita, kuten kasvoja tai esineit\u00e4. Kukin konvoluutiokerros ottaa seuraavat parametrit sis\u00e4\u00e4ns\u00e4 <sup>18</sup>:</p> <ul> <li>Sy\u00f6te: \\(W_1 \\times H_1 \\times D_1\\) (leveys x korkeus x syvyys/kanavat)</li> <li>Filttereiden m\u00e4\u00e4r\u00e4: \\(K\\) (eli syvyyssuunnan koko)</li> <li>Suotimen koko: \\(F\\) (esim. \\(3 \\times 3\\))</li> <li>Askel (stride): \\(S\\) (usein 1)</li> <li>Toppaus (padding): \\(P\\) (usein <code>j // 2</code> eli 'same' toppaus)</li> </ul> <p>Konvoluutiokerroksen l\u00e4ht\u00f6 t\u00e4ten kokoa:</p> <ul> <li>Leveys: \\(W_2 = \\frac{W_1 - F + 2P}{S} + 1\\)</li> <li>Korkeus: \\(H_2 = \\frac{H_1 - F + 2P}{S} + 1\\)</li> <li>Syvyys: \\(D_2 = K\\)</li> </ul> <p>T\u00e4m\u00e4 osuus on j\u00e4tetty lyhyeksi, koska aihe on niin kattavasti selitetty kurssikirjoissa, yll\u00e4 olevassa Medium-artikkelissa ja esimerkiksi StatQuestin sek\u00e4 3Blue1Brownin videoissa.</p>"},{"location":"konvoluutio/cnn/#koontikerros","title":"Koontikerros","text":"<p>Koontikerros (pooling layer) on konvoluutioverkon komponentti, joka suorittaa alin\u00e4ytteist\u00e4misen (downsampling) sy\u00f6tteelle. T\u00e4m\u00e4n kerroksen p\u00e4\u00e4tarkoituksena on v\u00e4hent\u00e4\u00e4 piirrekarttojen (engl. feature maps, activation maps) spatiaalista kokoa (leveys ja korkeus), mik\u00e4 auttaa v\u00e4hent\u00e4m\u00e4\u00e4n laskennallista kuormitusta, muistink\u00e4ytt\u00f6\u00e4 ja ylikoulutuksen riski\u00e4. Koontikerros tiivist\u00e4\u00e4 t\u00e4rkeimm\u00e4t piirteet s\u00e4ilytt\u00e4en samalla olennaisen informaation. N\u00e4it\u00e4 on montaa eri sorttia, mutta yleisimm\u00e4t ovat max-pooling ja average-pooling. N\u00e4iden PyTorch-toteutukset l\u00f6ytyv\u00e4t <code>torch.nn.MaxPool2d</code> ja <code>torch.nn.AvgPool2d</code> -luokista. N\u00e4iden 2-ulotteisten koontikerrosten lis\u00e4ksi on olemassa my\u00f6s 1-ulotteisia ja 3-ulotteisia versioita, joita k\u00e4ytet\u00e4\u00e4n vastaavasti 1D- ja 3D-datassa. G\u00e9ron esittelee my\u00f6s harvinaisemmat tyypit: depthwise pooling ja global average pooling <sup>1</sup>.</p> <p></p> <p>Kuva 9: Max-pooling toteutettuna 5x5 taulukkoa vasten. Suotimen koko on 3x3. Ylemm\u00e4ss\u00e4 esimerkiss\u00e4 askel on 1, alemmassa askel on 2. Kummassakin tapauksessa on esitelty kolme ensimm\u00e4ist\u00e4 askelta.</p> <p>Kukin koontikerros ottaa seuraavat parametrit sis\u00e4\u00e4ns\u00e4 <sup>18</sup>:</p> <ul> <li>Sy\u00f6te: \\(W_1 \\times H_1 \\times D_1\\) (leveys, korkeus, syvyys/kanavat)</li> <li>Suotimen koko: \\(F\\) (esim. \\(2 \\times 2\\))</li> <li>Askel (stride): \\(S\\)</li> </ul> <p>Koontikerroksen l\u00e4ht\u00f6 t\u00e4ten kokoa:</p> <ul> <li>Leveys: \\(W_2 = \\frac{W_1 - F}{S} + 1\\)</li> <li>Korkeus: \\(H_2 = \\frac{H_1 - F}{S} + 1\\)</li> <li>Syvyys: \\(D_2 = D_1\\)</li> </ul> <p>Hyvin tyypillinen koontikerros on \\(2 \\times 2\\) max-pooling, jossa askeleena on 2. T\u00e4m\u00e4 tarkoittaa, ett\u00e4 kuvan leveys ja korkeus puolittuvat jokaisella pooling-kerroksella. K\u00e4rjist\u00e4en kyseess\u00e4 on siis <code>resize(50 %, interpolation=max)</code>-operaatio. Muista kuitenkin, ett\u00e4 t\u00e4ss\u00e4 ei sin\u00e4ns\u00e4 en\u00e4\u00e4 pienennet\u00e4 kuvaa vaan piirrekarttoja.</p>"},{"location":"konvoluutio/cnn/#case-study-fractional-max-pooling-graham-2014","title":"Case Study: Fractional Max-Pooling (Graham, 2014)","text":"<p>T\u00e4ss\u00e4 osiossa syvennyt\u00e4\u00e4n Benjamin Grahamin vuonna 2014 esittelem\u00e4\u00e4n Fractional Max-Pooling -arkkitehtuuriin, joka saavutti aikanaan poikkeuksellisen alle 4 % virheasteen CIFAR-10-datasetill\u00e4 <sup>2</sup>. Malli on erinomainen esimerkki siit\u00e4, kuinka konvoluutioverkkojen suunnittelussa voidaan poiketa valtavirran konventioista ja saavuttaa silti huipputuloksia. Motivaatio arkkitehtuurin valinnalle case studyyn on juurikin t\u00e4m\u00e4: \u00e4l\u00e4 lukitse itse\u00e4si ajattelemaan, ett\u00e4 on vain yksi tapa rakentaa konvoluutioverkkoja tai muitakaan neuroverkkoja.</p> <p>Case studyn koodi on toteutettu <code>501_fractional_max_pooling.py</code>-tiedostossa. T\u00e4h\u00e4n osioon liittyy osion ensimm\u00e4inen teht\u00e4v\u00e4. Lue se alta.</p>"},{"location":"konvoluutio/cnn/#arkkitehtuurin-filosofia-ja-suotimien-kasvu","title":"Arkkitehtuurin filosofia ja suotimien kasvu","text":"<p>Tyypillisesti konvoluutioverkoissa, kuten VGG:ss\u00e4 tai ResNetiss\u00e4, kanavien m\u00e4\u00e4r\u00e4 kaksinkertaistetaan tietyin v\u00e4liajoin (esim. 64 \\(\\to\\) 128). Grahamin mallissa l\u00e4hestymistapa on kuitenkin erilainen: kanavien m\u00e4\u00e4r\u00e4 kasvaa lineaarisesti kaavalla \\(160 \\times n\\), miss\u00e4 \\(n\\) on kerroksen j\u00e4rjestysnumero <sup>2</sup>.</p>"},{"location":"konvoluutio/cnn/#fractional-max-pooling-mekanismi","title":"Fractional Max-Pooling -mekanismi","text":"<p>Mallin keskeinen innovaatio on nimens\u00e4 mukainen Fractional Max-Pooling. Perinteinen \\(2\\times2\\) max-pooling puolittaa kuvan koon jokaisella askeleella, mik\u00e4 rajoittaa verkon syvyytt\u00e4 pienill\u00e4 kuvilla. Grahamin ratkaisussa skaalauskerroin on \\(\\sqrt[3]{2}\\) (noin 1,26) <sup>2</sup>. T\u00e4m\u00e4 maltillisempi koon pienent\u00e4minen mahdollistaa huomattavasti syvemm\u00e4t verkot ilman, ett\u00e4 piirrekartat kutistuvat liian nopeasti \\(1\\times1\\)-pikselin kokoon.</p> <p>Lis\u00e4ksi menetelm\u00e4 hy\u00f6dynt\u00e4\u00e4 satunnaisuutta. Pooling-alueet voidaan valita joko limitt\u00e4in (overlapping) tai erillisin\u00e4 (disjoint) ja niiden sijainti arvotaan <sup>2</sup>. Kannattaa katsoa Figure 1 alkuper\u00e4isest\u00e4 julkaisusta: se selvent\u00e4\u00e4 asiaa, kuinka digitaalisessa kuvassa voi k\u00e4ytt\u00e4\u00e4 poolingia, joka ei ole kahdella jaollinen.</p>"},{"location":"konvoluutio/cnn/#moderni-head-rakenne","title":"Moderni \"Head\" -rakenne","text":"<p>Verkon loppuosa poikkeaa my\u00f6s tyypillisest\u00e4 CNN:st\u00e4. Sen sijaan, ett\u00e4 piirrekartat litistett\u00e4isiin (flatten) ja sy\u00f6tett\u00e4isiin tiheille (Dense/Linear) kerroksille, malli k\u00e4ytt\u00e4\u00e4 \\(1\\times1\\) konvoluutiota (C1) <sup>2</sup>. T\u00e4m\u00e4 kerros projisoi piirteet suoraan luokkien lukum\u00e4\u00e4r\u00e4\u00e4 vastaavaksi vektoriksi.</p>"},{"location":"konvoluutio/cnn/#regularisointi-ja-koulutuksen-erikoisuudet","title":"Regularisointi ja koulutuksen erikoisuudet","text":"<p>Koska malli on valtava suhteessa datasetin kokoon, regularisointi on kriittist\u00e4. Mallissa sovelletaan \"kasvavaa dropoutia\": ensimm\u00e4isiss\u00e4 piilotetuissa kerroksissa dropout on 0 %, ja se kasvaa lineaarisesti 50 %:iin verkon loppup\u00e4\u00e4t\u00e4 kohden. <sup>2</sup></p> <p>Toinen tekninen erikoisuus liittyy verkon sy\u00f6tteen kokoon. Koska pooling-suhde on murtoluku, verkon vaatima sy\u00f6tekoko ei ole triviaali laskea. K\u00e4yt\u00e4nn\u00f6ss\u00e4 haluttu output-koko p\u00e4\u00e4tet\u00e4\u00e4n ensin, ja vaadittu input-koko lasketaan \"takaperin\" kertomalla kokoa skaalauskertoimella jokaisen kerroksen kohdalla. T\u00e4m\u00e4 johtaa usein siihen, ett\u00e4 alkuper\u00e4isi\u00e4 kuvia on pehmustettava (padding) runsaasti.</p>"},{"location":"konvoluutio/cnn/#inferenssi-verkko-on-itsessaan-ensemble","title":"Inferenssi: Verkko on itsess\u00e4\u00e4n ensemble","text":"<p>Pooling-vaiheen satunnaisuudesta johtuen saman kuvan ajaminen verkon l\u00e4pi useaan kertaan tuottaa hieman erilaisia ennusteita. T\u00e4t\u00e4 ominaisuutta hy\u00f6dynnet\u00e4\u00e4n testausvaiheessa (inference). Lopullinen luokitus ei perustu yhteen ajokertaan, vaan usean (esim. 12) ajokerran keskiarvoon (Model Averaging). T\u00e4m\u00e4 toimii ik\u00e4\u00e4n kuin \"k\u00f6yh\u00e4n miehen ensemble-menetelm\u00e4n\u00e4\", parantaen luotettavuutta ilman tarvetta kouluttaa useita erillisi\u00e4 verkkoja. <sup>2</sup> T\u00e4t\u00e4 ei ole toteutettu kurssin koodissa, mutta voit halutessasi kokeilla t\u00e4t\u00e4 itse. Se hoituisi jotakuinkin n\u00e4in:</p> <pre><code>outputs = [model(image) for _ in range(12)]   # Run 12 times\navg_output = torch.stack(outputs).mean(dim=0) # Average predictions\n</code></pre>"},{"location":"konvoluutio/cnn/#tehtavat","title":"Teht\u00e4v\u00e4t","text":"<p>Teht\u00e4v\u00e4: Tutustuminen Fractional Max-Pooling -toteutukseen</p> <p>Avaa tiedosto <code>notebooks/nb/500/501_fractional_max_pooling.py</code>. Tutki koodia ja pohdi oppimisp\u00e4iv\u00e4kirjassasi seuraavia kysymyksi\u00e4:</p> <ul> <li>K\u00e4\u00e4nteinen koon laskenta: Miten <code>get_fmp_sizes</code>-funktio toimii? Miksi verkon kerrosten koot lasketaan \"lopusta alkuun\" (output \\(\\to\\) input)?</li> <li>Dynaaminen padding: Toteutuksessa k\u00e4ytet\u00e4\u00e4n dynaamista paddingia (<code>pad_total</code>). Miksi t\u00e4m\u00e4 on v\u00e4ltt\u00e4m\u00e4t\u00f6nt\u00e4 juuri t\u00e4ss\u00e4 arkkitehtuurissa, kun taas esimerkiksi VGG-verkossa p\u00e4rj\u00e4t\u00e4\u00e4n kiinte\u00e4ll\u00e4 paddingilla?</li> <li>Verkon \"p\u00e4\u00e4\" (Head): Miten <code>FMPNet</code>-luokan <code>forward</code>-metodin loppuosa eroaa perinteisest\u00e4 <code>nn.Linear</code>-kerroksesta? Miksi t\u00e4ss\u00e4 on k\u00e4ytetty \\(1\\times1\\) konvoluutiota (<code>convC1</code>)? Onko kenties niin, ett\u00e4 matemaattisesti \\(1\\times1\\) konvoluutio \\(1\\times1\\) kokoisella spatiaalisella kartalla on identtisen t\u00e4ysin kytketyn kerroksen kanssa?</li> <li>Ensemble-ennustaminen: Miten mallin ennusteet lasketaan testausvaiheessa? Miksi sama kuva sy\u00f6tet\u00e4\u00e4n verkolle useita kertoja? Eik\u00f6 neuroverkko olekaan deterministinen? Miksi minun toteutus toimii, vaikka siin\u00e4 ei sy\u00f6tet\u00e4 kuin kerran?</li> </ul> <p>Mallin kouluttamiseen meni opettajan GeForce RTX 3060 Ti:ll\u00e4 yli 11 tuntia (300 epookkia, noin 2 min 17 sek per epookki). Saat kouluttaa mallin itse tai voit k\u00e4ytt\u00e4\u00e4 valmista mallia, joka on tallennettu tiedostoon <code>notebooks/gitlfs-store/502_cifar10_fractionalmaxp.pth</code>. Huomaa, ett\u00e4 repositorio tulee kloonata Git LFS -tuen kanssa, jotta malli l\u00f6ytyy koneeltasi. Jos t\u00e4m\u00e4 on t\u00e4ysin vieras konsepti, lue: How to Git | GitLab: LFS</p> <p>Teht\u00e4v\u00e4: FMP ja MNIST</p> <p>Toteuta tiedostoon <code>notebooks/nb/500/503_fractional_max_pool_MNIST.py</code> versio Grahamin mallista, joka on sovitettu MNIST-datasetille.</p> <p>Alkuper\u00e4isess\u00e4 paperissa (Graham, 2014) on m\u00e4\u00e4ritelty MNIST:lle kevyempi arkkitehtuuri kuin CIFAR-10:lle. Etsi paperista (tai kokeile itse) sopivat parametrit ja muokkaa koodia seuraavasti:</p> <ul> <li>Dataset: Vaihda CIFAR-10 \\(\\to\\) MNIST. Huomioi, ett\u00e4 MNIST on mustavalkoinen (1 kanava), kun taas CIFAR-10 on v\u00e4rillinen (3 kanavaa).</li> <li>Arkkitehtuuri: Paperin mukaan MNIST-mallissa k\u00e4ytet\u00e4\u00e4n eri m\u00e4\u00e4r\u00e4\u00e4 kerroksia ja eri kasvukerrointa.<ul> <li>CIFAR-10-mallissa kerroksia oli 12 ja kasvukerroin suuri.</li> <li>MNIST-mallille riitt\u00e4\u00e4 v\u00e4hempi m\u00e4\u00e4r\u00e4 kerroksia ja pienempi kasvukerroin.</li> <li>My\u00f6s skaalauskerroin \\(\\alpha\\) voi olla eri (esim. \\(\\sqrt{2}\\) vs \\(\\sqrt[3]{2}\\)), jotta kuva kutistuu sopivasti 28x28-koosta.</li> </ul> </li> <li>Tavoite: Kouluta malli ja vertaa saavuttamaasi tarkkuutta.<ul> <li>P\u00e4rj\u00e4nnet reilusti pienemm\u00e4ll\u00e4 epookkim\u00e4\u00e4r\u00e4ll\u00e4 kuin 300.   </li> </ul> </li> </ul> <p>Oikean arkkitehtuurin my\u00f6t\u00e4 mallin luomisen j\u00e4lkeen pit\u00e4isi tulostua <code>Total trainable parameters: 438,826</code> ja <code>debug_forward_pass()</code>-funktion pit\u00e4isi tulostaa jotakuinkin seuraavaa viimeisiss\u00e4 riveiss\u00e4\u00e4n::</p> <pre><code>[Head] Input: torch.Size([1, 192, 2, 2]) (Expected 2x2)\n-&gt; ConvC2 (2x2 kernel): torch.Size([1, 192, 1, 1]) (Should be 1x1)\n-&gt; ConvC1 (1x1 kernel): torch.Size([1, 10, 1, 1]) (Channels = Num Classes)\n-&gt; Final Output (Flattened): torch.Size([1, 10])\n</code></pre> <p>Tip</p> <p>Voit kokeilla, kauan mallin koulutus kest\u00e4\u00e4 GPU vs. CPU. Jos haluat s\u00e4\u00e4st\u00e4\u00e4 aikaa, selvit\u00e4 10 epookkiin kuluva aika ja skaalaa se haluamaasi epookkim\u00e4\u00e4r\u00e4\u00e4n. Opettajan GPU:lla kesti noin 7 sekuntia per epookki (batch size 32). Jos CPU olisi k\u00e4yt\u00f6ss\u00e4, niin mik\u00e4 seuraavista olisi oikea arvio?</p> <ul> <li>10 sekuntia per epookki (+ 43 %)</li> <li>30 sekuntia per epookki (+ 329 %)</li> <li>1 min 30 s per epookki (+ 1186 %)</li> <li>2 min 30 s per epookki (+ 2043 %)</li> </ul> <p>Teht\u00e4v\u00e4: LeNet ja MNIST</p> <p>Toteuta tiedostoon <code>notebooks/nb/500/504_lenet_MNIST.py</code> LeNet-5 -arkkitehtuuri MNIST-datasetille. Vertaile sen suorituskyky\u00e4 toteuttamaasi  Grahamin Fractional Max-Pooling -malliin. Saat itse valita, toteutatko mahdollisimman orjallisesti alkuper\u00e4isen mallin vai Adrian Rosebrockin tulkitseman modernisoidun version. </p> <p>Vaihtoehto 1: Orjallinen LeNet-5</p> <p>Mallin arkkitehtuuri l\u00f6ytyy LeCunin alkuper\u00e4isest\u00e4 paperista <sup>5</sup>. Jos haluat olla uskollinenalkuper\u00e4iselle arkkitehtuurille, voit k\u00e4ytt\u00e4\u00e4 LeCunin tanh-aktivointifunktiota, jonka toteutus on \\(1.7159 \\times \\tanh(\\frac{2}{3}x)\\).</p> <p>Alkuper\u00e4isess\u00e4 paperissa mainitaan 32x32 sy\u00f6tekoko. MNIST on 28x28, joten voit lis\u00e4t\u00e4 kuviin 2 pikselin reunuksen (padding) joka reunalle, jolloin kuvat ovat 32x32-kokoisia. T\u00e4m\u00e4 prosessi liittyy paperin lauseeseen: \"In the first version, the images were centered in a 28 x 28 image by computing the center of mass of the pixels, and translating the image so as to position this point at the center of the 28x28 field In some instances, this 28x28 field was ex tended to 32x32 with background pixels\".</p> <p>Vaihtoehto 2: Modernisoitu LeNet-5</p> <p>Modernisoitu versio on Adrian Rosebrockin blogipostauksesta LeNet \u2013 Convolutional Neural Network in Python tai h\u00e4nen kirjastaan Deep Learning for Computer Vision with Python. T\u00e4ss\u00e4 versiossa k\u00e4ytet\u00e4\u00e4n ReLU-aktivointia. Arkkitehtuuri on seuraava:</p> Layer Type Output Size Filter Size / Stride Input 28x28x1 Conv1 28x28x20 5x5 / K = 20 Act1 28x28x20 ReLU Pool1 14x14x20 2x2 / S = 2 Conv2 14x14x50 5x5 / K = 50 Act2 14x14x50 ReLU Pool2 7x7x50 2x2 / S = 2 FC1 500 Act3 500 ReLU FC2 10 Softmax 10 <p>Teht\u00e4v\u00e4: (Valinnainen) HOG</p> <p>T\u00e4m\u00e4 on valinnainen teht\u00e4v\u00e4. Kokeile <code>505_hog.py</code>-tiedostoa jotakin kuvaa vasten. Kyseisell\u00e4 Notebookilla on luotu yll\u00e4 oleva \"Kissa hypp\u00e4\u00e4 hularenkaasta\"-triptyykki.</p>"},{"location":"konvoluutio/cnn/#lahteet","title":"L\u00e4hteet","text":"<ol> <li> <p>G\u00e9ron, A. Hands-On Machine Learning with Scikit-Learn and PyTorch. O'Reilly. 2025.\u00a0\u21a9\u21a9\u21a9\u21a9</p> </li> <li> <p>Graham, B. Fractional Max-Pooling. University of Warwick. 2014 (version 4: 2015). https://doi.org/10.48550/arXiv.1412.6071\u00a0\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9</p> </li> <li> <p>Prince, S. Understanding Deep Learning. The MIT Press. 2023. https://udlbook.github.io/udlbook/\u00a0\u21a9\u21a9\u21a9\u21a9</p> </li> <li> <p>Fukushima, K. Neocognitron: A Self-organizing Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position. Princeton. https://www.cs.princeton.edu/courses/archive/spr08/cos598B/Readings/Fukushima1980.pdf\u00a0\u21a9</p> </li> <li> <p>LeCun, Y., Bottou, L., Bengio, Y., &amp; Haffner, P. Gradient-Based Learning Applied to Document Recognition. Proceedings of the IEEE, 86(11). http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf\u00a0\u21a9\u21a9</p> </li> <li> <p>Krizhevsky, A., Sutskever, I., &amp; Hinton, G. E. ImageNet Classification with Deep Convolutional Neural Networks. https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf\u00a0\u21a9</p> </li> <li> <p>Szegedy, C. et. al. Going Deeper with Convolutions. https://arxiv.org/abs/1409.4842\u00a0\u21a9</p> </li> <li> <p>Simonyan, K., &amp; Zisserman, A. Very Deep Convolutional Networks for Large-Scale Image Recognition. https://arxiv.org/abs/1409.1556\u00a0\u21a9</p> </li> <li> <p>Hassan, M. VGG16 \u2013 Convolutional Network for Classification and Detection. Neurohive. https://neurohive.io/en/popular-networks/vgg16/\u00a0\u21a9</p> </li> <li> <p>He, K., Zhang, X., Ren, S., &amp; Sun, J. Deep Residual Learning for Image Recognition. https://arxiv.org/abs/1512.03385\u00a0\u21a9</p> </li> <li> <p>Azeem. Understanding ResNet Architecture: A Deep Dive into Residual Neural Network. https://medium.com/@ibtedaazeem/understanding-resnet-architecture-a-deep-dive-into-residual-neural-network-2c792e6537a9\u00a0\u21a9</p> </li> <li> <p>Ronneberger, O., Fischer, P., &amp; Brox, T. U-Net: Convolutional Networks for Biomedical Image Segmentation. https://arxiv.org/abs/1505.04597\u00a0\u21a9</p> </li> <li> <p>He, K., Gkioxari, G., Doll\u00e1r, P., &amp; Girshick, R. Mask R-CNN. https://arxiv.org/abs/1703.06870\u00a0\u21a9</p> </li> <li> <p>Huang, G., Liu, Z., Van Der Maaten, L., &amp; Weinberger, K. Q. Densely Connected Convolutional Networks. https://arxiv.org/abs/1608.06993\u00a0\u21a9</p> </li> <li> <p>Dosovitskiy, A. et. al. An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. https://arxiv.org/abs/2010.11929\u00a0\u21a9</p> </li> <li> <p>Ojala, T., Pietik\u00e4inen, M., &amp; M\u00e4enp\u00e4\u00e4, T. Multiresolution Gray Scale and Rotation Invariant Texture Classification with Local Binary Patterns. IEEE Transactions on Pattern Analysis and Machine Intelligence, 24(7), 971-987. 2002. doi: 10.1109/TPAMI.2002.1017623\u00a0\u21a9</p> </li> <li> <p>Lowe, D. G. Distinctive Image Features from Scale-Invariant Keypoints. 2004. https://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf\u00a0\u21a9</p> </li> <li> <p>Rosebrock, A. PyImageSearch Gurus Course: 8.5.1 A CNN Primer. https://www.pyimagesearch.com/pyimagesearch-gurus-course/\u00a0\u21a9\u21a9</p> </li> </ol>"},{"location":"mallinnus/datanlataus/","title":"Datan lataus","text":""},{"location":"mallinnus/datanlataus/#datan-lataus-pytorchissa","title":"Datan lataus PyTorchissa","text":"<p>PyTorch tarjoaa <code>torch.utils.data</code>-moduulissa kaksi luokkaa, jotka helpottavat datan k\u00e4sittely\u00e4: <code>Dataset</code> ja <code>DataLoader</code>. Lis\u00e4ksi l\u00f6ytyy esimerkiksi <code>TensorDataset</code>-luokka, josta voi olla apua harjoitellessa.</p> <ul> <li>Dataset on luokka, joka k\u00e4\u00e4rii sis\u00e4\u00e4ns\u00e4 datan ja labelit.</li> <li>DataLoader on luokka, joka k\u00e4\u00e4rii yll\u00e4 olevan iteroitavaksi objektiksi.</li> </ul>"},{"location":"mallinnus/datanlataus/#tensordataset","title":"TensorDataset","text":"<p>K\u00e4yt\u00e4nn\u00f6ss\u00e4 voimme siis k\u00e4ytt\u00e4\u00e4 mit\u00e4 tahansa tensoreita ja k\u00e4\u00e4ri\u00e4 ne datasetiksi, n\u00e4in:</p> <pre><code># 5 samples with 3 features each\nX = torch.tensor([\n    [1.0, 2.0, 3.0],\n    [4.0, 5.0, 6.0],\n    [7.0, 8.0, 9.0],\n    [1.5, 2.5, 3.5],\n    [4.5, 5.5, 6.5]\n])\n\n# Binary labels\ny = torch.tensor([0, 1, 1, 0, 1])\n\n# Dataset\ndataset = TensorDataset(X, y)\n</code></pre> <p>Nyt voimme kaivaa datasetist\u00e4 yksitt\u00e4isi\u00e4 n\u00e4ytteit\u00e4:</p> <pre><code>data, label = dataset[0]\n# tensor([1.0, 2.0, 3.0])\n# tensor(0)\n</code></pre>"},{"location":"mallinnus/datanlataus/#tee-se-itse","title":"Tee-se-itse","text":"<p>Yksinkertaisimmillaan <code>Dataset</code>-luokan tarvitsee toteuttaa kaksi metodia: <code>__len__</code> ja <code>__getitem__</code>, joista tosin ensimm\u00e4inen on optional. Jos alaviivoilla ymp\u00e4r\u00f6idyt funktiot ovat sinulle vieraita, niin ne ovat Pythonin erikoismetodeja, jotka vastaavat, kun objektia kutsutaan <code>len(dataset)</code>-funktiolla tai objektia yritet\u00e4\u00e4n viipaloida (engl. slice) hakasulkeilla <code>dataset[idx]</code> tai <code>dataset[start:stop]</code>.</p> <pre><code>class CustomDataset(Dataset):\n    def __init__(self, data, labels):\n        self.data = data\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        return self.data[idx], self.labels[idx]\n</code></pre> <p>Luonnollisesti voit tehd\u00e4 datasetist\u00e4 aivan mit\u00e4 tahansa. Vain ohjelmointitaitosi ovat rajana. Voit toteuttaa esimerkiksi: </p> <ul> <li>Etsi labelit indeksitiedostosta (<code>data/labels.txt</code>)</li> <li>Lue kuvat kovalevylt\u00e4 (<code>data/train.parquet</code>, ...)<ul> <li>Tai kenties lataa S3:sta (jos <code>download=True</code>)</li> <li>Tai varoita jos tuoreempi data on saatavilla verkosta</li> </ul> </li> <li>Esik\u00e4sittele dataa lennossa (jos <code>transform</code>-parametri on m\u00e4\u00e4ritelty)</li> <li>Palauta vain jokin tietty versio/subset datasta (esim. <code>train=True</code>)</li> <li>Parametri <code>obj.classes</code> sis\u00e4lt\u00e4en ihmisluettavat luokat</li> <li>Parametri <code>obj.class_to_idx</code> m\u00e4\u00e4rittelee, mik\u00e4 luokka vastaa mit\u00e4kin indeksi\u00e4</li> </ul>"},{"location":"mallinnus/datanlataus/#jako-koulutus-ja-testidatasettiin","title":"Jako koulutus- ja testidatasettiin","text":"<p>Yleinen k\u00e4yt\u00e4nt\u00f6 on jakaa data koulutus- ja testidatasettiin. T\u00e4m\u00e4 onnistuu helposti <code>torch.utils.data.random_split</code>-funktiolla <sup>1</sup>:</p> <pre><code>from torch.utils.data import random_split\n\nds = CustomDataset(...)\n\ntotal_count = len(ds)\ntrain_count = int(0.7 * total_count)\nval_count = int(0.15 * total_count)\n\n# Varmistetaan ett\u00e4 kaikki n\u00e4ytteet tulevat k\u00e4ytt\u00f6\u00f6n\n# eli loput 15 %\ntest_count = total_count - train_count - val_count  \n\ntrain_ds, val_ds, test_ds = \n     random_split(ds, [train_count, val_count, test_count])\n</code></pre>"},{"location":"mallinnus/datanlataus/#dataloader","title":"DataLoader","text":"<p>DataLoader on vain wrapper Datasetin ymp\u00e4rille, joten jatketaan yll\u00e4 luodun <code>TensorDataset</code>-esimerkin parissa. Huomaa, ett\u00e4 DataLoader ei toteuta <code>__getitem__</code>-metodia, vaan ainoastaan <code>__iter__</code>-metodin, joka palauttaa iteraattorin. Et voi siis hakea yksitt\u00e4ist\u00e4 n\u00e4ytett\u00e4 <code>mydataloader[0]</code>, vaan sinun tulee iteroida datan l\u00e4pi esimerkiksi <code>for</code>-silmukassa tai <code>next()</code>-funktiolla.</p> <pre><code># Alustetaan aiemmin luodun datasetin pohjalta DataLoader\ndataloader = DataLoader(dataset, batch_size=2, shuffle=False)\n\n# Loopataan ja tulostetaan datan\u00e4ytteet\nfor data, label in dataloader:\n    print(data.shape)\n    print(label.shape)\n    print()\n</code></pre> Output<pre><code>torch.Size([2, 3])\ntorch.Size([2])\n\ntorch.Size([2, 3])\ntorch.Size([2])\n\ntorch.Size([1, 3])\ntorch.Size([1])\n</code></pre>"},{"location":"mallinnus/datanlataus/#data-ja-pytorch-vision","title":"Data ja PyTorch Vision","text":"<p>My\u00f6s TorchVision, joka on PyTorchin virallinen lis\u00e4kirjasto kuvank\u00e4sittelyyn, tarjoaa ty\u00f6kaluja datan lataukseen. Oletkin jo k\u00e4ytt\u00e4nyt <code>torchvision.datasets.MNIST</code>-datasetti\u00e4 aiemmissa harjoituksissa. N\u00e4iden lis\u00e4ksi TorchVision tarjoaa pohjaluokkia (ks. Base classes for custom datasets), jotka ovat: <code>DatasetFolder</code> ja <code>ImageFolder</code> ja <code>VisionDataset</code>. </p>"},{"location":"mallinnus/datanlataus/#visiondataset","title":"VisionDataset","text":"<p>VisionDataset on Datasetin kaltainen pohjaluokka, joka tarjoaa lis\u00e4toiminnallisuutta kuvadatasetin k\u00e4sittelyyn. N\u00e4ist\u00e4 n\u00e4kyvimm\u00e4t ovat:</p> <ul> <li><code>root</code>: Datasetin juurihakemisto (k\u00e4ytet\u00e4\u00e4n tulostukseen)</li> <li><code>transforms</code>: kutsuttava funktio, joka ottaa vastaan kuvat ja labelit ja palauttaa muokatun version niist\u00e4</li> <li><code>transform</code>: kutsuttava funktio, joka ottaa vastaan vain kuvan ja palauttaa muokatun version siit\u00e4</li> </ul> <p>Oletkin jo k\u00e4ytt\u00e4nyt <code>transforms</code>-ominaisuutta aiemmin:</p> <pre><code># 110_first_model.py\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.1307,), (0.3081,))  # MNIST mean and std\n])\n</code></pre> <p>Itse luokan k\u00e4ytt\u00f6 hoituu samalla tavalla kuin aiemmin esitellyn <code>CustomDataset</code>-esimerkin kanssa. Eli <code>class MyVisionDataset(VisionDataset):</code> ja toteutat <code>__len__</code> ja <code>__getitem__</code>-metodit.</p>"},{"location":"mallinnus/datanlataus/#imagefolder","title":"ImageFolder","text":"<p>ImageFolder on VisionDatasetin aliluokka, joka olettaa datan olevan j\u00e4rjestettyn\u00e4 hakemistoihin siten, ett\u00e4 jokainen alihakemisto vastaa yht\u00e4 luokkaa aakkosellisessa j\u00e4rjestyksess\u00e4. T\u00e4m\u00e4 tekee kuvien lataamisesta helppoa, jos ne on j\u00e4rjestetty valmiiksi oikeisiin hakemistoihin. Esimerkiksi:</p> <pre><code>data/\n    aasiankultakissa/\n        001.png\n        002.png\n        ...\n    aavikkoilves/\n        001.png\n        ...\n    ...\n    zorilla/\n        123.png\n        ...\n</code></pre> <p>Saisit n\u00e4m\u00e4 ladattua suoraan datasetiksi n\u00e4in:</p> <pre><code>from torchvision.datasets import ImageFolder\n\ndataset = ImageFolder(root='data/')\n</code></pre> <p>Moroney vihjaa kirjassa AI and ML for Coders in PyTorch <sup>1</sup>, ett\u00e4 aakkosj\u00e4rjestyksen tuomilta ongelmilta voi v\u00e4ltty\u00e4 k\u00e4ytt\u00e4m\u00e4ll\u00e4 <code>target_transform</code>-parametria, jolla voi m\u00e4\u00e4ritell\u00e4 oman funktionsa labelien muokkaamiseen. Esimerkiksi:</p> <pre><code># Mik\u00e4 tahansa luokitusj\u00e4rjestys\ncustom_class_to_idx = {\n    'aasiankultakissa': 42, \n    'aavikkoilves': 3, \n    ...,\n    'zorilla': 1024\n}\n\n# Luodaan dataset, jonka target_transform on lambda-funktio\ndataset = ImageFolder(\n  root='data/',\n  target_transform=\n    lambda x: custom_class_to_idx[dataset.classes[x]]\n)\n\n# Ylikirjoitetaan class_to_idx\ndataset.class_to_idx = custom_class_to_idx\nprint(dataset.class_to_idx)\n</code></pre>"},{"location":"mallinnus/datanlataus/#muut-keinot-datan-lataukseen","title":"Muut keinot datan lataukseen","text":""},{"location":"mallinnus/datanlataus/#keras-3-ja-pytorch-backend","title":"Keras 3 ja PyTorch-backend","text":"<p>Kuten PyTorch-luvussa mainittiin, Keras 3 tukee j\u00e4lleen useita taustaj\u00e4rjestelmi\u00e4 \u2013 mukaan lukien PyTorchia. T\u00e4m\u00e4 tarkoittaa, ett\u00e4 voit k\u00e4ytt\u00e4\u00e4 Kerasin tuttuja datasettej\u00e4 ja datan k\u00e4sittelyty\u00f6kaluja, vaikka malli py\u00f6risikin PyTorch-backendilla. Emme k\u00e4yt\u00e4 t\u00e4ss\u00e4 toteutuksessa Kerasia, mutta j\u00e4tet\u00e4\u00e4n kuitenkin maininnan tasolle, ett\u00e4 saatat t\u00f6rm\u00e4t\u00e4 t\u00e4m\u00e4n sortin snippetteihin:</p> <pre><code>train_ds, val_ds = keras.utils.image_dataset_from_directory(\n    \"PetImages\",\n    validation_split=0.2,\n    subset=\"both\",\n    seed=1337,\n    image_size=image_size,\n    batch_size=batch_size,\n)\n</code></pre>"},{"location":"mallinnus/datanlataus/#hugging-face-datasets","title":"Hugging Face Datasets","text":"<p>T\u00e4h\u00e4n oletkin jo t\u00f6rm\u00e4nnyt <code>214_cyberhate.py</code>-tiedostossa. Hugging Facesta voi ladata Datasets-repoista dataa joko <code>huggingface-hub</code> tai <code>datasets</code>-kirjastolla. Hub-kirjasto on tarkoitettu my\u00f6s muiden kuin datasettien noutamiseen: sill\u00e4 voi etsi\u00e4 Hugging Facesta esimerkiksi valmiiksi koulutettuja malleja.</p> <p>L\u00f6yd\u00e4t n\u00e4iden dokumentaation online: Datasets, huggingface_hub.</p>"},{"location":"mallinnus/datanlataus/#huggingface-hub","title":"huggingface-hub","text":"<p>T\u00e4m\u00e4 on kyberviha-Notebookista tuttu:</p> <pre><code>filepath = hf_hub_download(\n    repo_id=\"sourander/yskills\",\n    repo_type=\"dataset\",\n    filename=\"ySKILLS_longitudinal_dataset_teacher_processed.csv\",\n)\n\ndf = pd.read_csv(filepath)\n</code></pre> <p>Ideaalitilanteessa CSV-tiedosto ladattaisiin jonkin oman PyTorch Datasets-toteutuksen avulla sis\u00e4\u00e4n. Tiedosto on kuitenkin niin pieni, ett\u00e4 harjoituksessa se otettiin <code>train_test_split</code>:n j\u00e4lkeen k\u00e4ytt\u00f6\u00f6n <code>torch.FloatTensor(X_train).to(device)</code>-komennolla.</p>"},{"location":"mallinnus/datanlataus/#datasets","title":"datasets","text":"<p>Yll\u00e4 mainitulla ty\u00f6kalulla on n\u00e4pp\u00e4r\u00e4 ladata yksitt\u00e4inen tiedosto kerrallaan. Jos Hugging Face -repo on oikein j\u00e4rjestetty, sielt\u00e4 voi ladata kerralla train, test ja muutkin datasetit n\u00e4in:</p> <pre><code>from datasets import load_dataset\nds = load_dataset(\"username/repoid\")\n</code></pre> <p>Esimerkiksi <code>sourander/yskills</code>-datasetti on j\u00e4rjestetty siten, ett\u00e4 erillist\u00e4 train/test/validation jakoa ei ole tehty tiedostotasolla vaan koko datasetti on samassa CSV-tiedostossa. T\u00e4ll\u00f6in <code>load_dataset</code> lataa koko datasetin <code>train</code>-avaimeen. Jos <code>datasets</code>-kirjaston kanssa haluaisi kuitenkin edet\u00e4, voisi koodin n\u00e4ytt\u00e4\u00e4 t\u00e4lt\u00e4:</p> <pre><code>from datasets import load_dataset\n\n# CSV:n sis\u00e4lt\u00f6 l\u00f6ytyy \"train\"-avaimesta.\n# T\u00e4ss\u00e4 datasetiss\u00e4 ei ole test- tai validation-osioita.\nds = load_dataset(\"sourander/yskills\").with_format(\"torch\")\n\n# Nyt on batch ja train\nsplit_ds = ds[\"train\"].train_test_split(test_size=0.3, seed=42)\n\n# Siirret\u00e4\u00e4n ne eri loadereihin\ntrainloader = DataLoader(ds[\"train\"], batch_size=32)\ntestloader = DataLoader(ds[\"test\"], batch_size=32)\n\n# Kaivetaan yksi batch ulos\nfor batch in trainloader:\n    break\n</code></pre> <p>T\u00e4ss\u00e4 v\u00e4liss\u00e4 on hyv\u00e4 huomauttaa, ett\u00e4 jatkossa <code>len(batch) != 32</code>, koska Hugging Face -Datasets palauttaa sanakirjan, jossa on avaimina sarakkeiden nimet. Eli siis <code>batch.keys()</code> palauttaa sarakenimet. T\u00e4m\u00e4 vaatisi jotakuinkin seuraavanlaista k\u00e4sittely\u00e4 koulutusloopissa:</p> <pre><code>for batch in dataloader:\n    # Erotellaan piirteet ja labelit ja st\u00e4k\u00e4t\u00e4\u00e4n horisontaalisesti X:ksi\n    feature_cols = [c for c in batch.keys() if c != \"RISK101\"]\n    X = torch.stack([batch[col] for col in feature_cols], dim=1).float().to(device)\n    y = batch[\"RISK101\"].float().to(device)\n\n    # Normaali forward pass\n    outputs = model(X).squeeze(1)\n</code></pre> <p>T\u00e4m\u00e4 on hieman hankalampi tapa edet\u00e4 kuin suora CSV:n lukeminen Pandasilla, mutta on hyv\u00e4 tunnistaa eri vaihtoehdot. Eri tutoriaaleissa ja eri kirjastojen kanssa pelatessa saatat t\u00f6rm\u00e4t\u00e4 yll\u00e4tt\u00e4v\u00e4\u00e4n valikoimaan erilaisia tapoja datan lataukseen (ja muuhunkin).</p>"},{"location":"mallinnus/datanlataus/#tehtavat","title":"Teht\u00e4v\u00e4t","text":"<p>Teht\u00e4v\u00e4: MNIST MLP Revisited</p> <p>Muistat varmaan aiemman <code>110_first_model.py</code>-notebookin, jossa ajoit ensimm\u00e4ist\u00e4 kertaa yksinkertaista eteenp\u00e4in kytkeytyv\u00e4\u00e4 neuroverkkoa MNIST-datasetill\u00e4. Palaa t\u00e4h\u00e4n harjoitukseen ja tee seuraavat parannukset:</p> <pre><code>import os\nNUM_CPU = os.cpu_count()\n\n# Voit kokeilla, hy\u00f6tyyk\u00f6 GPU vaiko CPU enemm\u00e4n:\nUSE_GPU = True # or False\n\n# Lis\u00e4\u00e4 kumpaankin DataLoaderiin seuraavat keyword-argumentit:\ntrainloader = DataLoader(..., persistent_workers=True, num_workers=NUM_CPU)\ntestloader = DataLoader(..., persistent_workers=True, num_workers=NUM_CPU)\n</code></pre> <p>Jos et ole kirjannut aiemmin koulutuksen kestoa yl\u00f6s, tee se nyt ennen muutoksia. T\u00e4m\u00e4n j\u00e4lkeen tee yll\u00e4 mainitut muutokset ja aja koulutus uudestaan. Kuinka paljon nopeutusta sait aikaan? Tutustu siihen, mit\u00e4 <code>persistent_workers</code> ja <code>num_workers</code> tekev\u00e4t ja miksi ne nopeuttavat datan latausta n\u00e4inkin paljon.</p> <p>Teht\u00e4v\u00e4: CIFAR10 Datasetin pl\u00e4r\u00e4\u00e4minen</p> <p>Tutustu CIFAR10 -datasettiin. Datasetti koostuu 60 000 v\u00e4rikuvasta. Kuvia on 6,000 kutakin luokkaa kohden eli luokkia on 10. Harjoittele seuraavia:</p> <ul> <li>Lataa CIFAR10-datasetti PyTorchin <code>torchvision.datasets</code>-moduulista.</li> <li>Tutki datan rakennetta (kuinka monta kuvaa, kuvan koko, v\u00e4rit, luokat).</li> <li>Visualisoi yksi kuva</li> <li>Visualisoi useampi kuva ruudukossa (grid). <ul> <li>Bonus: K\u00e4ytt\u00e4j\u00e4 voi valita luokan.</li> </ul> </li> <li>Luo <code>DataLoader</code>, jolla voit iteroida datan l\u00e4pi mini-batcheina.<ul> <li>Visualisoi yksi mini-batch ruudukossa.</li> </ul> </li> </ul> <p>Voit k\u00e4ytt\u00e4\u00e4 apuna <code>410_cifar10.py</code>-notebookia tai kirjoittaa koodin alusta itse.</p> <p>Teht\u00e4v\u00e4: CIFAR10 Malli</p> <p>Kouluta my\u00f6s yksinkertainen eteenp\u00e4in kytkeytyv\u00e4 (feedforward) neuroverkko CIFAR10-datasetill\u00e4. Tulemme my\u00f6hemmin vertaamaan t\u00e4t\u00e4 suoritusta konvoluutioverkkoon (CNN).</p> <p>Alta saat jo osviittaa, mihin lukemiin tulet p\u00e4\u00e4sem\u00e4\u00e4n seuraavissa luvuissa. Nyt voit olla tyytyv\u00e4inen, jos p\u00e4\u00e4set noin 50\u201360 % tarkkuuteen (accuracy). Mik\u00e4 mahtaa olla baseline, jotta olet arpaa parempi?</p> Paper title Error rate Accuracy Year Convolutional Deep Belief Networks on CIFAR-10 21.1 % 78.9% 2010 Maxout Networks 9.38 % 90.62% 2013 Wide Residual Networks 4.0 % 96.0% 2016 ... ... ... ... An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale 0.5 % 99.5% 2021 <p>Kannattaa tutkia my\u00f6s, kauan mallin koulutus kest\u00e4\u00e4. Data sek\u00e4 malli ovat aiempaa suurempia. Opettajan valitsemalla arkkitehtuurilla saatiin 57 % testitarkkuus (joka ei juuri parantunut epookin nro 30 j\u00e4lkeen). T\u00e4ll\u00e4 arkkitehtuurilla koulutus kesti, kun <code>persistent_workers=True</code> ja <code>num_workers=NUM_CPU</code> asetukset olivat paikoillaan:</p> <ul> <li>CPU 100 epookkia: 10 min 5 s</li> <li>GPU 100 epookkia: 8 min 20 s</li> </ul> <p>Taulukon l\u00e4hde: Wikipedia: CIFAR-10</p> <p>Voit k\u00e4ytt\u00e4\u00e4 apuna <code>411_cifar10.py</code>-notebookia tai kirjoittaa koodin alusta itse.</p> <p>Teht\u00e4v\u00e4: ImageFolderin k\u00e4ytt\u00f6</p> <p>K\u00e4yt\u00e4 ImageFolder-luokkaa ja <code>custom_class_to_idx</code>-sanakirjaa. T\u00e4h\u00e4n on valmis pohja, jossa tarvii muokata vain yht\u00e4 solua. Katso <code>412_imagefolder.py</code>-notebook.</p> <p>Varmista, ett\u00e4 ymm\u00e4rr\u00e4t, miss\u00e4 tiedostot ovat fyysisesti levyll\u00e4.</p>"},{"location":"mallinnus/datanlataus/#lahteet","title":"L\u00e4hteet","text":"<ol> <li> <p>Moroney, L. AI and ML for Coders in PyTorch. O'Reilly. 2025.\u00a0\u21a9\u21a9</p> </li> </ol>"},{"location":"mallinnus/kaytannot/","title":"Kouluttamisen k\u00e4yt\u00e4nn\u00f6t","text":""},{"location":"mallinnus/kaytannot/#geronin-vinkit","title":"Geronin vinkit","text":"<p>T\u00e4ss\u00e4 osiossa k\u00e4yd\u00e4\u00e4n l\u00e4pi mallin kouluttamiseen liittyvi\u00e4 hyvi\u00e4 tai yleisi\u00e4 k\u00e4yt\u00e4nt\u00f6j\u00e4. Jatkossa kurssilla edet\u00e4\u00e4n eteenp\u00e4in kytkeytyvist\u00e4, t\u00e4ysin kytketyist\u00e4 verkoista (engl. feedforward fully connected neural networks, multilayer perceptron) kohti oudompia rakenteita, kuten konvoluutioverkkoja ja sekvensseihin soveltuvia rekursiivisia verkkoja. Ennen n\u00e4it\u00e4 on hyv\u00e4 varmistaa, ett\u00e4 p\u00e4\u00e4dyt johonkin johtop\u00e4\u00e4t\u00f6kseen siit\u00e4, mill\u00e4 oletusarvoilla voit l\u00e4hte\u00e4 liikenteeseen esimerkiksi projektity\u00f6ss\u00e4si, mik\u00e4li teht\u00e4v\u00e4\u00e4n soveltuu MLP/FFNN-malli.</p> <p>On oletus, ett\u00e4 luet t\u00e4ss\u00e4 yhteydess\u00e4 kurssikirjan Hands-On Machine Learning with Scikit-Learn and PyTorch<sup>1</sup> luvun 10 sek\u00e4 11 <sup>1</sup>. Voi olla miellek\u00e4st\u00e4 selata my\u00f6s eritt\u00e4in kansantajuista kirjaa nimelt\u00e4\u00e4n Machine Learning Yearning<sup>2</sup>. Toinen kurssikirja, Understanding Deep Learning, antaa hyvin taustaa erityisesti regularisointiin. Toivon mukaan olet jo valmiiksi edennyt luvun 8 loppuun asti kirjassa, sill\u00e4 kurssin aiheet ovat t\u00e4h\u00e4n asti liittyneet pitk\u00e4lti kirjan lukuihin 1\u20138. Alla on taulukko, joka on lainattu suoraan kurssikirjasta<sup>1</sup>. Se toimikoon hyv\u00e4n\u00e4 koosteena termeist\u00e4, jotka sinun tulisi osata selitt\u00e4\u00e4 omin sanoin oppimisp\u00e4iv\u00e4kirjaasi.</p> Hyperparameter Default value Kernel initialization He initialization Activation function ReLU if shallow; Swish if deep Normalization None if shallow; batch-norm or layer-norm if deep Regularization Early stopping; weight decay if needed Optimizer Nesterov accelerated gradient or Adam Learning rate scheduler Performance scheduling or 1cycle <p>Taulukko 1. Yleisi\u00e4 hyperparametreja ja niiden oletusarvoja. Taulukko on englanniksi alkuper\u00e4isl\u00e4hteen mukaisesti. <sup>1</sup></p>"},{"location":"mallinnus/kaytannot/#karpathyn-vinkit","title":"Karpathyn vinkit","text":"<p>Kuten Karpathy toteaa artikkelissaan A Recipe for Training Neural Networks, mallien koulutus vaatii k\u00e4rsiv\u00e4llisyytt\u00e4, tarkkuutta ja systemaattista l\u00e4hestymistapaa, koska valmiit kirjastot eiv\u00e4t poista virheiden riski\u00e4. Onnistuminen perustuu datan tuntemiseen, yksinkertaisista malleista aloittamiseen ja vaiheittaiseen monimutkaistamiseen. Karpathyn vinkeiss\u00e4 on samoja piirteit\u00e4 kuin Yleiskatsaus-osion ty\u00f6nkulussa, mutta n\u00e4m\u00e4 sukeltavat l\u00e4hemm\u00e4s varsinaista k\u00e4yt\u00e4nt\u00f6\u00e4. Alla poimintaa artikkelista maistiaisena: <sup>3</sup></p> <ul> <li>Tunne data kuin omat taskusi</li> <li>Luo baseline ja pipeline</li> <li>Pid\u00e4 lego-palikat aluksi yksinkertaisina</li> <li>Ylisovita</li> <li>Regularisoi</li> </ul>"},{"location":"mallinnus/kaytannot/#tehtavat","title":"Teht\u00e4v\u00e4t","text":"<p>Teht\u00e4v\u00e4: Kouluttamisen k\u00e4yt\u00e4nn\u00f6t</p> <p>Selit\u00e4 tiiviisti alla listatut termit omin sanoin oppimisp\u00e4iv\u00e4kirjaasi. Kirjaa asiat yl\u00f6s siten, ett\u00e4 voit jatkossa k\u00e4ytt\u00e4\u00e4 sit\u00e4 omana muistiinpanona, kun sinun pit\u00e4\u00e4 palata n\u00e4ihin aiheisiin. Voit k\u00e4ytt\u00e4\u00e4 apuna kurssimateriaaleja ja muita l\u00e4hteit\u00e4, mutta kirjoita asiat omin sanoin. Mik\u00e4li koodin k\u00e4ytt\u00f6 on tarpeen, voit k\u00e4ytt\u00e4\u00e4 sit\u00e4 havainnollistamaan asiaa. Se on jopa suositeltavaa osassa termeiss\u00e4.</p> <ul> <li>Validation split (sinulle on training ja testing jo aiemmin tuttua tavaraa.) (ks.  luvut 5\u20137 ja 12)</li> <li>Vanishing gradients (ks.  luku 11)</li> <li>Regularisointi (dropout, L1 ja L2 weight decay) (ks.  ja  )</li> <li>Error analysis (ks.  luku 14\u201319)</li> </ul> <p>Alla l\u00e4hdevinkkej\u00e4:</p> <p> Hands-On Machine Learning with Scikit-Learn and PyTorch -kirjaa eli virallista kurssikirjaa. Se l\u00f6ytyy koulun kirjastosta.</p> <p> Machine Learning Yearning -kirjaa, joka on ilmainen e-kirja. L\u00f6ytyy osoitteesta: andrew-ng-machine-learning-yearning.pdf</p> <p> Understanding Deep Learning -kirja antaa ryhti\u00e4 teorialle. Regularisoinnista on kokonainen luku 9.</p> <p>Teht\u00e4v\u00e4: Piirr\u00e4 multihead malli (Gaussian)</p> <p>Avaa <code>420_gaussian_regression.py</code> ja tutustu sen koodiin, erityisesti mallin rakenteeseen. Vahvista osaamisesi piirt\u00e4m\u00e4ll\u00e4 malli valitsemallasi ty\u00f6kalulla (esim. Excalidraw). Malli on muotoa multi-task learning siin\u00e4 mieless\u00e4, ett\u00e4 se ennustaa kaksi lukua: mean ja variance. Mallilla on ns. shared trunk ja kaksi headia, mist\u00e4 johtuu termi multihead.</p> <p>Kannattaa tutustua my\u00f6s kurssikirjan luvun 10 lopulla olevaan \"Building Nonsequential Models Using Custom Modules\" -osioon, jossa on eri tavalla haarautuva verkko. Verkkossa osa inputista tuodaan \"ohitusreitti\u00e4\" piilotetun kerrosten ohi. </p> <p>Skip connections / Residual connections</p> <p>Ohitusreittej\u00e4 kutsutaan englanniksi termeill\u00e4 skip connections tai residual connections. Ne auttavat mallia oppimaan syvempi\u00e4 verkkoja tehokkaammin, koska ne helpottavat gradientin kulkua taaksep\u00e4in verkon l\u00e4pi. T\u00f6rm\u00e4nnet n\u00e4ihin my\u00f6hemmin konvoluutioverkon ResNet arkkitehtuurissa.</p>"},{"location":"mallinnus/kaytannot/#lahteet","title":"L\u00e4hteet","text":"<ol> <li> <p>G\u00e9ron, A. Hands-On Machine Learning with Scikit-Learn and PyTorch. O'Reilly. 2025.\u00a0\u21a9\u21a9\u21a9\u21a9</p> </li> <li> <p>Ng, A. Machine Learning Yearning. 2018. https://info.deeplearning.ai/machine-learning-yearning-book\u00a0\u21a9</p> </li> <li> <p>Karpathy, A. A Recipe for Training Neural Networks. 2019. https://karpathy.github.io/2019/04/25/recipe/\u00a0\u21a9</p> </li> </ol>"},{"location":"mallinnus/yleiskatsaus/","title":"Yleiskatsaus","text":""},{"location":"mallinnus/yleiskatsaus/#mallinnus","title":"Mallinnus","text":"<p>T\u00e4m\u00e4 luku on osin koostetta aiemmista luvuista, mutta aiheisiin sukelletaan hieman syvemm\u00e4lle. Osa termeist\u00e4, kuten optimointifunktiot, ovat olleet vain sivulauseina. Leikkis\u00e4sti sanottuna aihe on: \"Mist\u00e4 on pienet \u2013 tai suuret \u2013 neuroverkot tehty?\" \ud83e\udd16</p> <p>Neuroverkkojen luomisen prosessista k\u00e4ytet\u00e4\u00e4n termi\u00e4 mallinnus (engl. modeling, building or developing a model). Mallinnus tarkoittaa prosessia, jossa suunnitellaan, rakennetaan ja koulutetaan neuroverkko, joka ratkaisee tietyn ongelman. Mallinnus kattaa siis kaikki vaiheet datan hankinnasta ja esik\u00e4sittelyst\u00e4 mallin arkkitehtuurin suunnitteluun, kouluttamiseen ja arviointiin. Keskeisin vaihe on se, kun matemaattinen funktio sovitetaan dataan, mutta se on mekaanisin ja kenties helpoin osa-alue.</p>"},{"location":"mallinnus/yleiskatsaus/#tyovaiheet-lyhyesti","title":"Ty\u00f6vaiheet lyhyesti","text":"<p>Aiemmin Johdatus koneoppimiseen -kurssilla tutustuit jo yleiseen koneoppimisen ty\u00f6nkulkuun: datan ker\u00e4\u00e4miseen, esik\u00e4sittelyyn, mallin valintaan ja arviointiin. T\u00e4ss\u00e4 luvussa tarkennamme n\u00e4it\u00e4 vaiheita nimenomaan neuroverkon n\u00e4k\u00f6kulmasta \u2013 eli siihen, millainen funktio valitaan ja miten sen muotoa (arkkitehtuuria) s\u00e4\u00e4det\u00e4\u00e4n. Alla oleva taulukko on yhdistelm\u00e4 Essential Math for AI -kirjan luvun 3 alun ty\u00f6nkulusta <sup>1</sup> sek\u00e4 Deep Learning with Python (3rd ed) kirjan luvusta 6 <sup>2</sup>. Se kokoaa yhteen mallintamisen t\u00e4rkeimm\u00e4t vaiheet. Datan hankinta (tai l\u00e4hinn\u00e4 sen k\u00e4ytt\u00f6 PyTorchissa) k\u00e4sitell\u00e4\u00e4n tarkemmin seuraavassa luvussa. Datan louhintaa on k\u00e4sitelty muilla kursseilla.</p> Ty\u00f6vaihe Kuvaus Tunnista ongelma M\u00e4\u00e4rittele, onko kyse luokittelusta, regressiosta, generoinnista tai esimerkiksi anomalioiden havaitsemisesta. Hanki sopiva data Varmista, ett\u00e4 dataa on oikeanmallista, sit\u00e4 on riitt\u00e4v\u00e4sti ja se on laadukasta. T\u00e4m\u00e4 vaihe on usein aikaa vievin. Valitse virhefunktio Virhefunktio (eng. loss function, error function, cost function, objective function) kertoo, kuinka ohi tavoitteesta ennuste menee. Luo malli Suunnittele tai valitse hypoteesifunktio. Valitse optimointimenetelm\u00e4 Gradienttimenetelm\u00e4 (eng. gradient descent) on keskeinen ty\u00f6kalu minimointiin. Se perustuu virhefunktion derivaatan laskemiseen. Regularisoi Regularisointi tekee funktiosta tasaisemman ja v\u00e4hent\u00e4\u00e4 ylisovittamista. Kouluta Optimoi eli minimoi virhe . T\u00e4m\u00e4 on CPU/GPU-intensiivinen fit-vaihe eli mallin koulutus."},{"location":"mallinnus/yleiskatsaus/#tyovaiheet-yksityiskohtaisemmin","title":"Ty\u00f6vaiheet yksityiskohtaisemmin","text":""},{"location":"mallinnus/yleiskatsaus/#ongelma","title":"Ongelma","text":"<p>\"You can\u2019t do good work without a deep understanding of the context of what you\u2019re doing. Why is your customer trying to solve this particular problem? What value will they derive from the solution? How will your model be used? How will it fit into your customer\u2019s business processes? What kind of data is available or could be collected? What kind of machine learning task can be mapped to the business problem?\" <sup>2</sup> </p> <p>T\u00e4m\u00e4 on Johdatus koneoppimiseen -kurssilta tuttua. Esimerkiksi logistinen regressio soveltuu luokitteluun, kun taas lineaarinen regressio on tarkoitettu jatkuvien arvojen ennustamiseen, ja k-Means soveltuu klusterointiin. Neuroverkoissa t\u00e4m\u00e4 muuttuu sin\u00e4ns\u00e4, ett\u00e4 sama arkkitehtuuri voi soveltua monenlaisiin ongelmiin, kunhan mallin ulostulokerros ja virhefunktio valitaan oikein. My\u00f6hemmin kurssilla k\u00e4sittelemme kuviin, tekstiin tai aikasarjoihin erikoistuneita arkkitehtuureita; t\u00e4m\u00e4n viikon tarkoituksena on tunnistaa, kuinka eteenp\u00e4in kytketyn verkon (feedforward neural network) arkkitehtuuri soveltuu erilaisiin ongelmiin.</p> <p>Tulet huomaamaan, ett\u00e4 sama Dense-kerrosten verkko soveltuu muiden muassa seuraaviin ongelmiin: regressio, bin\u00e4\u00e4riluokittelu, monen luokan luokittelu (joko yksi luokka tai useita luokkia kerrallaan) ja jopa ep\u00e4varmuuden mallintaminen. Erona on vain ulostulokerros ja virhefunktio.</p> <p>Ongelmaa pohtiessa on hyv\u00e4 pyrki\u00e4 tunnistaa my\u00f6s alin l\u00e4ht\u00f6kohta (engl. baseline). Luokittelussa alin l\u00e4ht\u00f6kohta on satunnainen arvaus: bin\u00e4\u00e4riluokittelussa 50 %, k-luokassa 1/k. Regressiossa alin l\u00e4ht\u00f6kohta tulee tunnistaa bisneskontekstissa: kuinka tarkka ennusteen tulee olla, jotta siit\u00e4 on hy\u00f6ty\u00e4?</p>"},{"location":"mallinnus/yleiskatsaus/#data","title":"Data","text":"<p>T\u00e4h\u00e4n palaamme seuraavassa luvussa. </p> <p>Tip</p> <p>T\u00e4ss\u00e4 vaiheessa on hyv\u00e4 huomioida, ett\u00e4 neuroverkon tulevat toimeen ns. raakadatan kanssa. Oletkin jo n\u00e4hnyt, kuinka neuroverkko luokittelee kuvia pikseleiden intensiteettien perusteella ilman, ett\u00e4 kuvia on erikseen muunnettu piirteiksi (kuten reunat, kulmat, muodot). Raakadata esitet\u00e4\u00e4n kuitenkin aina vektoroidussa numeromuodossa. My\u00f6s kielimallit toimivat numeroidulla datalla.</p>"},{"location":"mallinnus/yleiskatsaus/#virhefunktio","title":"Virhefunktio","text":"<p>T\u00e4ss\u00e4 on t\u00e4rke\u00e4\u00e4 erottaa kaksi asiaa: virhefunktio ja evaluointimittarit. Virhefunktion tulee soveltua optimointiin, eli sen tulee olla derivoituva. Evaluointimittarit taas voivat olla mit\u00e4 tahansa, kunhan ne mittaavat haluttua ominaisuutta \u2013 mieluiten luotettavasti ja helposti tulkittavasti.</p> <p>Virhefunktio (engl. loss function, error function, cost function, objective function) mittaa, kuinka hyvin malli suoriutuu annetusta teht\u00e4v\u00e4st\u00e4.</p> <p>Evaluointimittarit (engl. evaluation metrics) mittaavat mallin suorituskyky\u00e4, mutta niit\u00e4 ei k\u00e4ytet\u00e4 optimointiin. Esimerkiksi ROC AUC on suosittu bin\u00e4\u00e4riluokittelun arviointimittari, mutta sit\u00e4 ei voi k\u00e4ytt\u00e4\u00e4 virhefunktiona, koska se ei ole derivoituva. <sup>2</sup></p> <p>Alla taulukko yleisimmist\u00e4 teht\u00e4v\u00e4tyypeist\u00e4, niiden ulostuloaktivoinneista ja virhefunktioista PyTorchissa. Taulukko on kirjoitettu englanniksi, koska en l\u00f6yd\u00e4 vakiintuneita suomennoksia, jotka erottaisivat toisistaan moniluokkaisen ennustuksen kaksi eri tyyppi\u00e4 (multi-class vs. multi-label classification). Pidemmilt\u00e4 nimilt\u00e4\u00e4n n\u00e4m\u00e4 ovat multiclass, single-label classification ja multilabel, multi-class classification. Ensimm\u00e4isess\u00e4 voi olla vain yksi luokka kerrallaan (esim. koira TAI kissa TAI lintu), kun taas j\u00e4lkimm\u00e4isess\u00e4 voi olla useita luokkia samanaikaisesti (esim. koira JA kissa).</p> Task type Output activation PyTorch loss function Task type explained Human metric Regression None <code>MSELoss</code>, <code>L1Loss</code> <code>0.123</code> MAE Binary classification None (Sigmoid)  <code>BCEWithLogitsLoss</code> <code>a</code> or not binary acc, F1, ROC AUC Multi-label classification None (Sigmoid per label)  <code>BCEWithLogitsLoss</code> <code>a</code> and/or <code>b</code> and/or <code>c</code> multilabel acc, F1, ROC AUC, Hamming Multi-class classification None (Softmax)  <code>CrossEntropyLoss</code> <code>a</code> or <code>b</code> or <code>c</code> multiclass acc, top-k acc, ROC AUC (OvR) Gaussian regression None (mean), Softplus (variance) <code>GaussianNLLLoss</code> mean and variance MAE (mean only) Poisson count modeling None <code>PoissonNLLLoss</code> <code>0</code> \u2026 <code>n</code> MAE <p>Selitykset</p> <p> Saatat n\u00e4hd\u00e4 yhdistelm\u00e4n <code>Sigmoid + BCELoss</code>, mutta <code>BCEWithLogitsLoss</code> on suositeltavampi, koska se on numeerisesti vakaampi (kuten PyTorchin dokumentaatiossa: BCEWithLogitsLoss todetaan.)</p> <p> Saatat n\u00e4hd\u00e4 yhdistelm\u00e4n <code>LogSoftmax + NLLLoss</code> moniluokkaisessa luokittelussa, mutta <code>CrossEntropyLoss</code> sis\u00e4lt\u00e4\u00e4 jo molemmat vaiheet ja v\u00e4ltt\u00e4\u00e4 turhan ty\u00f6n.</p> <p> Gaussinen regressiomalli antaa kaksi lukua: arvauksen (keskiarvo) ja ep\u00e4varmuuden (varianssi). Malli voi esimerkiksi sanoa: \"Arvioin, ett\u00e4 l\u00e4mp\u00f6tila on 21 \u00b0C, mutta ep\u00e4varmuus on noin \u00b13 \u00b0C.\" Varianssin positiivisuus voidaan varmistaa eksponentti- tai Softplus-aktivoinnilla. Softplus lis\u00e4\u00e4 numeerista vakautta, mutta tuo my\u00f6s pienen harhan tai lattian varianssiin.</p> <p> Poisson-malli olettaa, ett\u00e4 ilmi\u00f6 noudattaa Poisson-jakaumaa tavallisen normaalijakauman (kuten regressiossa) sijaan. Malli ennustaa ei-negatiivisen luvun: \"Annettujen piirteiden perusteella ennustan, ett\u00e4 asiakkaita tulee 10.\"</p>"},{"location":"mallinnus/yleiskatsaus/#malli","title":"Malli","text":"<p>Nyt sinulla pit\u00e4isi olla data vektoroituna, ongelma m\u00e4\u00e4riteltyn\u00e4 ja virhefunktio valittuna. Seuraava askel on hypoteesifunktion eli mallin valinta. T\u00e4t\u00e4 varten sinun on k\u00e4yt\u00e4nn\u00f6ss\u00e4 pakko pilkkoa datasetti kolmeen osaan:</p> <ul> <li>Koulutusdata (training set)</li> <li>Validointidata (validation set)</li> <li>Testidata (test set)</li> </ul> <p>Hypoteesifunktiolla eli mallilla on monta nime\u00e4: \"We use the terms hypothesis function, learning function, prediction function, training function, and model interchangeably.\" <sup>1</sup> Johdatus koneoppimiseen -kurssilla mallin valinta oli yksi vaiheista; neuroverkkojen kohdalla mallin valinta tarkoittaa arkkitehtuurin m\u00e4\u00e4rittely\u00e4. K\u00e4yt\u00e4nn\u00f6ss\u00e4 mallin kerrosten m\u00e4\u00e4r\u00e4 ja muoto ovat hyperparametreja. \"A deep learning model is like a sieve for data processing, made of a succession of increasingly refined data filters\u2014the layers <sup>2</sup>\".</p> <p>Watson ja Chollet kirjoittavat, ett\u00e4 \"To figure out how big a model you\u2019ll need, you must develop a model that overfits.\" <sup>2</sup> T\u00e4m\u00e4 tarkoittaa, ett\u00e4 et k\u00e4yt\u00e4nn\u00f6ss\u00e4 voi etuk\u00e4teen tiet\u00e4\u00e4, mink\u00e4 kokoinen malli soveltuu teht\u00e4v\u00e4\u00e4n. Aloita pienest\u00e4 ja skaalaa sit\u00e4 suuremmaksi kunnes l\u00f6yd\u00e4t ylisovittamisen rajan. T\u00e4m\u00e4n j\u00e4lkeen voit k\u00e4ytt\u00e4\u00e4 regularisointia ja etsi\u00e4 tasapainoa alisovittamisen ja ylisovittamisen v\u00e4lill\u00e4. Malli monimutkaisuus m\u00e4\u00e4rittyy seuraavilla:</p> <ul> <li>Kerrosten lukum\u00e4\u00e4r\u00e4</li> <li>Kunkin kerroksen solmujen (neuroneiden) lukum\u00e4\u00e4r\u00e4</li> <li>Epookkien lukum\u00e4\u00e4r\u00e4</li> </ul> <p>Lis\u00e4ksi voit muuttaa esimerkiksi aktivointifunktioita, optimointimenetelmi\u00e4 ja oppimisnopeutta (learning rate). N\u00e4ihin kuitenkin l\u00f6ytyy yleens\u00e4 hyv\u00e4t oletusarvot, joilla p\u00e4\u00e4see pitk\u00e4lle. Tutustumme n\u00e4ihin tarkemmin Kouluttamisen k\u00e4yt\u00e4nn\u00f6t-luvussa.</p>"},{"location":"mallinnus/yleiskatsaus/#regularisointi","title":"Regularisointi","text":"<p>T\u00e4h\u00e4n palataan Kouluttamisen k\u00e4yt\u00e4nn\u00f6t-luvussa.</p>"},{"location":"mallinnus/yleiskatsaus/#koulutus","title":"Koulutus","text":"<p>Mallin varsinainen koulutus tapahtuu optimointimenetelm\u00e4ll\u00e4, joka minimoi virhefunktion arvon. Yleisin menetelm\u00e4 on gradienttimenetelm\u00e4 (engl. gradient descent). Gradienttimenetelm\u00e4 perustuu virhefunktion derivaatan laskemiseen ja sen hy\u00f6dynt\u00e4miseen mallin painojen p\u00e4ivitt\u00e4misess\u00e4 siten, ett\u00e4 virhe pienenee jokaisella askeleella. T\u00e4m\u00e4n pit\u00e4isi olla sinulle jo tuttua.</p> <p>Muutoin t\u00e4m\u00e4 vaihe on jossain m\u00e4\u00e4rin mekaaninen. K\u00e4yt\u00e4t valmista kirjastoa, GPU alkaa tuottaa l\u00e4mp\u00f6\u00e4 ja sin\u00e4 menet kahville. \u2615</p>"},{"location":"mallinnus/yleiskatsaus/#tehtavat","title":"Teht\u00e4v\u00e4t","text":"<p>Teht\u00e4v\u00e4: Mallinna Fashion MNIST</p> <p>Kouluta yksinkertainen neuroverkko FashionMNIST -datasetill\u00e4. Datasetti on siit\u00e4 tuttu, ett\u00e4 se noudattaa MNIST:n tavoin samaista rakennetta: 28x28 pikselin harmaas\u00e4vykuvat, joissa on vaatekappaleita luokiteltavana. Luokkia on 10 ja kyseess\u00e4 on multi-class, single-label classification -ongelma. Datasetti l\u00f6ytyy suoraan <code>torchvision.datasets</code>-moduulista jaettuna koulutus- ja testidataseteiksi. Niiss\u00e4 on yhteens\u00e4 70 000 kuvaa (60 000 koulutukseen, 10 000 testaukseen). T\u00e4m\u00e4 kaikki on hyvin, hyvin tuttua MNIST:st\u00e4. Se, mik\u00e4 muuttuu, on ett\u00e4 kuvat ovat vaikeampia tulkita kuin numerot (sandaali vs. lenkkari on vaikeampi erottaa kuin 3 vs. 7). Jos k\u00e4yt\u00e4t samaa 784-256-128-10 -arkkitehtuuria kuin aiempi MLP, ja Sigmoid-kerroksia, koulutus kest\u00e4\u00e4 jotakuinkin yht\u00e4 kauan kuin edellinenkin. Saavutettu tarkkuus tulee olemaan heikompi (n. 85 %) sadalla epookilla. </p> <p>Huomaa, ett\u00e4 \"oikea vastaus\" on v\u00e4hemm\u00e4n merkityksellinen kuin sinun oppimismatka ja ymm\u00e4rryksen syventyminen. Kokeile erilaisia arkkitehtuureita, optimointimenetelmi\u00e4 ja hyperparametreja. Dokumentoi oppimiskokemuksesi. Oikean vastauksen sinulle antaa tuore kielimalli hetkess\u00e4, tai voit jopa kaivaa sen netist\u00e4, kuten PyTorch Learn the Basics: Datasets &amp; Dataloaders tai AI and ML for Coders in PyTorch -kirjan repositoriosta. Huijaamalla huijaat l\u00e4hinn\u00e4 vain itse\u00e4si.</p> <p>\u00c4l\u00e4 siis huijaa vaan ota ensimm\u00e4isen viikon <code>110_first_model.py</code>-tiedosto esimerkiksi. Voit k\u00e4ytt\u00e4\u00e4 pohjana <code>400_fashion_mnist.py</code>-tiedostoa tai luoda kokonaan oman Notebookisi. </p> <ul> <li>Aloita pienest\u00e4 mallista ja kasvata sit\u00e4, kunnes l\u00f6yd\u00e4t ylisovittamisen rajan.</li> <li>K\u00e4yt\u00e4 Tensorboardia prosessin seurantaan ja dokumentointiin.</li> <li>Tallenna malli seuraavaa teht\u00e4v\u00e4\u00e4 varten!</li> </ul> <p>Kun tallennat arvot, tallenna mukana my\u00f6s mallin arkkitehtuuriin liittyv\u00e4t tiedot, joiden avulla saat alustettua t\u00e4ysin saman mallin uusiksi.</p> <p>Mallin tallennus</p> <p>Tallenna malli PyTorchin <code>torch.save()</code>-funktiolla. Tallenna mukaan my\u00f6s mallin arkkitehtuuriin liittyv\u00e4t tiedot, kuten kerrosten lukum\u00e4\u00e4r\u00e4 ja solmujen lukum\u00e4\u00e4r\u00e4 kussakin kerroksessa. N\u00e4in voit alustaa t\u00e4ysin saman mallin uudelleen lataamisen yhteydess\u00e4. T\u00e4m\u00e4n voi tehd\u00e4 monin eri tavoin, mutta alla on yksi esimerkki:</p> <pre><code>model_checkpoint = {\n    'input_size': 784,\n    'output_size': 10,\n    'hidden_layers': [256, 128, 64],\n    'state_dict': model.state_dict()\n}\n\ntorch.save(model_checkpoint, 'models/mnist_mlp_checkpoint.pth')\n</code></pre> <p>Jos haluat haastaa itse\u00e4si, kokeile k\u00e4\u00e4nt\u00e4\u00e4 malli TorchScript-muotoon <code>torch.jit.script()</code>-funktiolla. L\u00f6yd\u00e4t t\u00e4h\u00e4n hyv\u00e4n esimerkin Hands-On Machine Learning with Scikit-Learn and PyTorch -kirjan luvun 10 lopusta otsikon \"Compiling and Optimizing a PyTorch Model\" alta.</p> <p>Relu vs. Sigmoid</p> <p>Kannattaa kokeilla ainakin ReLU-aktivointia Sigmoidin sijasta, mink\u00e4 jo itsess\u00e4\u00e4n pit\u00e4isi nostaa tarkkuutta muutaman prosenttiyksik\u00f6n verran.</p> <p>Teht\u00e4v\u00e4: Lataa Fashion MNIST -malli</p> <p>K\u00e4yt\u00e4 edellisen teht\u00e4v\u00e4n tallennettua mallia ennustamaan luokkia Fashion MNIST -datasetin testidatalle. T\u00e4m\u00e4n Notebookin kanssa sinulla ei ole sit\u00e4 ongelmaa, ett\u00e4 vahingossa ajaisit useita minuutteja viev\u00e4n solun uudestaan. Toisin sanoen t\u00e4ss\u00e4 sinun on helppo harjoitella seuraavia asioita:</p> <ul> <li>Mallin lataaminen tiedostosta.</li> <li>Mallin k\u00e4ytt\u00e4minen ennustamiseen.</li> <li>Ennusteiden evaluointi sopivilla mittareilla (kuten top-k accuracy).</li> <li>Output-kerroksen numeroiden tutkiminen<ul> <li>Aktivaatio on None, joten ulostulo on raakaa logit-arvoa.</li> <li>Tulosta arvot sin\u00e4ll\u00e4\u00e4n ja todenn\u00e4k\u00f6isyydet (softmaxin avulla).</li> </ul> </li> </ul> <p>Voit k\u00e4ytt\u00e4\u00e4 pohjana <code>401_fashion_mnist_eval.py</code>-tiedostoa tai luoda kokonaan oman Notebookisi.</p> <p>Teht\u00e4v\u00e4: Tutustu aktivointifunktioihin</p> <p>Aja Marimo Notebook <code>403_activation_functions.ipynb</code> ja tutustu eri aktivointifunktioihin.</p>"},{"location":"mallinnus/yleiskatsaus/#lahteet","title":"L\u00e4hteet","text":"<ol> <li> <p>Nelson, H. Essential Math for AI. O'Reilly Media. 2023.\u00a0\u21a9\u21a9</p> </li> <li> <p>Watson, M &amp; Chollet, F. Deep Learning with Python, Third Edition. Manning. 2025.\u00a0\u21a9\u21a9\u21a9\u21a9\u21a9</p> </li> </ol>"},{"location":"neuroverkot/neuroverkot_101/","title":"Neuroverkot","text":""},{"location":"neuroverkot/neuroverkot_101/#maaritelma","title":"M\u00e4\u00e4ritelm\u00e4","text":""},{"location":"neuroverkot/neuroverkot_101/#koneoppimista","title":"Koneoppimista","text":"<p>Neuroverkot (engl. neural networks) ovat koneoppimisen malleja, jotka saavat inspiraationsa ihmisen aivojen rakenteesta ja toiminnasta. Neuroverkot pystyv\u00e4t oppimaan monimutkaisia kuvioita datasta, ja niit\u00e4 k\u00e4ytet\u00e4\u00e4n laajalti erilaisissa sovelluksissa, kuten kuvantunnistuksessa, puheentunnistuksessa ja luonnollisen kielen k\u00e4sittelyss\u00e4. Koneoppimisen (mukaan lukien sen alaisuuteen kuuluvan syv\u00e4oppimisen) voi tiiviisti m\u00e4\u00e4ritell\u00e4 seuraavasti:</p> <p>\"Fit a given set of data points into an appropriate function (mapping an input to an output) that picks up on the important signals in the data and ignores the noise, then make sure this function performs well on new data.\"</p> <p>\u2014 Hala Nelson <sup>1</sup></p> <p>Kannattaa kerrata omista Johdatus koneoppimiseen -kurssin muistiinpanoista, kuinka teko\u00e4ly, koneoppiminen ja syv\u00e4oppiminen liittyv\u00e4t toisiinsa. Voit my\u00f6s kerrata sielt\u00e4 muita m\u00e4\u00e4ritelmi\u00e4 koneoppimisesta.</p> <p>Se, kuinka neuroverkot eroavat Johdatus koneoppimiseen -kurssin malleista, on:</p> <ul> <li>Neuroverkot pystyv\u00e4t oppimaan itse piirteet (feature learning). T\u00e4m\u00e4 ei tarkoita, ett\u00e4 feature engineering vaihe olisi turha, mutta t\u00e4t\u00e4 ty\u00f6t\u00e4 voi ulkoistaa neuroverkolle.</li> <li>Neuroverkot pystyv\u00e4t mallintamaan monimutkaisempia, ep\u00e4lineaarisia suhteita datassa.</li> </ul>"},{"location":"neuroverkot/neuroverkot_101/#epalineaarista","title":"Ep\u00e4lineaarista","text":"<p>Varmistetaan jo heti kurssin alussa, ett\u00e4 on ymm\u00e4rrys siit\u00e4, mit\u00e4 lineaarisuus tarkoittaa t\u00e4ss\u00e4 kontekstissa. Lineaariset kaavat tai funktiot on helppo tunnistaa siit\u00e4, ett\u00e4 ne on helppo kirjoittaa. Piirteet esiintyv\u00e4t funktiossa omassa luonnollisessa muodossaan. Funktiossa ei esiinny esimerkiksi: neli\u00f6juuria, potensseja, logaritmisa, sini\u00e4, cosinia tai muuta selke\u00e4sti ei-lineaarista. <sup>1</sup> Esimerkki Pythonilla olisi:</p> <pre><code>def linear_function(x1, x2, x3):\n    return w1 * x1 + w2 * x2 - w3 * x3 + w0\n</code></pre> <p>Ei-lineaariset funktiot ovat monimutkaisempia. Sy\u00f6tteen ja tuloksen v\u00e4lill\u00e4 on ep\u00e4lineaarinen suhde. <sup>1</sup> Esimerkki Pythonilla:</p> <pre><code>import math\n\ndef nonlinear_function(x1, x2, x3):\n    return w1 * math.sqrt(x1) + w2 * (x2 / x3) + w3 * math.sin(x3) + w0\n</code></pre> <p>Neuroverkot kykenev\u00e4t mallintamaan ep\u00e4lineaarisia funktioita, koska ne k\u00e4ytt\u00e4v\u00e4t ep\u00e4lineaarisia aktivointifunktioita (kuten ReLU, sigmoid tai tanh) piilotetuissa kerroksissaan. T\u00e4m\u00e4 mahdollistaa monimutkaisten kuvioiden oppimisen datasta.</p>"},{"location":"neuroverkot/neuroverkot_101/#historia","title":"Historia","text":""},{"location":"neuroverkot/neuroverkot_101/#all-or-nothing","title":"All or nothing","text":"<p>Syv\u00e4oppiminen ei suinkaan ole syntynyt ChatGPT:n my\u00f6t\u00e4 2020-luvulla. Vuonna 1943 Warren McCulloch ja Walter Pitts julkaisivat artikkelin \"A Logical Calculus of the Ideas Immanent in Nervous Activity\", jossa he esittiv\u00e4t yksinkertaisen mallin keinotekoisesta neuronista. Malli perustui \"all-or-nothing\" -periaatteeseen, jossa neuronin aktivaatio tapahtuu, kun sy\u00f6tteiden painotettu summa ylitt\u00e4\u00e4 tietyn kynnyksen. Kyseess\u00e4 olivat siis bin\u00e4\u00e4riset neuronit, jotka toimivat loogisina portteina. <sup>2</sup></p> <p>\"Pitts was self-taught, and by age 12, had received an offer to study at Cambridge University with the great Bertrand Russell. He did not take up this invitation, and indeed throughout his life did not accept any offers of advanced degrees or positions of authority. Most of his famous work was done while he was homeless.\"</p> <p>\u2014 Gugger &amp; Howard, Deep Learning for Coders with fastai and PyTorch <sup>2</sup></p>"},{"location":"neuroverkot/neuroverkot_101/#dartmouth-ja-ain-synty","title":"Dartmouth ja AI:n synty","text":"<p>Vaikka McCulloch ja Pitts olivat jo 1943 luoneet teoreettisen pohjan keinotekoisille neuroneille, AI:n syntym\u00e4hetki tieteenalana on kes\u00e4ll\u00e4 1956 Dartmouth Collegessa j\u00e4rjestetty ty\u00f6paja Dartmouth Summer Research Project \u2013 ainakin yliopiston itsens\u00e4 mukaan <sup>3</sup>. John McCarthy toimi kokoonpanijana ja muita j\u00e4rjest\u00e4ji\u00e4 olivat Marvin Minsky, Claude Shannon ja Nathaniel Rochester.</p> <p>\"We propose that a 2-month, 10-man study of artificial intelligence be carried out during the summer of 1956 at Dartmouth College in Hanover, New Hampshire. [...] An attempt will be made to find how to make machines use language, form abstractions and concepts, solve kinds of problems now reserved for humans, and improve themselves.\"</p> <p>\u2014 A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence, 1955 <sup>4</sup></p> <p>Ty\u00f6pajan aivoriihiss\u00e4 k\u00e4siteltiin jo tuolloin monia alueita, jotka ovat edelleen keskeisi\u00e4. Ty\u00f6pajasta on jo yli 70 vuotta, mutta silti siihen t\u00f6rm\u00e4\u00e4 yh\u00e4: John K. Thompson esitteli Helsinki Data Week 2025:ssa t\u00e4m\u00e4n kes\u00e4projektin AI:n ensimm\u00e4isen\u00e4 askeleena Keynote-puheessaan.</p>"},{"location":"neuroverkot/neuroverkot_101/#kissakokeet","title":"Kissakokeet","text":"<p>50-luvun lopulla David Hubel ja Torsten Wiesel tutkivat, kuinka aivokuoressa k\u00e4sitell\u00e4\u00e4n visuaalista informaatiota. He havaitsivat, ett\u00e4 tietyt neuronit reagoivat spesifisiin visuaalisiin \u00e4rsykkeisiin, kuten viivoihin ja reunoihin <sup>5</sup>. He saivat t\u00e4st\u00e4 Nobelin fysiologian ja l\u00e4\u00e4ketieteen palkinnon vuonna 1981. <sup>6</sup> Hubel ja Wiesel suorittivat kokeensa n\u00e4ytt\u00e4m\u00e4ll\u00e4 visuaalisia \u00e4rsykkeit\u00e4 nukutetuille kissoille. N\u00e4iden 24 kissaraukan hermosolujen aktivaatiota tarkkailtiin mittalaitteilla aivokuoresta. <sup>7</sup> Lieneek\u00f6 kirja (ja elokuva) Kellopeliappelsiini ottanut t\u00e4st\u00e4 vaikutteita?</p> <p>Hubel ja Wiesel yrittiv\u00e4t aluksi stimuloida kissojen n\u00e4k\u00f6aivokuoren neuroneja yksinkertaisilla muodoilla kuten pisteill\u00e4, mutta eiv\u00e4t saaneet mit\u00e4\u00e4n vastetta. Sitten sattuma ja vahinko astuivat peliin: \"And then, as with many of the great discoveries, from X-rays to penicillin to the microwave oven, Hubel and Wiesel made a serendipitous observation: As they removed one of their slides from the projector, its straight edge elicited the distinctive crackle of their recording equipment to alert them that a primary visual cortex neuron was firing.\" <sup>5</sup> N\u00e4m\u00e4 neuronit, joihin signaali tulee ensimm\u00e4isen\u00e4 silmien suunnasta, saivat nimen \"simple cells\". N\u00e4m\u00e4 solut kytkeytyv\u00e4t edelleen monimutkaisempiin \"complex cells\" -soluihin, jotka reagoivat viivoihin ja reunoihin eri kulmissa. Kun n\u00e4it\u00e4 verkkoja kasataan useita kerroksia, meill\u00e4 on syv\u00e4 neuroverkko, joka pystyy tunnistamaan monimutkaisia kuvioita, kuten kasvoja, esineit\u00e4 ja maisemia.</p> <p></p> <p>Kuva 1: Otos Hubelin ja Wieselin tutkimuksesta. Kuva n\u00e4ytt\u00e4\u00e4, miten primaari n\u00e4k\u00f6aivokuori (V1) reagoi eri kohtiin verkkokalvon n\u00e4k\u00f6kent\u00e4ss\u00e4 osuvista pistem\u00e4isist\u00e4 valoista reseptiivisen kent\u00e4n kautta. <sup>7</sup></p> <p>Tip</p> <p>Aivokuori on evoluution my\u00f6h\u00e4inen kehitystuote, joka selitt\u00e4\u00e4 nis\u00e4kk\u00e4iden monimutkaista k\u00e4ytt\u00e4ytymist\u00e4 verrattuna vanhempiin el\u00e4inryhmiin. <sup>5</sup></p> <p>Aivoja kutsutaan \"harmaaksi aineeksi\", koska ulkopinta (aivokuori) on harmaata. Suurin osa aivoista on kuitenkin valkoista ainetta, joka kuljettaa tietoa pitki\u00e4 matkoja. Sen hermosolut on p\u00e4\u00e4llystetty valkoisella rasvaisella kalvolla, joka nopeuttaa signaalien johtumista. <sup>5</sup></p>"},{"location":"neuroverkot/neuroverkot_101/#perceptron","title":"Perceptron","text":"<p>1950-luvun tapahtui samanaikaisesti my\u00f6s muuta. Frank Rosenblatt jalosti McCulloch ja Pittsin ajatusta kehitt\u00e4en tavan kouluttaa neuroverkkoja. N\u00e4in syntyi Mark I Perceptron, joka oli yksi ensimm\u00e4isist\u00e4 neuroverkkopohjaisista malleista. <sup>2</sup> Kyseinen malli ei ollut teoriaa vaan se saatiin toteutettua siten, ett\u00e4 se tunnisti yksinkertaisia kuvioita, kuten neli\u00f6n ja ympyr\u00e4n. Voit tutustua alkuper\u00e4iseen artikkeliin l\u00e4hteiden kautta l\u00f6ytyv\u00e4st\u00e4 PDF-tiedostosta. <sup>8</sup></p> <p></p> <p>Kuva 2: Lehtileike Research Trends -lehden kes\u00e4n 1958 numerosta. Huomaa ingressi: \"Introducing the perceptron \u2014 A machine which senses, recognizes, remembers, and responds like the human mind.\" <sup>8</sup></p>"},{"location":"neuroverkot/neuroverkot_101/#ai-talven-alku","title":"AI-talven alku","text":"<p>MIT:n tohtori Marvin Minsky ja Seymour Papert julkaisivat vuonna 1969 kirjan Perceptrons, jossa he osoittivat, ett\u00e4 yksitt\u00e4inen kerros ei pysty ratkaisemaan tiettyj\u00e4 ongelmia, kuten XOR-ongelmaa. Howard ja Gugger <sup>2</sup> toteavat, ett\u00e4 samassa Perceptrons-kirjassa esiteltiin my\u00f6s ratkaisuja ongelmaan, kuten useiden kerrosten k\u00e4ytt\u00f6. Heid\u00e4n mukaansa vain rajoitukset saivat huomiota, ja n\u00e4in alkoi parin vuosikymmenen \"talvi\", jolloin neuroverkkojen tutkimus hiipui.</p>"},{"location":"neuroverkot/neuroverkot_101/#80-luvun-kevat","title":"80-luvun kev\u00e4t","text":"<p>AI-talven j\u00e4lkeen alkoi taas tapahtua. 1986 David Rumelhart, James McClelland ja PDP Research Group julkaisivat moniosaisen artikkelin Parallel Distributed Processing (PDP). Howard ja Gugger nostavat t\u00e4m\u00e4n viimeisen 50 vuoden k\u00e4\u00e4nteentekevimm\u00e4ksi julkaisuksi. PDP:n asettamat vaatimukset, kuten \"joukko prosessointiyksik\u00f6it\u00e4\" ja \"ulostulon funktio\", ovat edelleen keskeisi\u00e4 neuroverkkojen m\u00e4\u00e4ritelm\u00e4ss\u00e4. Skaala on toki kasvanut: 80-luvulla verkoissa oli yleens\u00e4 2 kerrosta. Jo t\u00e4ll\u00f6in, 80- ja 90-luvuilla, koneoppimisella oli jo oikeita k\u00e4ytt\u00f6tarkoituksia, mutta AI-tutkimus koki yh\u00e4 tietynlaista AI-talvea. Vasta \u00e4skett\u00e4in, 2010-luvun lopulla, alkoi nykyinen AI-kev\u00e4t. <sup>2</sup> Avainsanoja t\u00e4ss\u00e4 nykyisen kev\u00e4\u00e4n alussa ovat esimerkiksi AlexNet, AlphaGo, GAN, GPU.</p> <p>Video 1: Stanfordin tohtori Jay McClelland vastaa Podcastiss\u00e4 kysymykseen \"What is Parallel Distributed Processing?\" eli PDP. Videolla keskustellaan siit\u00e4, miksi ihminen muistaa helpommin h\u00e4nelle esitetyn kirjaimen, jos esitetyt kirjaimet muodostavat sanan.</p> <p>Video 2: Yann LeCun esiintyy vuonna 1989 videolla esittelem\u00e4ss\u00e4 LeNEt 1 -verkkoa (9760 parametria), joka kykenee tunnistamaan k\u00e4sinkirjoitettuja numeroita. Datasetti tunnetaan nimell\u00e4 MNIST. T\u00e4m\u00e4 kyseinen video on ConvNet-verkon avulla kuvanlaadultaan paranneltu versio alkuper\u00e4isest\u00e4. Videolla esiintyy siis konvoluutioverkkojen esi-is\u00e4, ja videota on korjailtu vuosikymmeni\u00e4 my\u00f6hemmin sen kunnioittamiseksi.</p> <p>80-luvulla vaikuttivat my\u00f6s 2024 Nobelilla palkitut John J. Hopfield ja Geoffrey Hinton. <sup>9</sup> Daniel Crevier nostaa Hopfieldin ty\u00f6n merkityksen esilleen esiin kirjassaan AI: The Tumultuous Search for Artificial Intelligence. H\u00e4n kirjoittaa, ett\u00e4 AI-talvi loppui osaltaan 80-luvulla Hopfieldin julkaisuun, mainiten my\u00f6s PDP:n sek\u00e4 backpropagation-algoritmin, joihin kumpaankin liittyy Rummelhart. <sup>10</sup> Suomalaisena on kuitenkin hyv\u00e4 huomauttaa, ett\u00e4 backpropagation-algoritmin ensimm\u00e4isen\u00e4 keksinyt lienee Seppo Linnainmaa pro gradu -ty\u00f6ss\u00e4\u00e4n vuonna 1970, joskaan ei neuroverkon kontekstissa. T\u00e4st\u00e4 huolimatta: \"As of 2020, all modern software packages for NNs (such as Google's Tensorflow) are based on Linnainmaa's method of 1970.\" <sup>11</sup></p> <p></p> <p>Kuva 3: Hopfield network -mallin toimintaa graafisesti kuvattuna. Vastaava maisemassa vaeltaminen lienee Johdatus koneoppimiseen -kurssin Gradient Descent -osiosta tuttu. Kuva: \u00a9Johan Jarnestad/The Royal Swedish Academy of Sciences</p>"},{"location":"neuroverkot/neuroverkot_101/#matalat-neuroverkot","title":"Matalat neuroverkot","text":""},{"location":"neuroverkot/neuroverkot_101/#viittaus-koneoppimiseen","title":"Viittaus koneoppimiseen","text":"<p>Ennen kuin tutustumme aiheen syv\u00e4\u00e4n p\u00e4\u00e4tyyn eli syviin neuroverkkoihin (engl. deep neural networks), on hyv\u00e4 tarkistella matalia neuroverkkoja (engl. shallow neural networks). Kertaa alkuun Johdatus koneoppimiseen kurssilta Normaaliyht\u00e4l\u00f6, Gradient Descent sek\u00e4 Logistinen regressio. Kyseisell\u00e4 kurssilla sinulle on kerrottu, ett\u00e4 n\u00e4iss\u00e4 aiheissa on pohja neuroverkkojen ymm\u00e4rrykselle. Nyt on siihen paneutumisen aika.</p> <p>Tavallisen 1D-regressiomallin rajoituksia ovat <sup>12</sup>, ett\u00e4 se voi mallintaa:</p> <ul> <li>vain viivan</li> <li>yhden inputin</li> <li>yhden outputin</li> </ul> <p>N\u00e4it\u00e4 rajoituksia kierrettiin Johdatus koneoppimiseen kurssilla osin k\u00e4ytt\u00e4m\u00e4ll\u00e4 logistista regressiota, SGD:t\u00e4 ja polynomeja. Jos j\u00e4lkimm\u00e4inen ei her\u00e4t\u00e4 muistikuvia, kertaa scikitin dokumentaatiosta PolynomialFeatures, jonka avulla muuttujista <code>[a, b]</code> voi muodostaa toisen asteen polynomifunktion <code>[a, b, a^2, ab, b^2]</code>. Malli on yh\u00e4 lineaarinen parametrien suhteen, mutta muunnettu piirreavaruus mahdollistaa ep\u00e4lineaaristen kuvioiden mallintamisen alkuper\u00e4isess\u00e4 sy\u00f6teavaruudessa. T\u00e4m\u00e4 ei ehk\u00e4 ole tieteellisesti t\u00e4ysin p\u00e4tev\u00e4 vertaus, mutta voi auttaa: kuvittele, ett\u00e4 piirr\u00e4t logaritmiseen taulukkoon suoran viivan. Viiva on lineaarinen logaritmisessa avaruudessa, mutta alkuper\u00e4isess\u00e4 mittakaavassa (\"todellisuudessa\") se kuvaa eksponentiaalista k\u00e4yr\u00e4\u00e4.</p>"},{"location":"neuroverkot/neuroverkot_101/#maaritelma_1","title":"M\u00e4\u00e4ritelm\u00e4","text":"<p>Kuva 4: Matala neuroverkko koostuu kerroksista: sy\u00f6te (input), piilotettu (hidden) ja tuloste (output). Kerrokset yhdist\u00e4v\u00e4t eteenp\u00e4in suunnatut yhteydet (nuolet), joten n\u00e4it\u00e4 kutsutaan eteenp\u00e4in sy\u00f6tt\u00e4viksi verkoiksi (feed-forward networks). Kun jokainen muuttuja yhdistyy kaikkiin seuraavan kerroksen muuttujiin, kyseess\u00e4 on t\u00e4ysin yhdistetty verkko. Yhteydet edustavat painokertoimia, piilokierroksen muuttujia kutsutaan neuroneiksi tai piiloyksikk\u00f6iksi (hidden units). (CC-BY-NC-ND) <sup>12</sup></p> <p>Yll\u00e4 n\u00e4kyv\u00e4n kuvan verkosta tekee matalan se, ett\u00e4 siin\u00e4 on vain yksi piilokerros. Jos kerroksia olisi useita, kyseess\u00e4 olisi syv\u00e4 neuroverkko. N\u00e4ihin tutustumme my\u00f6hemmin.</p> <p>Nyt pyyd\u00e4n sinua palaamaan takaisin Johdatus Koneoppimiseen kurssin Logistinen regressio osioon. Siell\u00e4 on esitelty logistinen regressio, joka on k\u00e4yt\u00e4nn\u00f6ss\u00e4 yksi neuroni. Jos kytket sy\u00f6tteen useisiin neuroneihin, saat piilokerroksen. Jos kytket piilokerroksen useisiin neuroneihin, saat tulostekerroksen (output). N\u00e4in sinulla on neuroverkko luotuna. Muista, ett\u00e4 tuloja ja l\u00e4ht\u00f6j\u00e4 voi olla useita.</p>"},{"location":"neuroverkot/neuroverkot_101/#mita-se-tekee","title":"Mit\u00e4 se tekee?","text":"<p>K\u00e4sitell\u00e4\u00e4n t\u00e4m\u00e4n otsikon alla seuraavanlaista verkkoa:</p> <p></p> <p>Kuva 5: Yksinkertainen neuroverkko, jossa on vain yksi sy\u00f6te x, kolme piilotettua neuronia ja yksi tulos. Vasemmanpuoleiseen versioon on lis\u00e4ttyn\u00e4 vakiotermi (intercept, bias), joka yleens\u00e4 j\u00e4tet\u00e4\u00e4n kuvaajista pois. (CC-BY-NC-ND) <sup>12</sup></p> <p>Kaikki kuvan nuolet ovat painoja (weights). Lineaarialgebrassa n\u00e4it\u00e4 kutsuttaisiin kulmakertoimiksi (slope), mutta neuroverkoissa termi on paino. Koska meill\u00e4 on 1 sis\u00e4\u00e4ntulo ja 3 neuronia, n\u00e4iden v\u00e4lill\u00e4 on <code>1 x 3</code> eli kolme painoa. Lis\u00e4ksi kutakin vakiotermi\u00e4 (bias) kohden on yksi paino, joten niit\u00e4 on kolme lis\u00e4\u00e4. Yhteens\u00e4 painoja on siis kuusi. Toivon mukaan t\u00e4m\u00e4 alkaa kuulostaa tutulta, kun mietit Johdatus koneoppimiseen kurssin normaaliyht\u00e4l\u00f6n matriisiesityst\u00e4, joka k\u00e4siteltiin Hill Climbing osiossa. Kuvaa tutkimalla huomaat, ett\u00e4 esimerkiksi \\(\\theta_{10}\\) ja \\(\\theta_{11}\\) vastaavat painoja, jotka yhdist\u00e4v\u00e4t sy\u00f6tteen \\(x\\) ja vakiotermin \\(1\\) piilotetun kerroksen ensimm\u00e4iseen neuroniin \\(h_1\\). Theta on siis 3x2 matriisi, joka n\u00e4ytt\u00e4\u00e4 t\u00e4lt\u00e4:</p> \\[ \\Theta = \\begin{bmatrix} \\theta_{10} &amp; \\theta_{11} \\\\ \\theta_{20} &amp; \\theta_{21} \\\\ \\theta_{30} &amp; \\theta_{31} \\end{bmatrix} \\] <p>Eli siis \\(h_1\\), \\(h_2\\) ja \\(h_3\\), tai tarkemmin niiden esiasteet (pre-activation), lasketaan seuraavasti:</p> \\[ \\begin{align*} h_{pre1} &amp;= \\theta_{10} + \\theta_{11} x \\\\ h_{pre2} &amp;= \\theta_{20} + \\theta_{21} x \\\\ h_{pre3} &amp;= \\theta_{30} + \\theta_{31} x \\end{align*} \\] <p>Yll\u00e4 olevissa lukee pienell\u00e4 <code>pre</code>, koska kyseess\u00e4 ovat esiasteet (engl. pre-activations), jotka merkit\u00e4\u00e4n usein lyhenteell\u00e4 \\(z\\), ja tunnetaan my\u00f6s nimell\u00e4 logitti (engl. logit). N\u00e4ist\u00e4 saa varsinaiset piilotetun yksik\u00f6n aktivoinnit (activations) aktivointifunktion avulla. K\u00e4sittelemme aktivointifunktiot my\u00f6hemmin kattavammin, mutta t\u00e4ss\u00e4 v\u00e4liss\u00e4 riitt\u00e4\u00e4 hyv\u00e4ksy\u00e4, ett\u00e4 kunkin piilotetun kerroksen neuronin laskema arvo sy\u00f6tet\u00e4\u00e4n tyypillisesti ReLu-aktivointifunktioon, joka palauttaa nollan, jos sy\u00f6te on negatiivinen, ja sy\u00f6tteen itsens\u00e4, jos se on positiivinen.</p> <p></p> <p>Kuva 6: ReLu-aktivointifunktio. (CC-BY-NC-ND) <sup>12</sup></p> <p>Kun t\u00e4m\u00e4 aktivointifunktio, \\(f(z) = max(0, z)\\), joka tunnetaan jatkossa pienen\u00e4 sigmana (\\(\\sigma\\)), on otettu huomioon, piilotetun kerroksen arvot ovat siis:</p> \\[ \\begin{align*} h_1 &amp;= \\sigma(\\theta_{10} + \\theta_{11} x) \\\\ h_2 &amp;= \\sigma(\\theta_{20} + \\theta_{21} x) \\\\ h_3 &amp;= \\sigma(\\theta_{30} + \\theta_{31} x) \\end{align*} \\] <p>Yll\u00e4 olevassa kaavassa <code>x</code> on sy\u00f6te, \\(\\theta\\) on painot ja \\(h\\) on piilotetun kerroksen aktivoinnit eli varsinaiset hidden unit eli piiloyksik\u00f6t. N\u00e4iden lineaarinen yhdistelm\u00e4 antaa tuloksen <code>y</code>:</p> \\[ y = \\phi_0 + \\phi_1 h_1 + \\phi_2 h_2 + \\phi_3 h_3 \\] <p>Kaiken kaikkiaan mallin opittua parametrej\u00e4 ovat siis:</p> \\[ \\begin{align*} \\phi_0 &amp;= \\text{tuloskerroksen vakiotermi (bias)} \\\\ \\phi_1, \\phi_2, \\phi_3 &amp;= \\text{tuloskerroksen painot} \\\\ \\theta_{10}, \\theta_{20}, \\theta_{30} &amp;= \\text{piilotetun kerroksen muuttujien painot} \\\\ \\theta_{11}, \\theta_{21}, \\theta_{31} &amp;= \\text{piilotetun kerroksen vakioiden painot} \\end{align*} \\] <p>N\u00e4m\u00e4 nelj\u00e4 vaihetta, eli esiasteet, aktivoinnit, piilokerroksen l\u00e4ht\u00f6 ja viimeisen kerroksen tulos n\u00e4kyv\u00e4t alla olevassa kuvassa.</p> <p></p> <p>Kuva 7: Neuroverkon laskennan vaiheet <code>a-j</code>. Viimeisen kuvaajan varjostetussa alueessa \\(h_2\\) on passiivinen (leikattu), mutta \\(h_1\\) ja \\(h_3\\) ovat molemmat aktiivisia. (CC-BY-NC-ND) <sup>12</sup></p> <ul> <li>Esiasteet (a-c): Sy\u00f6te x sy\u00f6tet\u00e4\u00e4n kolmeen lineaarifunktioon, joista jokaisella on eri y-leikkauspiste ja kulmakerroin.</li> <li>Aktivoinnit (d-f): Jokainen lineaarifunktio sy\u00f6tet\u00e4\u00e4n ReLU-aktivointifunktioon, joka leikkaa negatiiviset arvot nollaan.</li> <li>Painotus (g-i): Kolmea leikattu funktiota painotetaan (skaalataan) kertoimilla \\(\\phi_1\\), \\(\\phi_2\\) ja \\(\\phi_3\\).</li> <li>Yhteenlasku (j): Leikatut ja painotetut funktiot summataan yhteen ja lis\u00e4t\u00e4\u00e4n offset-arvo \\(\\phi_0\\), joka kontrolloi korkeutta.</li> </ul> <p>Huomaa, ett\u00e4 kuvaajassa on kolme \"nivelt\u00e4\". T\u00e4st\u00e4 tulee termi piecewise linear function (suom. paloittain m\u00e4\u00e4ritelty lineaarinen funktio). Mik\u00e4li ennustettava ilmi\u00f6 on monimutkainen, tarvitaan useampia piilokerroksia, jotta t\u00e4m\u00e4 paloittain m\u00e4\u00e4ritelty funktio saadaan taiteltua haluttuun muotoon. Alla t\u00e4st\u00e4 viel\u00e4 havainnollistava kuva.</p> <p></p> <p>Kuva 8: Katkoviivalla n\u00e4kyv\u00e4\u00e4 todellista ilmi\u00f6t\u00e4 voi yritt\u00e4\u00e4 mallintaa eri piiloverkon kokoisilla malleilla. Vasemmanpuoleinen malli on selke\u00e4sti liian yksinkertainen, oikea on tarkka (joskin kenties liian tarkka.) (CC-BY-NC-ND) <sup>12</sup></p> <p>Jos haluat tutustua aiheeseen syvemmin, tutustu Understanding Deep Learning kirjaan, joka on ilmainen ja avoin verkossa. Kirjaan liittyv\u00e4 Qatarin yliopiston kurssi l\u00f6ytyy my\u00f6s ilmaiseksi YouTube: Deep Learning Fall 2024.</p>"},{"location":"neuroverkot/neuroverkot_101/#koulutus-ja-inferenssi","title":"Koulutus ja inferenssi","text":"<p>Kurssilla k\u00e4sitell\u00e4\u00e4n neuroverkkojen koulutusta ja inferenssi\u00e4 (eli mallin k\u00e4ytt\u00f6\u00e4). Esitell\u00e4\u00e4n termit jo kuitenkin t\u00e4ss\u00e4 alkuvaiheessa, koska ne ovat keskeisi\u00e4 neuroverkkojen ymm\u00e4rt\u00e4misess\u00e4, ja pohjustavat vastavirta (backpropagation) algoritmia, jota k\u00e4sitell\u00e4\u00e4n parin seuraavan osion aikana.</p> <p>Aiheesta l\u00f6ytyy my\u00f6s pidempi Nvidian artikkeli, jos haluat tutustua: What\u2019s the Difference Between Deep Learning Training and Inference?</p>"},{"location":"neuroverkot/neuroverkot_101/#koulutus","title":"Koulutus","text":"<p>Koulutusvaiheessa mallille sy\u00f6tet\u00e4\u00e4n koulutusdataa. T\u00e4m\u00e4 on Johdatus koneoppimisesta tuttu <code>X_train</code>-osuus datasetist\u00e4. Malli laskee ennusteet \\(\\hat{y}\\) ja vertaa niit\u00e4 todellisiin arvoihin \\(y\\). N\u00e4iden erotus lasketaan h\u00e4vi\u00f6funktiolla (loss function). H\u00e4vi\u00f6funktio palauttaa yhden luvun, joka kertoo kuinka hyvin malli suoriutui. T\u00e4m\u00e4n luvun perusteella mallin parametrej\u00e4 s\u00e4\u00e4det\u00e4\u00e4n, jotta h\u00e4vi\u00f6 pienenee. T\u00e4t\u00e4 toistetaan useita kertoja, kunnes malli on oppinut halutun tason tarkkuuden. T\u00e4m\u00e4n pit\u00e4isi olla kertausta Johdatus koneoppimiseen -kurssilta. Kannattaa vilkaista omia muistiinpanoja ja omaa oppimisp\u00e4iv\u00e4kirjaa.</p> <p>Neuroverkkojen koulutukseen liittyy yksi hyvinkin keskeinen ero perinteisiin malleihin verrattuna: Neuroverkot oppivat itse piirteet (feature learning). Perinteisiss\u00e4 malleissa piirteet piti usein valita k\u00e4sin, mutta neuroverkot pystyv\u00e4t oppimaan hy\u00f6dylliset piirteet suoraan datasta.</p> <p>Koulutuksen aikana tarvittu muistin m\u00e4\u00e4r\u00e4 riippuu monesta tekij\u00e4st\u00e4. Jos haluat tutustua asiaan klikkailemalla, k\u00e4y kurkkaamassa interaktiivista Hugging Facen blogikirjoitusta Visualize and understand GPU memory in PyTorch.</p>"},{"location":"neuroverkot/neuroverkot_101/#inferenssi","title":"Inferenssi","text":"<p>Inferenssi on mallin k\u00e4ytt\u00f6\u00e4. Kun malli on koulutettu, se kirjoitetaan levylle: tai siis tarkemmin sanottuna sen parametrit tallennetaan. Jatkossa parametrit voidaan ladata k\u00e4ytt\u00f6\u00f6n, jopa useille eri laitteille samanaikaisesti rinnakkain, ja mallia voidaan k\u00e4ytt\u00e4\u00e4 ennustamiseen. T\u00e4t\u00e4 kutsutaan inferenssiksi.</p> <p>Neuroverkkojen inferenssi vaatii v\u00e4hemm\u00e4n muistia (ja laskentatehoa) kuin koulutus, koska mallin parametrej\u00e4 ei en\u00e4\u00e4 s\u00e4\u00e4det\u00e4. Malli vain suorittaa eteenp\u00e4in sy\u00f6tt\u00e4misen (feed-forward) laskennan. Mallia voidaan my\u00f6s eri tekniikoin pienent\u00e4\u00e4 ilman ett\u00e4 suorituskyky k\u00e4rsii liikaa. N\u00e4it\u00e4 tekniikoita ovat esimerkiksi kvantisointi (quantization), karsinta (pruning) ja \"tislaus tai tiivistys\" (distillation). N\u00e4it\u00e4 k\u00e4sitell\u00e4\u00e4n my\u00f6hemmin kurssilla ainakin pintapuolisesti. On hyv\u00e4 kuitenkin jo tunnistaa, ett\u00e4 mallin k\u00e4ytt\u00f6kulut (inferenssi) ja koulutuskulut (training) eroavat toisistaan merkitt\u00e4v\u00e4sti. K\u00e4yt\u00e4nn\u00f6ss\u00e4 voit t\u00f6rm\u00e4t\u00e4 vaikkapa BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding-julkaisun malliin BERT sivustolla Hugging Face siten, ett\u00e4 osa vaatii enemm\u00e4n ja osa v\u00e4hemm\u00e4n suorituskyky\u00e4. Alla taulukkona suuntaa-antava vertailu.</p> Malli n parameteria Tensor tyyppi optimoinnin taso Muistin tarve painoille bert-base-uncased 110M float32 Alkuper\u00e4inen koulutettu malli ~440 MB distilbert-base-uncased 66M float32 40% pienempi, 60% nopeampi ~264 MB distilbert-base-uncased-distilled-squad 66M float32 QA-teht\u00e4viin hienos\u00e4\u00e4detty ~264 MB distilbert-base-uncased-distilled-squad-int8-static-inc 66M int8 Kvantisointi ~66 MB <p>Muistin tarpeen voi laskea helposti: 32-bittinen liukuluku vaatii 4 tavua muistia. N\u00e4it\u00e4 on 110 miljoonaa, joten 110M * 4B = 440MB. Kvantisoinnissa mallin painot muunnetaan 8-bittisiksi kokonaisluvuiksi, jolloin muistin tarve on vain nelj\u00e4sosa alkuper\u00e4isest\u00e4. Huomaa, ett\u00e4 inferenssiss\u00e4 muistia tarvitsee my\u00f6s muita asioita, kuten sy\u00f6tteet, v\u00e4liarvot ja mahdolliset v\u00e4limuistit. Todellisen muistin tarve voi siis olla esimerkiksi 20-50 % enemm\u00e4n kuin pelkkien painojen vaatima muisti.</p>"},{"location":"neuroverkot/neuroverkot_101/#mihin-kaytetaan","title":"Mihin k\u00e4ytet\u00e4\u00e4n","text":"<p>Tutustu n\u00e4ihin:</p> <ul> <li>Dilmegani: Top 50 Deep Learning Use Case &amp; Case Studies</li> <li>Lex Fridman: Deep Learning Basics: Introduction and Overview (YouTube-video)</li> </ul>"},{"location":"neuroverkot/neuroverkot_101/#tehtavat","title":"Teht\u00e4v\u00e4t","text":"<p>Teht\u00e4v\u00e4: TensorFlow Playground</p> <p>Tutustu online-ty\u00f6kaluun TensorFlow Playground. Kokeile eri asetuksia ja yrit\u00e4 ymm\u00e4rt\u00e4\u00e4, miten ne vaikuttavat mallin oppimiseen, ja kuinka t\u00e4m\u00e4 liittyy yll\u00e4 kirjoitettuun teoriaan (ja historiaan). Dokumentoi omat havaintosi oppimisp\u00e4iv\u00e4kirjaasi \u2013 jatka t\u00e4t\u00e4 dokumentointia jatkossa kaikkien teht\u00e4vien yhteydess\u00e4.</p> <ol> <li> <p>Mallinna ty\u00f6kalulla Perceptron-paperin mukainen malli. Sinulla pit\u00e4isi olla siis \\(x_1\\) ja \\(x_2\\) sy\u00f6ttein\u00e4, ei yht\u00e4\u00e4n piilotettua kerrosta ja tulos. K\u00e4yt\u00e4 ReLU-aktivointifunktiota, vaikka se ei olekaan aivan 1958 ajan mukainen.</p> <p>Tunnista eri datasetit sivustolta. Ne ovat j\u00e4rjestyksess\u00e4:</p> <ul> <li><code>Circle</code></li> <li><code>Exclusive or</code> (XOR)</li> <li><code>Gaussian</code></li> <li><code>Spiral</code></li> </ul> </li> <li> <p>0 piilotettua: Todista, ett\u00e4 on mahdotonta ratkaista XOR-ongelma ilman piilotettua kerrosta. Todista Gauss mahdolliseksi.</p> </li> <li>1 piilotettu: Kokeile ratkaista XOR-ongelma yhdell\u00e4 piilotetulla kerroksella, jossa on 2-4 neuronia. Ratkaise my\u00f6s Gauss ja Circle.</li> <li>4 piilotettua: Kokeile ratkaista Spiral-ongelma nelj\u00e4ll\u00e4 piilotetulla kerroksella, joissa on kussakin 2-8 neuronia. Aloita pienemm\u00e4st\u00e4 mallista ja monimutkaista sit\u00e4 v\u00e4hitellen. Voi olla kannattavaa yritt\u00e4\u00e4 pit\u00e4\u00e4 inputin puolella olevat kerrokset suurempina (neuronim\u00e4\u00e4r\u00e4n osalta) kuin outputin puolella olevat kerrokset. Eli mallista tulee siis suppilo, joka piennee kohti outputtia.</li> </ol> <p>Teht\u00e4v\u00e4: Quick, Draw!</p> <p>Pelaa er\u00e4 (tai useampi) Googlen Quick, Draw! peli\u00e4.</p> <p>Tutustu t\u00e4m\u00e4n j\u00e4lkeen sen taustalla olevaan dataan domain/data.</p> <p>Tutustu viimeisen\u00e4 viel\u00e4 Kaggle-sivultolta l\u00f6ytyv\u00e4\u00e4n haasteeseen, jossa datan perusteella tulee pyrki\u00e4 tehd\u00e4 mahdollisimman tarkka luokittelija: Quick, Draw! Doodle Recognition Challenge.</p> <p>Teht\u00e4v\u00e4: UDLbook Shallow</p> <p>Lataa PDF-muodossa koneellesi Understanding Deep Learning kirja. Tutustu sen lukuun kolme, \"Shallow neural networks\" ja tee lopulta seuraavat teht\u00e4v\u00e4t:</p> <ul> <li>Problem 3.4 Draw a version of figure 3.3 where the y-intercept and slope of the third hidden unit have changed as in figure 3.14c. Assume that the remaining parameters remain the same.</li> <li>Problem 3.11 How many parameters does the model in figure 3.6 have?</li> </ul> <p>Voit k\u00e4ytt\u00e4\u00e4 ensimm\u00e4iseen teht\u00e4v\u00e4\u00e4n UDL-kirjan Interactive Figures-ty\u00f6kalua.</p> <p>Saat toki ratkaista halutessasi my\u00f6s muita ongelmia. Kurssilla siirryt\u00e4\u00e4n kuitenkin seuraavaksi teoriasta PyTorchin kautta k\u00e4yt\u00e4nt\u00f6\u00f6n.</p> <p>Teht\u00e4v\u00e4: ANN ja el\u00e4inkunta</p> <p>Kannattaa tutustua Wikipedian Cerebral cortex sek\u00e4 Neuron-artikkeleihin. Aivokuoren (engl. cerebral cortex) osalta aiheeseen liittyv\u00e4\u00e4 sis\u00e4lt\u00f6\u00e4 on ainakin \"Layers of neocortex\"-otsikkoon liittyv\u00e4 teksti ja kuvat. T\u00e4m\u00e4 ei ole biologian kurssi, joten silm\u00e4ily riitt\u00e4\u00e4. Neuroverkot (ANN, Artificial Neural Network) perustuvat ideatasolla siihen, kuinka aivojen synapsien ja neuronien verkosto toimii \u2013 tai ainakin, kuinka sen kuviteltiin toimivan viel\u00e4 1900-luvun puoliv\u00e4liss\u00e4.</p> <p>Vertaa nykyisi\u00e4 koneoppimismalleja el\u00e4inkunnan aivoihin. List of animals by number of neurons -lista on yksi mahdollinen l\u00e4hde. Jos verrataan melko naiivisti parametrim\u00e4\u00e4ri\u00e4, niin mit\u00e4 el\u00e4imi\u00e4 seuraavat mallit vastaavat:</p> Malli Vuosi desimaali potenssiesitys LeNet-5 1998 60 000 6.0 x 10^4 AlexNet 2012 60 000 000 6.0 x 10^7 GPT-3 2020 175 000 000 000 1.75 \u00d7 10^11 Grok-1 (open source) 2024 314 000 000 000 3.14 \u00d7 10^11 GPT-4 (spekulaatio) 2024 1 760 000 000 000 1.76 \u00d7 10^12 <p>Vinkki: mieti tarkkaan, kumpaa \"mallin parametrien m\u00e4\u00e4r\u00e4\" vastaa paremmin aivoissa: neuronien vai synapsien m\u00e4\u00e4r\u00e4?    </p> <p>Teht\u00e4v\u00e4: BERT Large</p> <p>Yll\u00e4 on esiteltyn\u00e4 BERT-mallin <code>base</code>-versio ja sen kevennetty <code>distilbert</code>-versio. Tutustu, kuinka BERT Large liittyy t\u00e4h\u00e4n. Kuinka monta parametria siin\u00e4 on? Kuinka paljon enemm\u00e4n muistia se vaatii verrattuna <code>base</code>-versioon? Miten se tai sen koulutus eroaa <code>base</code>-versiosta?</p> <p>Tutki samalla Hugging Face -sivustoon, jos se ei ole sinulle ennest\u00e4\u00e4n tuttu. Mit\u00e4 kaikkea sivustolta l\u00f6ytyy? Kuka sinne voi lis\u00e4t\u00e4 sis\u00e4lt\u00f6\u00e4?</p>"},{"location":"neuroverkot/neuroverkot_101/#lahteet","title":"L\u00e4hteet","text":"<ol> <li> <p>Nelson, H. Essential Math for AI. O'Reilly Media. 2023.\u00a0\u21a9\u21a9\u21a9</p> </li> <li> <p>Gugger, J. &amp; Howard, J. Deep Learning for Coders with fastai and PyTorch. O'Reilly Media. 2020.\u00a0\u21a9\u21a9\u21a9\u21a9\u21a9</p> </li> <li> <p>Dartmouth University. Artificial Intelligence Coined at Dartmouth. https://home.dartmouth.edu/about/artificial-intelligence-ai-coined-dartmouth\u00a0\u21a9</p> </li> <li> <p>McCarthy, J., Minsky, M.L., Rochester, N. &amp; Shannon, C.E. A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence. 1955. https://raysolomonoff.com/dartmouth/boxa/dart564props.pdf\u00a0\u21a9</p> </li> <li> <p>Krohn, J., Beyleveld, G. &amp; Bassens, A. Deep Learning Illustrated: A Visual, Interactive Guide to Artificial Intelligence. Addison-Wesley Professional. 2019.\u00a0\u21a9\u21a9\u21a9\u21a9</p> </li> <li> <p>The Nobel Prize. Nobel Prize in Physiology or Medicine 1981. https://www.nobelprize.org/prizes/medicine/1981/summary/\u00a0\u21a9</p> </li> <li> <p>Hubel, D.H. &amp; Wiesel, T.N. *Receptive fields of single neurones in the cat's striate cortex. The Journal of Physiology, 1959. https://doi.org/10.1113/jphysiol.1968.sp008455\u00a0\u21a9\u21a9</p> </li> <li> <p>Rosenblatt, F. The Design of an Intelligent Automaton. Research Trends, Cornell Aeronautical Laboratory. Summer 1958, Issue 2. https://www.informationphilosopher.com/solutions/scientists/rosenblatt/Rosenblatt_Research_Trends.pdf\u00a0\u21a9\u21a9</p> </li> <li> <p>The Nobel Prize. Nobel Prize in Physics 2024. https://www.nobelprize.org/prizes/physics/2024/summary/\u00a0\u21a9</p> </li> <li> <p>Crevier, D. AI: The Tumultuous Search for Artificial Intelligence. Basic Books. 1993. https://www.researchgate.net/profile/Daniel-Crevier/publication/233820788_AI_The_Tumultuous_History_of_the_Search_for_Artificial_Intelligence/links/63fe3d9457495059454f87ca/AI-The-Tumultuous-History-of-the-Search-for-Artificial-Intelligence.pdf\u00a0\u21a9</p> </li> <li> <p>Schmidhuber, J. Who Invented Backpropagation?. 2014 (p\u00e4ivitetty 2025). https://people.idsia.ch/~juergen/who-invented-backpropagation.html\u00a0\u21a9</p> </li> <li> <p>Prince, S. Understanding Deep Learning. The MIT Press. 2023. https://udlbook.github.io/udlbook/\u00a0\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9</p> </li> </ol>"},{"location":"neuroverkot/syvaoppiminen_FC/","title":"Syv\u00e4t neuroverkot","text":""},{"location":"neuroverkot/syvaoppiminen_FC/#syvaoppiminen","title":"Syv\u00e4oppiminen","text":""},{"location":"neuroverkot/syvaoppiminen_FC/#maaritelma","title":"M\u00e4\u00e4ritelm\u00e4","text":"<p>M\u00e4\u00e4ritelm\u00e4n osalta Understanding Deep Learning kirjan luvun 3 alku on hyv\u00e4:</p> <p>\"The last chapter described shallow neural networks, which have a single hidden layer. This chapter introduces deep neural networks, which have more than one hidden layer. With ReLU activation functions, both shallow and deep networks describe piecewise linear mappings from input to output.\" <sup>1</sup></p> <p>Prince toteaa, ett\u00e4 matalan neuroverkkojen kyky kuvata monimutkaisia funktioita kasvaa piilokerroksen neuronien m\u00e4\u00e4r\u00e4n lis\u00e4\u00e4ntyess\u00e4. Riitt\u00e4v\u00e4n suurella neuronim\u00e4\u00e4r\u00e4ll\u00e4 matalat verkot pystyv\u00e4t mallintamaan mielivaltaisen monimutkaisia funktioita. K\u00e4yt\u00e4nn\u00f6ss\u00e4 t\u00e4m\u00e4 on kuitenkin usein mahdotonta, sill\u00e4 tarvittava neuronien m\u00e4\u00e4r\u00e4 voi kasvaa kohtuuttoman suureksi. <sup>1</sup></p> <p></p> <p>Kuva 1: Kirjassa Deep Learning with Python syv\u00e4\u00e4 neuroverkkoa verrataan operaatioksi, jonka teht\u00e4v\u00e4 on suoristaa paperimytty. Input on paperimytty, ja n\u00e4ist\u00e4 opitaan ne datan representaation laskokset, jotka mytyn ovat luoneet <sup>2</sup>. Kuva on ChatGPT:ll\u00e4 luotu.</p> <p>Syv\u00e4t neuroverkot tarjoavat t\u00e4h\u00e4n ratkaisun: ne pystyv\u00e4t tuottamaan huomattavasti enemm\u00e4n lineaarisia alueita kuin matalat verkot samalla parametrim\u00e4\u00e4r\u00e4ll\u00e4. Kerrosten m\u00e4\u00e4r\u00e4n ja niiden neuronien m\u00e4\u00e4r\u00e4 on siis jotakin, mit\u00e4 pit\u00e4\u00e4 optimoida mallia suunniteltaessa. Palaamme t\u00e4h\u00e4n kohta t\u00e4ss\u00e4 samassa luvussa.</p>"},{"location":"neuroverkot/syvaoppiminen_FC/#yleiskatsaus","title":"Yleiskatsaus","text":"<p>T\u00e4ysin yhdistetyt kerrokset (engl. fully connected layers) ovat syv\u00e4oppimisen peruskomponentteja. Niiss\u00e4 jokainen neuroni on yhteydess\u00e4 kaikkiin edellisen kerroksen neuroneihin. T\u00e4m\u00e4 mahdollistaa monimutkaisempien suhteiden oppimisen sy\u00f6tteiden ja ulostulojen v\u00e4lill\u00e4. Tosiel\u00e4m\u00e4n mallit ovat 2020-luvulla siirtyneet yh\u00e4 enemm\u00e4n erilaisiin konvoluutio- ja toistoverkkoihin, mutta FC-kerrokset ovat edelleen keskeisi\u00e4 monissa arkkitehtuureissa. T\u00e4ss\u00e4 luvussa keskitymme verkkoihin, joissa on pelkki\u00e4 FC-kerroksia.</p> <p>Konsepti on helppo ja tulee toivon mukaan selv\u00e4ksi seuraavaa kuvaa katsomalla. Huomaat, ett\u00e4 olet toteuttanut n\u00e4it\u00e4 verkkoja jo edellisen luvun TensorFlow Playground -teht\u00e4v\u00e4ss\u00e4.</p> <p>Kuvassa kerroksen yksi neuronit ovat \\(h_1\\), \\(h_2\\) ja \\(h_3\\). Kunkin niiden tuloste p\u00e4\u00e4tyy seuraavan kerroksen kunkin neuronin sy\u00f6tteeksi.</p> <p></p> <p>Kuva 2: Kaksi kerroksinen syv\u00e4verkko, jossa on kaksi piilotettua kerrosta, joissa kussakin on kolme neuronia. Jokainen piilotettu kerros on t\u00e4ysin yhdistetty (fully connected) edelliseen kerrokseen. (CC-BY-NC-ND) <sup>1</sup></p>"},{"location":"neuroverkot/syvaoppiminen_FC/#laskutoimitukset","title":"Laskutoimitukset","text":"<p>Selvyyden vuoksi k\u00e4yd\u00e4\u00e4n l\u00e4pi, miten verkko toimii. Oletetaan, ett\u00e4 sy\u00f6tevektori on \\(x = [x_1, x_2]\\). Ensimm\u00e4isen piilotetun kerroksen neuronit laskevat seuraavasti: </p> \\[ \\begin{align*} h_1 &amp;= a(w_{11} x_1 + w_{12} x_2 + b_1) \\\\ h_2 &amp;= a(w_{21} x_1 + w_{22} x_2 + b_2) \\\\ h_3 &amp;= a(w_{31} x_1 + w_{32} x_2 + b_3) \\end{align*} \\] <p>miss\u00e4 \\(w_{ij}\\) ovat painot ja \\(b_i\\) on bias-termi. Funktio \\(a\\) on aktivointifunktio ReLU. Toinen kerros on monimutkaisempi, koska siin\u00e4 on kolme sy\u00f6tett\u00e4 ja kolme vastaanottavaan neuronia, joten painoja tulee olemaan \\(3 \\times 3 = 9\\). Toisen kerroksen neuronit laskevat seuraavasti:</p> \\[ \\begin{align*} h_4 &amp;= a(w_{41} h_1 + w_{42} h_2 + w_{43} h_3 + b_4) \\\\ h_5 &amp;= a(w_{51} h_1 + w_{52} h_2 + w_{53} h_3 + b_5) \\\\ h_6 &amp;= a(w_{61} h_1 + w_{62} h_2 + w_{63} h_3 + b_6) \\end{align*} \\] <p>N\u00e4m\u00e4 merkinn\u00e4t alkavat olla kohtalaisen sekavia, joten on parempi k\u00e4ytt\u00e4\u00e4 vektori- ja matriisimerkint\u00f6j\u00e4. Kummankin kerroksen ja ulostulon laskenta voidaan ilmaista seuraavasti:</p> \\[ \\begin{align*} h^{(1)} &amp;= a(W^{(1)} x + b^{(1)}) \\\\ h^{(2)} &amp;= a(W^{(2)} h^{(1)} + b^{(2)}) \\\\ y &amp;= W^{(3)} h^{(2)} + b^{(3)} \\end{align*} \\] <p>Yll\u00e4 olevassa kaavassa \\(y\\) on laskettu ilman aktivointifunktiota. T\u00e4m\u00e4 tekee mallista regressiomallin, joka sopii hyvin jatkuvien arvojen ennustamiseen. Jos mallia halutaan k\u00e4ytt\u00e4\u00e4 bin\u00e4\u00e4riseen luokitteluun, siihen lis\u00e4t\u00e4\u00e4n sigmoid-aktivointifunktio. Huomaa, ett\u00e4 t\u00e4m\u00e4 on kertausta Johdatus koneoppimiseen -kurssin logistisesta regressiosta.</p> <p>Kurssin aikana tulemme k\u00e4ytt\u00e4m\u00e4\u00e4n PyTorch-kirjastoa, joka hoitaa paljon laskuja puolestamme. T\u00e4ss\u00e4 on jo esimakua siit\u00e4, kuinka yll\u00e4 olevat laskut voidaan toteuttaa PyTorchilla:</p> <pre><code># Esimerkin vuoksi W1 voisi n\u00e4ytt\u00e4\u00e4 t\u00e4lt\u00e4\nW1 = torch.tensor(\n    [\n    [0.11, 0.12],\n    [0.21, 0.22],\n    [0.31, 0.32]\n], dtype=torch.float32)\n\n# Lasketaan ensimm\u00e4inen kerros\nh1 = torch.relu(torch.matmul(W1, x) + b1)\n\n# Lasketaan toinen kerros\nh2 = torch.relu(torch.matmul(W2, h1) + b2)\n\n# Lasketaan ulostulo (ilman aktivointifunktiota)\ny = torch.matmul(W3, h2) + b3\n</code></pre> <p>Huomaa, ett\u00e4 t\u00e4ss\u00e4 on kyseess\u00e4 pelkk\u00e4 inferenssi eli ennustaminen. Koko mallin kouluttaminen vaatii viel\u00e4 paljon enemm\u00e4n koodia, ja t\u00e4m\u00e4 esitell\u00e4\u00e4n kurssilla my\u00f6hemmin.</p>"},{"location":"neuroverkot/syvaoppiminen_FC/#hyperparametrit","title":"Hyperparametrit","text":"<p>Syv\u00e4verkkojen suunnittelussa on useita hyperparametreja. Hyperparametrit ovat malliin liittyv\u00e4t asetukset, jotka valitetaan ennen sen kouluttamista \u2013 eli niit\u00e4 ei siis opita koulutusvaiheessa. T\u00e4ss\u00e4 luvussa keskitymme vain niihin hyperparametreihin, jotka liittyv\u00e4t FC-verkon kokoon:</p> <ul> <li>Kerrosten m\u00e4\u00e4r\u00e4 \\(K\\)</li> <li>Neuronien m\u00e4\u00e4r\u00e4 kussakin kerroksessa \\(D_k\\)</li> </ul> <p>Tutustumme my\u00f6s muihin hyperparametreihin kurssin edetess\u00e4. Hyperparametrien oikeita arvoja ei voi yksinkertaisesti tarkistaa jostakin Maolin taulukkokirjasta. Ne on l\u00f6ydett\u00e4v\u00e4 kokeilemalla.</p> <p></p> <p>Kuva 3: Syv\u00e4verkko, jossa on \\(K\\) piilotettua kerrosta, joissa kussakin on \\(D_k\\) neuronia. Jokainen piilotettu kerros on t\u00e4ysin yhdistetty (fully connected) edelliseen kerrokseen. T\u00e4h\u00e4n kuvaan on piirretty mukaan my\u00f6s vakiotermit (bias) \\(b_k\\), jotka ovat \\(D_k\\)-ulotteisia vektoreita. (CC-BY-NC-ND) <sup>1</sup></p> <p>Huomaa, ett\u00e4 jos meid\u00e4n budjetti GPU-muistille sallii vain \\(N = 1000\\) painoa, voimme valita esimerkiksi luoda \\(K=2\\) kerrosta, joissa kummassakin \\(D_k = 500\\) neuronia. Tai voimme tehd\u00e4 \\(K=5\\) kerrosta, joissa kussakin on \\(D_k = 200\\) neuronia. Tai voimme luoda suppilon, jossa ensimm\u00e4isess\u00e4 kerroksessa on \\(D_1 = 400\\) neuronia, toisessa \\(D_2 = 300\\), kolmannessa \\(D_3 = 200\\) ja nelj\u00e4nness\u00e4 \\(D_4 = 100\\). Kaikki n\u00e4m\u00e4 vaihtoehdot k\u00e4ytt\u00e4v\u00e4t saman verran muistia, mutta niill\u00e4 on erilaiset kyvyt oppia erilaisia funktioita. Jos tutkit vanhoja malleja, huomaat, ett\u00e4 suppilo oli ennen hyvinkin suosittu arkkitehtuuri. Nyky\u00e4\u00e4n on tavallisempaa k\u00e4ytt\u00e4\u00e4 saman kokoisia kerroksia. G\u00e9ron antaa nyrkkis\u00e4\u00e4nn\u00f6n, ett\u00e4 paremman hy\u00f6dyn saa tyypillisesti lis\u00e4\u00e4m\u00e4ll\u00e4 kerrosten m\u00e4\u00e4r\u00e4\u00e4 kuin neuronien m\u00e4\u00e4r\u00e4\u00e4 kerroksessa. <sup>3</sup></p> <p>\"A typical neural network for MNIST might have 3 hidden layers, the first with 300 neurons, the second with 200, and the third with 100. However, this practice has been largely abandoned because it seems that using the same number of neurons in all hidden layers performs just as well in most cases, or even better; plus, there is only one hyperparameter to tune, instead of one per layer. That said, depending on the dataset, it can sometimes help to make the first hidden layer bigger than the others.\" <sup>3</sup></p>"},{"location":"neuroverkot/syvaoppiminen_FC/#case-mlp-ja-mnist","title":"Case: MLP ja MNIST","text":""},{"location":"neuroverkot/syvaoppiminen_FC/#tehtavan-yleiskuvaus","title":"Teht\u00e4v\u00e4n yleiskuvaus","text":"<p>Aloitamme kurssin tutustumalla yksinkertaiseen syv\u00e4verkkoon, joka tunnetaan nimell\u00e4 monikerroksinen perceptroni (MLP, multi-layer perceptron). MLP on syv\u00e4verkko, joka koostuu useista t\u00e4ysin yhdistetyist\u00e4 kerroksista (FC-kerrokset), joissa on aktivointifunktio kunkin kerroksen j\u00e4lkeen. Valitsemamme ongelma, tai dataset, on MNIST. Lyhenteen NIST tulee sanoista National Institute of Standards and Technology, joka on Yhdysvaltain hallituksen virasto. Kirjain M tulee sanasta Modified. Dataa on esiprosessoitu siten, ett\u00e4 se on sopivassa muodossa koneoppimiseen, tehden siit\u00e4 hyv\u00e4n Hello World -esimerkin koneoppimiselle. Tyypillisess\u00e4 koneoppimisteht\u00e4v\u00e4ss\u00e4 saat hyvin harvoin n\u00e4in valmista dataa k\u00e4siisi: kuvat on valmiiksi rajattu, skaalattu, keskitetty ja muunnettu vektoreiksi. MNIST on kuitenkin erinomainen aloitus, koska se on pieni, helppo ymm\u00e4rt\u00e4\u00e4 ja sill\u00e4 on helppo kokeilla erilaisia malleja.</p> <p>MNIST-datassa on k\u00e4sinkirjoitettuja numeroita (0-9), jotka on skaalattu 28x28 pikselin harmaas\u00e4vykuviksi. Kuvat on esitetty alla olevassa kuvassa. PyTorchin MNNIST tarjoaa 60 000 koulutuskuvaa ja 10 000 testikuvaa. Kuvat ovat tavallisia yksikanavaisia harmaas\u00e4vykuvia PIL-formaatissa eli niiden pikseliarvot ovat v\u00e4lill\u00e4 <code>0-255</code>. Jos kaikki n\u00e4m\u00e4 kuvat lataisi yhteen tensoriin, sen koko olisi <code>[70000, 1, 28, 28]</code>.</p> <p></p> <p>Kuva 4: MNIST-datan esimerkkikuvia. Kuvat on poimittu PyTorch:n torchvision.datasets.MNIST-luokasta.</p> <p>Tavoite on siis: kouluttaa moniluokkainen luokittelija, joka pystyy tunnistamaan k\u00e4sinkirjoitetut numerot. T\u00e4m\u00e4 on 10-luokkainen luokitteluteht\u00e4v\u00e4, jossa jokainen luokka vastaa yht\u00e4 numeroa (0-9). Ty\u00f6 on jo tehty sinun puolestasi, koska t\u00e4m\u00e4 on kurssin aloitus, ja sinulle ei ole viel\u00e4 edes opetettu PyTorchin k\u00e4ytt\u00f6\u00e4. Koodi l\u00f6ytyy Notebookista <code>notebooks/nb/100/110_first_model.ipynb</code> t\u00e4m\u00e4n kurssimateriaalin repositoriota eli gh:sourander/syvaoppiminen. Aloitusluennolla sinulle on esitelty, mist\u00e4 mit\u00e4kin materiaalia l\u00f6ytyy, ja kuinka kurssi kannattaa suorittaa.</p> <p>Tip</p> <p>MLP:t ovat perusarkkitehtuuri, josta monet muut neuroverkot on johdettu. Huomaa, ett\u00e4 arkkitehtuureita on useita erilaisia. Aloitamme yksinkertaisimmasta mahdollisesta, jossa on vain FC-kerroksia, mutta etenemme kurssin aikana monimutkaisempiin arkkitehtuureihin, kuten konvoluutio- ja toistoverkkoihin (RNN). Tulet luomaan kurssin aikana konvoluutioverkon, joka istuu valittuun teht\u00e4v\u00e4\u00e4n paremmin kuin MLP.</p>"},{"location":"neuroverkot/syvaoppiminen_FC/#tulokset","title":"Tulokset","text":"<p>Aloitetaan k\u00e4\u00e4nteisesti tulosten esittelemisest\u00e4. Kuten on sanottu, MNIST on hyvinkin Hello World-tason teht\u00e4v\u00e4 n\u00e4in 2020-luvulla. Yksinkertainen MLP pystyy saavuttamaan yli 95 % tarkkuuden (accuracy) jo muutamassa minuutissa. Tulet huomaamaan, ett\u00e4 vaikeampien teht\u00e4vien kanssa koulutusajat kasvavat merkitt\u00e4v\u00e4sti, ja tarkkuudet j\u00e4\u00e4v\u00e4t usein vaatimattomaksi, varsinkin jos MLP-arkkitehtuuria k\u00e4ytet\u00e4\u00e4n vasarana, joka sopii teht\u00e4v\u00e4\u00e4n kuin teht\u00e4v\u00e4\u00e4n. Vasaralla viittaan sanontaan: \"it is tempting, if the only tool you have is a hammer, to treat everything as if it were a nail\" <sup>4</sup>. Tutustu alla olevaan kuvaajaan:</p> <p></p> <p>Kuva 5: MNIST-datalla koulutetun mallin tarkkuus (accuracy) ja h\u00e4vi\u00f6 (loss) koulutuksen aikana epookki epookilta.</p> <p>Kuvaajassa n\u00e4kyy nelj\u00e4 k\u00e4yr\u00e4\u00e4: <code>train_loss</code>, <code>train_acc</code>, <code>val_loss</code> ja <code>val_acc</code>. N\u00e4m\u00e4 kuvaavat mallin suoriutumista koulutusdatalla (train) ja validaatiodatalle (val). Koulutusdata on se data, jolla malli on koulutettu, ja validaatiodata on erillinen osajoukko datasta, jota ei ole k\u00e4ytetty mallin kouluttamiseen. Validaatiodataa k\u00e4ytet\u00e4\u00e4n mallin arviointiin koulutuksen aikana, jotta n\u00e4hd\u00e4\u00e4n, kuinka hyvin malli yleistyy n\u00e4kem\u00e4tt\u00f6m\u00e4\u00e4n dataan. Ideaalitilanteessa lopullinen arviointi tehd\u00e4\u00e4n testidatalla, joka on t\u00e4ysin erillinen sek\u00e4 koulutus- ett\u00e4 validaatiodatasta. T\u00e4ss\u00e4 meid\u00e4n yksinkertaisessa esimerkiss\u00e4 emme kuitenkaan tee erillist\u00e4 testidataa. Eli siis kaikki 60 000 kuvaa ovat koulutusdataa ja 10 000 kuvaa ovat validaatiodataa. Hyv\u00e4ksymme validaatiotuloksen lopulliseksi tulokseksi.</p> <p>Kuvaajan vaakasuuntainen akseli on epookkien m\u00e4\u00e4r\u00e4. Kuvan koulutuksessa on ajettu 100 epookkia. Yksi epookki tarkoittaa, ett\u00e4 koko koulutusdata on k\u00e4yty l\u00e4pi kerran. Koska koulutusdata on jaettu pienempiin eriin (batch), yksi epookki koostuu useammasta batchista. T\u00e4ss\u00e4 tapauksessa batch-koko on 128, joten yhdess\u00e4 epookissa on \\(60000 / 128 \\approx 469\\) askelta (batches). Malli p\u00e4ivitt\u00e4\u00e4 painojaan jokaisen batchin j\u00e4lkeen.</p>"},{"location":"neuroverkot/syvaoppiminen_FC/#koulutuksen-suoritusaika","title":"Koulutuksen suoritusaika","text":"<p>Koulutuksen tulokset eri raudalla:</p> Rauta Aika/epookki Aika/koko koulutus Lopputarkkuus (val) MacBook Pro (CPU) 2.9 s 4 min 48 s 95.35 % Linux PC (CPU) 3.2 s 5 min 22 s 95.21 % Linux PC (CUDA) 3.3 s 5 min 30 s 95.14 % MacBook Pro (MPS) 3.7 s 6 min 12 s 95.18 % Disco (CUDA) 4.0 s 8 min 38 s 95.37 % Win PC (CPU) 4.0 s 8 min 38 s 95.26 % Disco (CPU) 4.1 s 8 min 50 s 95.27 % Win PC (GPU) 6.9 s 11 min 32 s 95.26 % Google Colab (CPU) 10.8 s 18 min 00 s 95.35 % Google Colab (CUDA) 13.8 s 23 min 00 s 95.19 % Jupyter Hub (CPU) 20.4 s 33 min 24 s 95.35 % Jupyter Hub (0.33x GPU) 20.5 s 34 min 10 s 95.33 % <p>Macbook Pro on tarkemmalta malliltaan M2 Max (32 GB muistia). MPS (Metal Performance Shaders) on Apple Siliconin GPU-kiihdytys. PC on p\u00f6yt\u00e4kone i7-12700F suorittimella, 32 GB keskusmuistilla ja NVIDIA RTX 3060 Ti -n\u00e4yt\u00f6nohjaimella, jossa on 8 GB muistia. Linuxissa koodi ajetaan ilman konttia natiivissa suoritusymp\u00e4rist\u00f6ss\u00e4; Windowsissa sama kone k\u00e4ytt\u00e4\u00e4 Docker WSL 2:sta. Jupyter Hubissa koodi on ajettu tavallisena torstai-iltanap\u00e4iv\u00e4n\u00e4 ilman tietoa siit\u00e4, onko alustalla muita samanaikaisia k\u00e4ytt\u00e4ji\u00e4. Verrokkina listalla on Google Colab:n ilmainen CPU runtime sek\u00e4 GPU runtime (Tesla T4). </p>"},{"location":"neuroverkot/syvaoppiminen_FC/#epookkien-maara","title":"Epookkien m\u00e4\u00e4r\u00e4","text":"<p>Miksik\u00f6 juuri 100 epookkia? Koska se on mukavan py\u00f6re\u00e4 summa. Esimerkin mallin rakenne on lainattu Adrian Rosebrockin kirjasta Deep Learning for Computer Vision with Python Volume 1. Kukaan ei luonnollisesti pakota meit\u00e4 pys\u00e4htym\u00e4\u00e4n juuri 100 epookkiin, joten tutkitaan, mit\u00e4 tapahtu, jos jatkamme koulutusta 500 epookkiin asti.</p> <p>Alla n\u00e4kyy kuvaajissa, mit\u00e4 tapahtuu 100-500 epookin aikana. Kuvaajat on otettu ty\u00f6kalusta nimelt\u00e4\u00e4n TensorBoard, joka tulee sinulle tutuksi kurssin aikana. Lopputarkkuudet 500. epookin kohdalla ovat 99.79 % (train) ja 98.15 % (val). Alemmasta kuvasta (Kuva 6) n\u00e4kee, kuinka accuracy ei ole parantunut en\u00e4\u00e4 400. epookin j\u00e4lkeen laisinkaan validaatiodatalla, mutta koulutusdataa vasten se on edelleen parantunut. T\u00e4m\u00e4 on malliesimerkki ylikoulutumisesta (overfitting).</p> <p></p> <p>Kuva 6: TensorBoardissa on mahdollista zoomata kuvaajaan sis\u00e4\u00e4n. T\u00e4ss\u00e4 kuvaajassa n\u00e4kyy suunnilleen alue 100-500. Mallin virhe v\u00e4henee epookista 100 eteenp\u00e4in, mutta <code>train</code> ja <code>val</code> k\u00e4yr\u00e4t alkavat erkaantua toisistaan, mik\u00e4 viittaa ylikoulutukseen.</p> <p></p> <p>Kuva 7: T\u00e4ss\u00e4 kuvaajassa on zoomattu alueelle 400-500 accuracy-k\u00e4yr\u00e4ss\u00e4. Kuten n\u00e4kyy, validaatiotarkkuus ei ole parantunut 400. epookin j\u00e4lkeen, mutta koulutustarkkuus jatkaa parantumistaan. T\u00e4m\u00e4 on selke\u00e4 merkki ylikoulutumisesta (overfitting). Malli k\u00e4yt\u00e4nn\u00f6ss\u00e4 oppii ulkoa koulutusdatan.</p>"},{"location":"neuroverkot/syvaoppiminen_FC/#nostoja-koodista","title":"Nostoja koodista","text":"<p>Alempana on teht\u00e4v\u00e4, jossa sinua k\u00e4sket\u00e4\u00e4n ajaa Notebook, joka kouluttaa mallin. T\u00e4m\u00e4 toimii samalla kertaa sek\u00e4 \"Opi PyTorchia lukemalla\" ett\u00e4 \"Testaa kehitysymp\u00e4rist\u00f6si toimivuus\" -teht\u00e4v\u00e4n\u00e4. Teht\u00e4v\u00e4n lomassa sinun tulee k\u00e4yd\u00e4 koodi l\u00e4pi, mutta t\u00e4ss\u00e4 on joitakin nostoja, jotka kannattaa huomioida.</p>"},{"location":"neuroverkot/syvaoppiminen_FC/#datan-lataus","title":"Datan lataus","text":"<p>Mallin data ladataan n\u00e4in:</p> <pre><code># Define transforms\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.1307,), (0.3081,))\n])\n\n# Download and load the training data\nprint(\"[INFO] accessing MNIST...\")\ntrainset = datasets.MNIST(*args, train=True, **kwargs)\ntestset = datasets.MNIST(*args, train=False, **kwargs)\n</code></pre> <p>Koodisnippetist\u00e4 on p\u00e4\u00e4telt\u00e4viss\u00e4 ainakin, kuinka MNIST-datan voi normalisoida k\u00e4ytt\u00e4en <code>Normalize()</code>-metodia. Normalisoinnissa annetaan kaksi argumenttia: sy\u00f6tteiden keskiarvo ja keskihajonta. MNIST-tapauksen kohdalla n\u00e4m\u00e4 ovat hyvin tunnettuna arvoja ja ne on laskettu nimenomaan training-datalla. Kyseinen torchvision.transforms.Normalize itsess\u00e4\u00e4n on Johdatus koneoppimiseen -kurssilta tuttu juttu. Se on tarkalleen ottaen sama asia kuin sklearnin <code>StandardScaler</code>: \"Normalize a tensor image with mean and standard deviation. This transform does not support PIL Image.\"</p>"},{"location":"neuroverkot/syvaoppiminen_FC/#batchien-lataus","title":"Batchien lataus","text":"<p>Datan lataus tapahtuu <code>DataLoader</code>-luokan avulla. Kyseinen luokka on iteraattori-tyylinen olio, joka on wrapper datan ymp\u00e4rille. Se mahdollistaa datan k\u00e4sittelyn eriss\u00e4 (batches) ja se osaa sekoittaa datan (shuffle) sek\u00e4 ladata dataa rinnakkaisesti useammalla s\u00e4ikeell\u00e4 (num_workers). Alla on esimerkki koulutusdatan lataamisesta:</p> <pre><code># Create data loaders\ntrainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\ntestloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)\n</code></pre> <p>My\u00f6hemmin koulutusloopissa dataa haetaan n\u00e4in:</p> <pre><code>for epoch in range(EPOCHS):\n    model.train()\n    for batch_idx, (inputs, labels) in enumerate(trainloader):\n        # Training code here\n</code></pre>"},{"location":"neuroverkot/syvaoppiminen_FC/#batchin-koko","title":"Batchin koko","text":"<p>Miksi <code>BATCH_SIZE</code> on juuri 128? Alla taulukko, josta voit lukea tyypillisi\u00e4 eri er\u00e4koon vaikutuksia koulutukseen, tulokseen, muistink\u00e4ytt\u00f6\u00f6n ja niin edelleen:</p> Pienet (2-8) Medium (16-64) Large (64-2048) Muistink\u00e4ytt\u00f6 Pieni Kohtalainen Suuri Base learning rate Korkea arvo, laaja alue Keskikokoinen Pieni arvo, kapea alue. Gradientin laatu Kohinaisa, mutta ajantasainen Tasapainoinen Vakaa Lopputarkkuus Paras? Hyv\u00e4? Varoen hyv\u00e4? <p>Yll\u00e4 oleva taulukko perustuu Revisiting Small Batch Training for Deep Neural Networks julkaisuun <sup>5</sup>. Kysymysmerkit ovat minun lis\u00e4. G\u00e9ron mainitsee, ett\u00e4 er\u00e4iss\u00e4 tutkimuksissa my\u00f6s hyvinkin suuret er\u00e4t (esim. 8192) ovat toimineet hyvin, kunhan oppimisnopeus aloitetaan pienest\u00e4 arvosta. Oppiminen voi olla t\u00e4ll\u00f6in hyvinkin nopeaa. <sup>6</sup></p> <p>Er\u00e4koon valinta on hyperparametri \u2013 sanotaan usein. Pieni er\u00e4 koko voi johtaa ep\u00e4vakaampiin p\u00e4ivityksiin, mutta se voi my\u00f6s auttaa mallia yleistym\u00e4\u00e4n paremmin. Suuremmat er\u00e4t voivat hy\u00f6dynt\u00e4\u00e4 GPU:n rinnakkaisprosessointia tehokkaammin. Jos Google Researchin Tuning Playbookiin on uskominen, er\u00e4koko ei ylip\u00e4\u00e4t\u00e4ns\u00e4 ole hyperparametri vaan tekninen valinta: \"The batch size should not be treated as a tunable hyperparameter for validation set performance.\" <sup>7</sup> He siis k\u00e4yt\u00e4nn\u00f6ss\u00e4 ehdottavat, ett\u00e4 er\u00e4koko valitaan sen perusteella, mik\u00e4 parantaa thoughputtia ja koulutuksen nopeutta. Muut hyperparametrit, kuten learning rate, s\u00e4\u00e4det\u00e4\u00e4n sitten er\u00e4koko huomioiden.</p> <p>Selvyyden vuoksi sanottakoon viel\u00e4, ett\u00e4:</p> <ul> <li>Batch on siis N joukko kuvia, jotka sy\u00f6tet\u00e4\u00e4n malliin kerralla. Niiden pit\u00e4\u00e4 mahtua muistiin.</li> <li>Epookissa on useita askelia (steps). Tarkka askelten m\u00e4\u00e4r\u00e4 riippuu kuvien m\u00e4\u00e4r\u00e4st\u00e4 ja er\u00e4koosta. Eli <code>60 000 / 128 = 469</code> askelta per epookki. Tai <code>60 000 / 1 = 60 000</code> askelta per epookki, jos batch-koko on 1.</li> </ul>"},{"location":"neuroverkot/syvaoppiminen_FC/#mallin-maarittely","title":"Mallin m\u00e4\u00e4rittely","text":"<p>Malli m\u00e4\u00e4ritell\u00e4\u00e4n <code>MLP</code>-luokassa, joka perii <code>nn.Module</code>-luokan ominaisuudet.</p> <pre><code>class MLP(nn.Module):\n    def __init__(self):\n        super(MLP, self).__init__()\n        self.fc1 = nn.Linear(784, 256)\n        self.fc2 = nn.Linear(256, 128)\n        self.fc3 = nn.Linear(128, 10)\n\n    def forward(self, x):\n        x = x.view(-1, 784)\n        x = torch.sigmoid(self.fc1(x))\n        x = torch.sigmoid(self.fc2(x))\n        x = self.fc3(x)\n        return x\n</code></pre> <p>Mieti, mit\u00e4 forward-metodi tarkalleen palauttaa. Tuleeko sielt\u00e4 raakatulokset (logits) vai softmaxin l\u00e4pi k\u00e4yneet todenn\u00e4k\u00f6isyydet? Jos olet sit\u00e4 mielt\u00e4, ett\u00e4 raakatulokset, niin miss\u00e4 kohtaa koodia softmax tehd\u00e4\u00e4n? Tulet huomaamaan, ett\u00e4 PyTorchissa on useita tapoja tehd\u00e4 samoja asioita \u2013 aivan kuten ohjelmoinnissa yleens\u00e4kin.</p> Vaihtoehtoinen mallin m\u00e4\u00e4rittely ilman luokkaa <p>Huomaa, ett\u00e4 mallin voisi m\u00e4\u00e4ritell\u00e4 my\u00f6s ilman <code>nn.Module</code>-perint\u00e4\u00e4. T\u00e4ll\u00f6in koodi n\u00e4ytt\u00e4isi t\u00e4lt\u00e4:</p> <pre><code>model = nn.Sequential(\n    nn.Flatten(),\n    nn.Linear(784, 256),\n    nn.Sigmoid(),\n    nn.Linear(256, 128),\n    nn.Sigmoid(),\n    nn.Linear(128, 10),\n    nn.LogSoftmax(dim=1)\n)\n</code></pre> <p>T\u00e4m\u00e4 on kuitenkin PyTorchin kohdalla harvinaisempi tapa. Emme k\u00e4yt\u00e4 sit\u00e4 t\u00e4ll\u00e4 kurssilla.</p> <p>Huomaa, ett\u00e4 MLP on luokka. T\u00e4m\u00e4 mahdollistaa, ett\u00e4 sin\u00e4 voit itse lis\u00e4t\u00e4 luokkaan tarpeen mukaan metodeja. Ainoat pakolliset metodit ovat <code>__init__</code> ja <code>forward</code>. Kukaan ei est\u00e4 sinua tekem\u00e4st\u00e4 esimerkiksi <code>def initialize_weights(self):</code> -metodia, joka alustaa painot haluamallasi tavalla. Mallin <code>super()</code>-kutsussa saadut metodit ja ominaisuudet selvi\u00e4v\u00e4t PyTorchin dokumentaatiosta: https://pytorch.org/docs/stable/generated/torch.nn.Module.html.</p>"},{"location":"neuroverkot/syvaoppiminen_FC/#termistoa","title":"Termist\u00f6\u00e4","text":"<p>Alla on t\u00e4h\u00e4n asti kurssilla k\u00e4ytettyj\u00e4 termej\u00e4, jotka tulee jo nyt laittaa korvan taakse. T\u00e4ss\u00e4 vaiheessa kurssia l\u00e4hinn\u00e4 vain nime\u00e4mme kurssilla k\u00e4yt\u00e4vi\u00e4 aiheita. Syv\u00e4llisemp\u00e4\u00e4 k\u00e4sittely\u00e4 seuraa PyTorchin kautta my\u00f6hemmiss\u00e4 luvuissa.</p> Termi Selitys Painot (weights) Mallin parametrit, jotka oppivat datasta. Jokaisella yhteydell\u00e4 on oma painonsa. Tyypillisess\u00e4 kuvaajassa n\u00e4m\u00e4 esitet\u00e4\u00e4n viivoina, joiden paksuus tai v\u00e4ri voi kuvata painon suuruutta. Bias Mallin parametrit, jotka oppivat datasta. Jokaisella neuronilla on oma bias-termi. Aktivaatiofunktio Funktio, joka lis\u00e4t\u00e4\u00e4n neuronin ulostuloon. Aktivointifunktio tekee mallista ei-lineaarisen. Tappiofunktio Funktio, joka mittaa mallin virheen. Koulutuksen aikana pyrit\u00e4\u00e4n minimoimaan valittu loss function. Optimointi Prosessi, jossa mallin painot ja bias-termit p\u00e4ivitet\u00e4\u00e4n loss-funktion minimoimiseksi. Epoch Yksi l\u00e4pik\u00e4ynti koko koulutusdatasta. Batch Pieni osa koulutusdatasta, joka sy\u00f6tet\u00e4\u00e4n malliin kerralla. Learning rate Hyperparametri, joka m\u00e4\u00e4ritt\u00e4\u00e4, kuinka suuria p\u00e4ivityksi\u00e4 mallin painoihin ja biaseihin tehd\u00e4\u00e4n."},{"location":"neuroverkot/syvaoppiminen_FC/#tehtavat","title":"Teht\u00e4v\u00e4t","text":"<p>Teht\u00e4v\u00e4: UDLbook Deep</p> <p>Lue Understanding Deep Learning kirjasta v\u00e4hint\u00e4\u00e4n luvu 4.1 \"Composing neural networks\" sek\u00e4 4.2 \"From composing networks to deep networks\". Kirjoita itsellesi lyhyt yhteenveto aiheesta omin sanoinesi, jotta ymm\u00e4rr\u00e4t asian. Huomaa, ett\u00e4 aihetta k\u00e4sitell\u00e4\u00e4n my\u00f6s yll\u00e4 (ja kurssivideoilla).</p> <p>Tutustu my\u00f6s UDL-kirjan kylki\u00e4isen\u00e4 tuleviin Interactive Figures-ty\u00f6kaluihin. Erityisesti Concatenating networks sek\u00e4 Deep network computation-kuvaajiin.</p> <p>Teht\u00e4v\u00e4: Valitse kehitysymp\u00e4rist\u00f6si</p> <p>Valitse itsellesi sopiva kehitysymp\u00e4rist\u00f6, jossa aiot tehd\u00e4 kurssin harjoitukset. Vaihtoehtoja on useita:</p> <ul> <li>Lokaali kone:<ul> <li><code>uv</code>-ymp\u00e4rist\u00f6 ja VS Code Notebooks (t\u00e4t\u00e4 opettaja k\u00e4ytt\u00e4\u00e4 macOS:ll\u00e4 ja Ubuntussa)</li> <li><code>docker</code>-ymp\u00e4rist\u00f6 ja Jupyter Lab (Windows + CUDA GPU suositus)</li> </ul> </li> <li>Jupyter Hub (DC-labran yll\u00e4pit\u00e4m\u00e4)</li> <li>Coder (DC-labran yll\u00e4pit\u00e4m\u00e4)</li> <li>Google Colab</li> <li>Joku muu pilvipalvelu, jossa on GPU</li> </ul> <p>HUOM! Opettaja ei voi realistisesti kokeilla kaikkia vaihtoehtoja, jotka syntyv\u00e4t <code>(\"Win\", \"Mac\", \"Linux\") x (\"pip\", \"uv\", \"docker\") x (\"jupyterhub\", \"colab\", \"marimo\")</code> -ristikkona. Valitse siis sellainen, joka sinulle on tuttu tai jonka opit helposti. Opettaja tarjoaa tukea, mutta \u00e4l\u00e4 odota, ett\u00e4 sinulle annetaan tasan yksi koodirimpsu, jolla kaikki toimii. Hallitse omat ymp\u00e4rist\u00f6si!</p> <p>Esittele valitsemasi kehitysymp\u00e4rist\u00f6 oppimisp\u00e4iv\u00e4kirjassa. Mik\u00e4li sen asennus vaatii erityisi\u00e4 toimenpiteit\u00e4, kirjaa ne talteen, jotta voit palata niihin my\u00f6hemmin tarvittaessa. Oppimisp\u00e4iv\u00e4kirja ei ole pelk\u00e4st\u00e4\u00e4n arvosteltava artefakti, vaan se on my\u00f6s sinun henkil\u00f6kohtainen muistikirjasi. Hy\u00f6dynn\u00e4 sit\u00e4.</p> <p>P.S. Tarkista aloitusluennon tallenne! Siell\u00e4 on mit\u00e4 varmimmin neuvottu ainakin yksi tapa asentaa tarvittava ymp\u00e4rist\u00f6!</p> <p>Teht\u00e4v\u00e4: Aja MNIST MLP koodi</p> <p>Koodi l\u00f6ytyy Marimo Notebookista <code>notebooks/nb/100/110_first_model.py</code> t\u00e4m\u00e4n kurssimateriaalin repositoriota eli gh:sourander/syvaoppiminen.</p> <ol> <li>Lataa Notebook koneellesi.</li> <li> <p>(Optional:) jos k\u00e4yt\u00e4t Jupyteri\u00e4, k\u00e4\u00e4nn\u00e4 Marimo Notebook Jupyter Notebook -muotoon. Alustasta riippuen t\u00e4m\u00e4 voi onnistua esimerkiksi n\u00e4in:</p> <pre><code># Jos uv\nuvx marimo export ipynb 110_first_model.py -o 110_first_model.ipynb.ipynb\n\n# Jos ei uv\npip install marimo\nmarimo export ipynb 110_first_model.py -o 110_first_model.ipynb\n</code></pre> </li> <li> <p>Aja Notebook kokonaisuudessaan. Varmista, ett\u00e4 saat mallin koulutettua ja kaikki solut ajettua.</p> </li> <li>Lue koodi kokonaisuudessaan l\u00e4pi! Emme ole viel\u00e4 opiskelleet PyTorchin k\u00e4ytt\u00f6\u00e4, mutta yrit\u00e4 konseptitasolla ymm\u00e4rt\u00e4\u00e4, mit\u00e4 kukin koodirivi tekee.</li> </ol> <p>Samalla n\u00e4et benchmarkkia siihen, kuinka sinun rautasi suhtautuu opettajan rautaan (ks. yll\u00e4 oleva taulukko).</p> <p>Teht\u00e4v\u00e4: TensorBoard</p> <p>Yll\u00e4 oleva koodi k\u00e4ytt\u00e4\u00e4 TensorBoardia koulutuksen seurantaan. Aja TensorBoard omassa ymp\u00e4rist\u00f6ss\u00e4si. Ohjeita t\u00e4h\u00e4n on Notebookin lopussa ja mahdollisisssa kurssivideoissa. Varautu ottamaan my\u00f6s itsen\u00e4isesti selv\u00e4\u00e4: tutki, mit\u00e4 tiedostoja Notebook loi ja mihin (ks. <code>runs/</code>-hakemisto). Lyhyimmill\u00e4\u00e4n komento on kuitenkin:</p> <pre><code>cd notebooks/\nuv run tensorboard --logdir=runs\n</code></pre> <p>Tutustu TensorBoardin k\u00e4ytt\u00f6liittym\u00e4\u00e4n ja sen tarjoamiin visualisointeihin. Tutki, mik\u00e4 rivi Notebookissa on vastuussa kunkin metriikan kirjaamisesta TensorBoardiin.</p> <p>Teht\u00e4v\u00e4: Mallin tarkkuus CPU vs MPS vs CUDA</p> <p>Tutustu yll\u00e4 olevaan \"Koulutuksen suoritusaika\"-osioon. Osiossa on taulukko, josta selvi\u00e4\u00e4, miten eri rauta vaikuttaa koulutuksen suoritusaikaan. Taulukkoon on asetettu esille my\u00f6s lopputarkkuus validaatiodatalla. Pohdi, ett\u00e4:</p> <ul> <li>Miksi Macbook (CPU ja MPS) sek\u00e4 Linux PC (CPU sek\u00e4 CUDA) eiv\u00e4t p\u00e4\u00e4sseet t\u00e4ysin samaan lopputarkkuuteen?</li> <li>Vaihteleeko t\u00e4m\u00e4 joka kerta kun koulutat mallin uudestaan?</li> <li>Miten ihmeess\u00e4 CPU voi olla hitaampi kuin GPU? Huijataanko meit\u00e4 ostamaan n\u00e4yt\u00f6nohjaimia turhaan?</li> </ul>"},{"location":"neuroverkot/syvaoppiminen_FC/#lahteet","title":"L\u00e4hteet","text":"<ol> <li> <p>Prince, S. Understanding Deep Learning. The MIT Press. 2023. https://udlbook.github.io/udlbook/\u00a0\u21a9\u21a9\u21a9\u21a9</p> </li> <li> <p>Watson, M &amp; Chollet, F. Deep Learning with Python, Third Edition. Manning. 2025.\u00a0\u21a9</p> </li> <li> <p>G\u00e9ron, A. Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 3rd Edition. O'Reilly Media. 2022.\u00a0\u21a9\u21a9</p> </li> <li> <p>Wikipedia. Law of the instrument. https://en.wikipedia.org/wiki/Law_of_the_instrument\u00a0\u21a9</p> </li> <li> <p>Masters, D. &amp; Luschi, C. Revisiting Small Batch Training for Deep Neural Networks. arXiv:1804.07612. 2018. https://arxiv.org/abs/1804.07612\u00a0\u21a9</p> </li> <li> <p>G\u00e9ron, A. Hands-On Machine Learning with Scikit-Learn and PyTorch. O'Reilly. 2025.\u00a0\u21a9</p> </li> <li> <p>Godbole, V., Dahl. E, Gilmer. J., Shallue, J. &amp; Nado. Z. Deep Learning Tuning Playbook. Google Research. https://github.com/google-research/tuning_playbook\u00a0\u21a9</p> </li> </ol>"},{"location":"siirtovaikutus/pretrained/","title":"Koulutetun mallin k\u00e4ytt\u00f6","text":"<p>T\u00e4ss\u00e4 osiossa k\u00e4yd\u00e4\u00e4n l\u00e4pi, miten esikoulutettua mallia voidaan hy\u00f6dynt\u00e4\u00e4 omassa projektissa ilman, ett\u00e4 tarvitsee kouluttaa mallia alusta asti itse. T\u00e4m\u00e4 on esivaihe seuraavalle osalle, jossa k\u00e4sitell\u00e4\u00e4n siirtovaikutusta (transfer learning). Lis\u00e4ksi kokeilemme, voiko esikoulutettua mallia k\u00e4ytt\u00e4\u00e4 sellaisenaan luomaan piirrevektoreita, joiden pohjalta voidaan kouluttaa Johdatus koneoppimiseen -kurssilta tuttuja perinteisi\u00e4 koneoppimismalleja, kuten Random Forestia tai Logistic Regressionia.</p>"},{"location":"siirtovaikutus/pretrained/#pytorchin-mallit","title":"PyTorchin mallit","text":"<p>PyTorchin valmiiksi koulutettuihin malleihin p\u00e4\u00e4see k\u00e4siksi kahta reitti\u00e4:</p> <ul> <li>PyTorch Hub -sivuston kautta</li> <li><code>torchvision.models</code> -moduulin avulla</li> </ul> <p>Jos tarkkoja ollaan, niin n\u00e4m\u00e4 reitit ovat sin\u00e4ns\u00e4 samat, ett\u00e4 <code>torchvision.models</code> k\u00e4ytt\u00e4\u00e4 taustalla PyTorch Hubia. Erona on, ett\u00e4 <code>torchvision.models</code> tarjoaa vain kuvantunnistukseen tarkoitettuja malleja, kun taas PyTorch Hubista l\u00f6ytyy malleja monenlaisiin tarkoituksiin, kuten luonnollisen kielen k\u00e4sittelyyn (NLP) ja generatiivisiin malleihin. Jotta t\u00e4m\u00e4 ei olisi liian helppoa, niin monet n\u00e4ist\u00e4 malleista ovat fyysisesti s\u00e4il\u00f6ttyn\u00e4 Hugging Facen mallivarastoon. Katso vaikka PyTorch Hub: PyTorch-Transformers-dokumentaatio.</p> <p>Tutustut n\u00e4ihin malleihin harjoituksissa alla.</p>"},{"location":"siirtovaikutus/pretrained/#hugging-face","title":"Hugging Face","text":"<p>PyTorchin itsens\u00e4 tarjoamien esikoulutettujen mallien lis\u00e4ksi on olemassa useita kolmannen osapuolen sivustoja tai kirjastoja, jotka tarjoavat laajan valikoiman esikoulutettuja malleja eri tarkoituksiin. Eri julkaisuihin l\u00f6ytyvi\u00e4 malleja voi l\u00f6yty\u00e4 esimerkiksi Githubista tai Zenodosta. T\u00e4ll\u00e4 kurssilla k\u00e4sitell\u00e4\u00e4n yksinkertaisuuden vuoksi vain ja ainoastaan Hugging Facea. Hugging Facella on ensimm\u00e4isen luokan tuki nimenomaan PyTorch-viitekehykselle <sup>1</sup>. Mik\u00e4 siis on Hugging Face? Ei ainakaan sit\u00e4, mik\u00e4 se perustamishetkell\u00e4 oli:</p> <p>\"In 2016, Clement Delangue, Julien Chamound, and Thomas Wolf launched an AI-powered chatbot for teenagers called Hugging Face. Their vision for the product was a digital friend that was entertaining enough for people to have fun talking to it\"</p> <p>\u2014 [Jason Shen, 2024]<sup>2</sup></p> <p>Nykyp\u00e4iv\u00e4n\u00e4 Hugging Face on API-talouden ilmentym\u00e4. Sen etusivun navigaatiossa olevista osioista voi p\u00e4\u00e4tell\u00e4 sen eri palvelut:</p> <ul> <li>Models: Esikoulutettuja malleja (2.2M kirjoitushetkell\u00e4). <ul> <li> T\u00e4m\u00e4n tunnin aihe!</li> </ul> </li> <li>Datasets: Valmiita datakokoelmia.</li> <li>Spaces: Mahdollistaa esimerkiksi Gradio\u2011 tai Streamlit\u2011pohjaisten sovellusten julkaisemisen ja jakamisen.</li> <li>Community: Blog articles, Social posts, Daily papers.</li> <li>Docs: dokumentaatio.</li> <li>Enterprise: yrityspalvelut.</li> </ul> <p>Sinun tulee rekister\u00f6ity\u00e4 Hugging Facen k\u00e4ytt\u00e4j\u00e4ksi, jotta voit ladata malleja ohjelmallisesti. Rekister\u00f6ityminen on ilmaista ja perusk\u00e4ytt\u00f6 on ilmaista. Joitakin malleja saa k\u00e4ytt\u00e4\u00e4 vain jos pyyd\u00e4t k\u00e4ytt\u00f6luvan sen tekij\u00e4lt\u00e4. N\u00e4ist\u00e4 k\u00e4ytet\u00e4\u00e4n termi\u00e4 Gated models.</p> <p>Erityisen mielenkiintoinen on PyTorch Image Models (timm)-organisaatio Hugging Facessa, ja siihen liittyv\u00e4 timm-kirjasto. T\u00e4m\u00e4 kirjasto tarjoaa yli 600 esikoulutettua mallia kuvantunnistukseen, mukaan lukien monet viimeisimm\u00e4t arkkitehtuurit.</p>"},{"location":"siirtovaikutus/pretrained/#tehtavat","title":"Teht\u00e4v\u00e4t","text":"<p>Teht\u00e4v\u00e4: Luo Hugging Face tunnus</p> <p>Rekister\u00f6idy Hugging Facen k\u00e4ytt\u00e4j\u00e4ksi osoitteessa [Hugging Face](https://huggingface.co/. Suosittelen k\u00e4ytt\u00e4m\u00e4\u00e4n henkil\u00f6kohtaista tunnusta koulun s\u00e4hk\u00f6postin sijasta. On todenn\u00e4k\u00f6ist\u00e4, ett\u00e4 haluat k\u00e4ytt\u00e4\u00e4 palvelua my\u00f6s valmistumisen j\u00e4lkeen ja yksityisiss\u00e4 projekteissa.</p> <p>Kun olet rekister\u00f6itynyt, sinun tulee luoda Access Token -avain. Avainta k\u00e4ytet\u00e4\u00e4n autentikointiin ohjelmallisesti (eli Pythonissa.) Tokenin luontiin l\u00f6ytyy ohjeistusta User access tokens-dokumentaatiosta. Lyhyt ohje on kuitenkin:</p> <ul> <li>Klikkaa profiilikuvaketta oikeasta yl\u00e4kulmasta ja valitse \"Access tokens\".</li> <li>Klikkaa <code>+Create new token</code> -painiketta.</li> <li>Valitse nimi ja haluamasi fine-grained -oikeudet (esim. <code>read</code> riitt\u00e4\u00e4 t\u00e4h\u00e4n kurssiin). \u00c4l\u00e4 stressaa oikeuksista: voit aina luoda uuden avaimen jos tarvitset enemm\u00e4n oikeuksia.</li> </ul> <p>Kun olet luonut tokenin, ota se v\u00e4liaikaisesti talteen. T\u00e4ss\u00e4 v\u00e4liss\u00e4 voit tehd\u00e4 autentikaation <code>uvx</code>:n ja <code>hf</code>-kirjastojen avulla:</p> <pre><code>uvx hf auth login\n</code></pre> <p>Komento kysyy sinulta tokenia. Liit\u00e4 token t\u00e4h\u00e4n. Muut kysymykset ja niiden tarkemman kuvauksen l\u00f6yd\u00e4t CLI: hf auth login-dokumentaatiosta.</p> <p>Teht\u00e4v\u00e4: Hugging Face Hello World</p> <p>Asenna transformers-kirjasto, jos sinulla ei sit\u00e4 jo ole. Suorita seuraava komento projektisi juuressa:</p> <pre><code>uv add \"transformers[retrieval,timm,torch-vision]\"\n</code></pre> <p>Warning</p> <p>T\u00e4ss\u00e4 pit\u00e4\u00e4 olla tarkkana kirjastojen riippuvuuksien suhteen. Tarvitsemme kirjastot <code>datasets</code> ja <code>huggingface_hub</code> my\u00f6s, mutta niit\u00e4 ei kannata l\u00e4ht\u00f6kohtaisesti asentaa erikseen. Asenna ne sen sijaan k\u00e4ytt\u00e4en <code>transformers</code>-kirjaston extras-ominaisuutta eli hakasulkeissa listatut lis\u00e4osat. T\u00e4m\u00e4 varmistaa, ett\u00e4 asennettavat versiot ovat yhteensopivia kesken\u00e4\u00e4n.</p> <p>Kirjoitushetkell\u00e4 minulle ei esimerkiksi ollut ollenkaan <code>torch</code>-kirjastoa asennettuna omana rivin\u00e4\u00e4n, koska <code>transformers</code> hoiti sen asennuksen automaattisesti (koska extrat). N\u00e4m\u00e4 asennettujen pakettien suhteet selvi\u00e4\u00e4 komennolla <code>uv tree</code>, ja viel\u00e4 tarkemmin voi tutkia <code>uv tree --package=transformers</code>. Rankasti parsittu output, joka korostaa mahdollista ongelmaa, n\u00e4kyy alla:</p> <pre><code>transformers v4.57.3\n\u251c\u2500\u2500 huggingface-hub v0.36.0\n\u2502   \u2514\u2500\u2500  ...\n\u251c\u2500\u2500 tokenizers v0.22.1\n\u2502   \u2514\u2500\u2500 huggingface-hub v0.36.0 (*)\n\u251c\u2500\u2500 datasets v4.4.1 (extra: retrieval)\n\u2502   \u2514\u2500\u2500 huggingface-hub v0.36.0 (*)\n\u251c\u2500\u2500 timm v1.0.19 (extra: timm)\n\u2502   \u251c\u2500\u2500 huggingface-hub v0.36.0 (*)\n\u2502   \u251c\u2500\u2500 torch v2.9.1\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u2514\u2500\u2500 torchvision v0.24.1\n\u2502       \u2514\u2500\u2500 torch v2.9.1 (*)\n\u2514\u2500\u2500 torchvision v0.24.1 (extra: torch-vision)\n</code></pre> <p>Jos k\u00e4yt gh:huggingface/huggingface_hub-repossa, huomaat, ett\u00e4 <code>huggingface_hub</code>-kirjasto on tuoreelta versioltaan (kirjoitushetkell\u00e4) <code>v1.2.3</code>. Kyseinen kirjasto on loikannut uuteen Major-versioon Oct 27. Jos asentaisit sen k\u00e4sin, <code>uv</code> asentaisi t\u00e4m\u00e4n tuoreen version, ja major on taaksep\u00e4in yhteensopimaon by definition. Saisit paljon erroria. Summa summarum, k\u00e4yt\u00e4 ison kirjaston extra-asennuksia aina kun mahdollista!</p> <ol> <li>\u00c4lk\u00e4\u00e4 ep\u00e4r\u00f6ik\u00f6 kysy\u00e4 apua, jos asennuksessa ilmenee ongelmia!</li> <li>\u00c4l\u00e4 vaivu \"opettajan pit\u00e4isi hoitaa n\u00e4m\u00e4 asiat\" -ajatteluun. T\u00e4m\u00e4 on osa ohjelmistokehityksen arkea, ja on t\u00e4rke\u00e4\u00e4 oppia ratkaisemaan n\u00e4m\u00e4 ongelmat. Et todellakaan tule s\u00e4\u00e4stym\u00e4\u00e4n kirjastoriippuvuuksien kanssa painimiselta my\u00f6hemmink\u00e4\u00e4n urallasi.</li> </ol> <p>Avaa <code>600_hello_hugging_face.py</code> ja suorita se. Jos autentikointi on onnistunut, ohjelma lataa Hugging Facen <code>transformers</code>-kirjatoa k\u00e4ytt\u00e4en sentimenttianalyysiin soveltuvan mallin ja suorittaa ennusteen esimerkkilauseelle. Kirjoitushetkell\u00e4 malli on distilbert/distilbert-base-uncased-finetuned-sst-2-english, joka on esikoulutettu DistilBERT-malli, hienos\u00e4\u00e4detty SST-2-datalle (Stanford Sentiment Treebank). Malli on noin 270 MB kokoinen.</p> <p>Ohjelman pit\u00e4isi tulostaa jotain seuraavan kaltaista:</p> <pre><code>[{'label': 'POSITIVE', 'score': 0.9998}]\n</code></pre> <p>Teht\u00e4v\u00e4: Hate Speech over Naive Bayes</p> <p>Toteuta <code>601_hate_speech.py</code>-tiedostoon puuttuvat kohdat \u2013 tunnistat ne sanasta <code>IMPLEMENT</code>. Tutustu skriptin toimintaan. Jos sinulla on Johdatus koneoppimiseen -kurssin muistiinpanot saatavilla, tarkista, mihin tarkkuuteen Naive Bayes -malli ylsi saman datan ja ongelman kanssa.</p> <p>Teht\u00e4v\u00e4: MobileNetV3 k\u00e4ytt\u00f6</p> <p>Tiedostossa <code>603_pretrained.ipynb</code> on Marimo Notebook, jossa on k\u00e4yt\u00f6ss\u00e4 torchvisionin esikoulutettu MobileNetV3 Small -malli.</p> <p>Muokkaa tiedostoa siten, ett\u00e4:</p> <ol> <li>Valitse jokin toinen luokka (ei opettajan valitsema magpie)</li> <li>Etsi internetist\u00e4 kuvia, jotka kuuluvat t\u00e4h\u00e4n luokkaan (v\u00e4hint\u00e4\u00e4n 1 kpl)</li> <li>Muokkaa <code>Display Image</code> siten, ett\u00e4 my\u00f6s esik\u00e4sitelty kuva n\u00e4ytet\u00e4\u00e4n.</li> <li>Tee ennuste.</li> </ol> <p>Voit kokeilla my\u00f6s muita malleja, kuten ResNet- tai EfficientNet-malleja, jotka soveltuvat luokitteluun \u2013 tai jos olet rohkea, kokeile vaikka Object Detection -malleja (esim. Faster R-CNN)! Luokitteluun sopivan mallin valinnassa voi auttaa kurssikirjan Table 12-3, Some of the pretrained models available in torchvision, sorted by size <sup>3</sup>. </p>"},{"location":"siirtovaikutus/pretrained/#lahteet","title":"L\u00e4hteet","text":"<ol> <li> <p>Watson, M &amp; Chollet, F. Deep Learning with Python, Third Edition. Manning. 2025.\u00a0\u21a9</p> </li> <li> <p>Shen, J. How Hugging Face Transformed a $4.5B AI Powerhouse [Pivot Case Study]. The Path to Pivot. 2024. https://www.pathtopivot.com/hugging-face-pivot-case-study/\u00a0\u21a9</p> </li> <li> <p>G\u00e9ron, A. Hands-On Machine Learning with Scikit-Learn and PyTorch. O'Reilly. 2025.\u00a0\u21a9</p> </li> </ol>"},{"location":"siirtovaikutus/transferlearning/","title":"Siirtovaikutus","text":""},{"location":"siirtovaikutus/transferlearning/#termi","title":"Termi","text":""},{"location":"siirtovaikutus/transferlearning/#pedagoginen-tausta","title":"Pedagoginen tausta","text":"<p>Siirtovaikutus (engl. transfer learning) tarkoittaa aiemmin hankitun tieton tai taidon hy\u00f6dynt\u00e4mist\u00e4 uudessa, usein suhteellisen samankaltaisessa teht\u00e4v\u00e4ss\u00e4. On hyv\u00e4 huomata, ett\u00e4 t\u00e4m\u00e4 termi ei ole alkujaan koneoppimisen kontekstissa syntynyt. Termi on kotoisin (kasvatus)psykologiasta. Pedagogiaa opiskelleet ovat l\u00e4hes v\u00e4ist\u00e4m\u00e4tt\u00e4 t\u00f6rm\u00e4nneet Thorndiken ja Woodworthin l\u00f6yd\u00f6ksiin 1900-luvun alusta, jossa he osoittivat, ett\u00e4 harjoittelun vaikutus yhdell\u00e4 osa-alueella voi siirty\u00e4 toiseen osa-alueeseen, mik\u00e4li molemmissa on yhteisi\u00e4 elementtej\u00e4. Kuten he kirjoittavat:</p> <p>\"The general consideration of the cases of retention or of loss of practice effect seems to make it likely that spread of practice occurs only where identical elements are concerned in the influencing and influenced function.\" <sup>1</sup></p> <p>Oppiiko tammea osaava lapsi nopeammin shakin kuin ei-tammea osaava lapsi? Ent\u00e4 oppiiko shakkia taitava lapsia vertaisiaan nopeammin pelaamaan Carcassonnea? Nykyiset oppimisk\u00e4sitykset kasvatustieteiss\u00e4 ja kognitiotieteiss\u00e4 ovat ep\u00e4ilem\u00e4tt\u00e4 kehittyneet Thorndiken ja Woodworthin ajoista, mutta koska t\u00e4m\u00e4n kurssin konteksti on koneoppiminen, emme syvenny pedagogisiin teorioihin enemp\u00e4\u00e4. Termin k\u00e4ytt\u00f6 koneoppimisen yhteydess\u00e4 on kuitenkin hyvin osuvaa, koska koneoppimisen siirtovaikutus perustuu pitk\u00e4lti samankaltaiseen periaatteeseen. Siirtovaikutus ei ole hopealuoti, joka ratkaisee kaikki ongelmat aina, mutta samankaltaisen teht\u00e4v\u00e4n \u00e4\u00e4rell\u00e4 se voi tarjota nopean ja tehokkaan tavan saavuttaa hyvi\u00e4 tuloksia. UKK-instituutin Siirtovaikutus-artikkeli on kirjoitettu liikunnan n\u00e4k\u00f6kulmasta, ja siin\u00e4 kyseenalaistetaan jo otsikkotasolla: \"Taidot siirtyv\u00e4t vai siirtyv\u00e4tk\u00f6?\" <sup>2</sup>.</p>"},{"location":"siirtovaikutus/transferlearning/#koneoppiminen","title":"Koneoppiminen","text":"<p>Koneoppimisen kontekstissa termi on syntynyt 1970-luvun aikoihin. Bozinovski koostaa historiallista taustaa artikkelissaan <sup>3</sup>, johon kannattaa tutustua ainakin pintapuoleisesti.</p> <p>\"Basically it is using a pre-trained neural network (trained for Task1) for achieving shorter training time (positive transfer learning) in learning Task2.\" <sup>3</sup></p> <p>On t\u00e4rke\u00e4\u00e4 erotta seuraavat termit:</p> <ul> <li>Siirtovaikutus (Transfer Learning): Yleinen k\u00e4site eli kattotermi. Aiemmin opitun tiedon hy\u00f6dynt\u00e4miseen uudessa teht\u00e4v\u00e4ss\u00e4 <sup>4</sup>.<ul> <li>Hienos\u00e4\u00e4t\u00f6 (Fine-tuning): Siirtovaikutuksen erityinen muoto, jossa esikoulutettua mallia s\u00e4\u00e4det\u00e4\u00e4n uudelleen uudessa teht\u00e4v\u00e4ss\u00e4, usein pienemm\u00e4ll\u00e4 oppimisnopeudella ja pienemm\u00e4ll\u00e4 datam\u00e4\u00e4r\u00e4ll\u00e4 <sup>4</sup>.</li> <li>Piirrepohjainen siirto (Feature-based transfer): Siirtovaikutuksen muoto, jossa esikoulutetun mallin piirteit\u00e4 k\u00e4ytet\u00e4\u00e4n suoraan uudessa teht\u00e4v\u00e4ss\u00e4 ilman mallin painojen hienos\u00e4\u00e4t\u00f6\u00e4 <sup>4</sup>.</li> </ul> </li> </ul> <p>T\u00e4ll\u00e4 kurssilla k\u00e4sittelemme erityisesti piirrepohjaista siirtoa. Toivon mukaan muistat konvoluutioverkoista sen, ett\u00e4 ne oppivat matalammilla tasoilla yleisi\u00e4 piirteit\u00e4, kuten reunoja ja muotoja, joista muodostetaan piirrevektori, jota k\u00e4ytet\u00e4\u00e4n luokitteluun. T\u00e4m\u00e4 korvaa piirrevektorin k\u00e4sin suunnitellut piirteet, joita k\u00e4ytettiin ennen syvien verkkojen aikakautta. Koska matalammat tasot oppivat yleisi\u00e4 piirteit\u00e4, niit\u00e4 voidaan hy\u00f6dynt\u00e4\u00e4 uudessa teht\u00e4v\u00e4ss\u00e4, joka on samankaltainen kuin alkuper\u00e4inen teht\u00e4v\u00e4. Esimerkiksi esikoulutettu verkko, joka on koulutettu tunnistamaan esineit\u00e4 ImageNet-datasetill\u00e4, voi olla hyv\u00e4 l\u00e4ht\u00f6kohta hienos\u00e4\u00e4t\u00f6\u00f6n (fine-tuning) esimerkiksi l\u00e4\u00e4ketieteellisten kuvien luokittelussa. T\u00e4ll\u00f6in verkon matalammat tasot s\u00e4ilytet\u00e4\u00e4n, ja vain mallin korkein taso, fully connected layer, eli varsinainen luokittelija, korvataan uudella.</p> <p>Erityisesti kielimallien kontekstissa hienos\u00e4\u00e4t\u00f6 on yleinen k\u00e4yt\u00e4nt\u00f6, jossa esikoulutettu malli, kuten GPT tai BERT, s\u00e4\u00e4det\u00e4\u00e4n uudelleen tiettyyn teht\u00e4v\u00e4\u00e4n, kuten tekstin luokitteluun tai kysymys-vastaus -teht\u00e4viin. Pohjalla on usein ohjaamatonta oppimista, tai tarkemmin self-supervised learning -l\u00e4hestymistapa, jossa malli oppii kielen rakenteita ja merkityksi\u00e4 suuresta tekstikorpuksesta ilman oikeaa vastausta (eli label puuttuu). T\u00e4m\u00e4n j\u00e4lkeen malli hienos\u00e4\u00e4det\u00e4\u00e4n pienemm\u00e4ll\u00e4, teht\u00e4v\u00e4kohtaisella datalla. T\u00e4h\u00e4n tutustutaan kenties t\u00e4ll\u00e4 kurssilla pintapuolisesti, mutta syv\u00e4llisemmin my\u00f6hemmill\u00e4 kursseilla.</p> <p>Jos p\u00e4\u00e4dyt suorittamaan hienos\u00e4\u00e4t\u00f6\u00e4, tarvitset enemm\u00e4n muistia kuin pelk\u00e4n loppuun liitetyn luokittelijan kanssa. Vastavirta-algoritmi tarvitsee t\u00e4ll\u00f6in kaikkien ei-lukittujen kerrosten painot, aktivoinnit ja gradientit. T\u00e4ss\u00e4 tulee \u00e4kki\u00e4 kotik\u00e4ytt\u00f6isen GPU:n rajat vastaan. Tosin tyypillisesti aivan kaikkia kerroksia ei ylip\u00e4\u00e4t\u00e4ns\u00e4 hienos\u00e4\u00e4det\u00e4: Watson ja Chollet suosittelevat partial fine-tuning -l\u00e4hestymistapaa, jossa vain verkon korkeimmat kerrokset s\u00e4\u00e4det\u00e4\u00e4n uudelleen, ja matalammat kerrokset pidet\u00e4\u00e4n lukittuina. T\u00e4rkeimmiksi syiksi he nostavat, ett\u00e4 (1) mallin alimmat kerrokset sis\u00e4lt\u00e4v\u00e4t geneerisi\u00e4 muotoja ja piirteit\u00e4, jotka ovat kontekstista toiseen p\u00e4tevi\u00e4, ja (2) ylim\u00e4\u00e4r\u00e4isten painojen sis\u00e4llytt\u00e4minen kouluttamiseen nostaa ylisovittamisen riski\u00e4. <sup>5</sup></p>"},{"location":"siirtovaikutus/transferlearning/#kaytannossa","title":"K\u00e4yt\u00e4nn\u00f6ss\u00e4","text":"<p>Esikouluttamisen mallin k\u00e4ytt\u00f6 piirteiden muodostamiseen on varsin helppoa. T\u00e4ll\u00f6in k\u00e4yt\u00e4nn\u00f6ss\u00e4 leikkaisit koko verkosta pois viimeisen luokittelukerroksen, ja k\u00e4ytt\u00e4isit j\u00e4ljelle j\u00e4\u00e4nytt\u00e4 verkkoa piirteiden muodostamiseen. Otetaan esimerkiksi ResNet50, jossa 50 viittaa 50x painokerrosten m\u00e4\u00e4r\u00e4\u00e4n. My\u00f6s t\u00e4m\u00e4 malli on koulutettu aiemmin tutuksi tulleella ImageNet-datasetill\u00e4.</p> <pre><code>conv_base = models.resnet50(weights='IMAGENET1K_V1')\n\n# T\u00e4m\u00e4 tulostaisi 49x painokerrosta - viimeisin on luokittelukerros nimelt\u00e4\u00e4n \"fc.weight\"\n[name for name, child in conv_base.named_parameters() if \"conv\" in name]\n\n# Meit\u00e4 kiinnostaa enemm\u00e4n verkon rakenne, joten kurkkastaan sen lapsia:\n[x for x in conv_base.named_children()]\n</code></pre> Output<pre><code>[\n  \"conv1\",\n  \"bn1\",\n  \"relu\",\n  \"maxpool\",\n  \"layer1\",\n  \"layer2\",\n  \"layer3\",\n  \"layer4\",\n  \"avgpool\",\n  \"fc\"\n]\n</code></pre> <p>Jos tutkimme pelkk\u00e4\u00e4 viimeist\u00e4 kerrosta, sen rakenne on seuraava:</p> <pre><code>conv_base.fc\n</code></pre> Output<pre><code>Linear(in_features=2048, out_features=1000, bias=True)\n</code></pre>"},{"location":"siirtovaikutus/transferlearning/#pelkat-piirteet-ulos","title":"Pelk\u00e4t piirteet ulos","text":"<p>Jos haluaisimme tallentaa piirteet ulos, voisimme rakentaa uuden mallin, joka ottaa sy\u00f6tteen\u00e4 kuvan ja palauttaa piirrevektorin:</p> <pre><code>import torch.nn as nn\n\nclass FeatureExtractor(nn.Module):\n    def __init__(self, base_model):\n        super(FeatureExtractor, self).__init__()\n        # Kopioi kaikki kerrokset paitsi viimeisen luokittelukerroksen\n        self.features = nn.Sequential(*list(base_model.children())[:-1])\n\n    def forward(self, x):\n        x = self.features(x)\n        x = torch.flatten(x, 1)  # Litist\u00e4 piirrevektori\n        return x\n\nfeature_extractor = FeatureExtractor(conv_base)\n\n# Usage\ndummy_input = torch.randn(2, 3, 224, 224)\nfeatures = feature_extractor(dummy_input)\nprint(features.shape)  # Should be (2, 2048)\n</code></pre> <p>N\u00e4m\u00e4 piirteet voi luonnollisesti tallentaa tiedostoon ja siten k\u00e4ytt\u00e4\u00e4 my\u00f6hemmin vaikkapa Logistic Regression -luokittelijan kouluttamiseen.</p>"},{"location":"siirtovaikutus/transferlearning/#loppuun-liitetty-luokittelija","title":"Loppuun liitetty luokittelija","text":"<p>Jos haluaisimme rakentaa mallin, jossa on loppuun liitetty luokittelija, voisimme tehd\u00e4 sen seuraavasti:</p> <pre><code>new_head = nn.Linear(in_features=2048, out_features=num_classes)\n\nconv_base.fc = new_head\n</code></pre> <p>Tip</p> <p>Huomaa, ett\u00e4 voimme sis\u00e4llytt\u00e4\u00e4 luokittelijaan my\u00f6s piilotetun kerroksen, jolloin rakenne olisi hieman monimutkaisempi, kuten:</p> <pre><code>new_head = nn.Sequential(\n    nn.Linear(in_features=2048, out_features=512),\n    nn.ReLU(),\n    nn.Dropout(0.5),\n    nn.Linear(in_features=512, out_features=num_classes)\n)\n\nconv_base.fc = new_head\n</code></pre> <p>Kun edellinen p\u00e4\u00e4 on korvattu uudella, meid\u00e4n tulee kouluttaa vain t\u00e4m\u00e4 uusi p\u00e4\u00e4. T\u00e4m\u00e4 onnistuu asettamalla muiden kerrosten <code>requires_grad</code>-attribuutin arvoksi <code>False</code>:</p> <pre><code>for param in conv_base.parameters():\n    param.requires_grad = False\n\n# Uuden fully connected -kerroksen gradientit pit\u00e4\u00e4 sen sijaan laskea\nfor param in conv_base.fc.parameters():\n    param.requires_grad = True\n</code></pre> <p>Jatkossa malli koulutetaan aivan kuten kaikki aiemmatkin kurssin mallit: sinun tulee kirjoittaa training loop, jossa suoritetaan eteenp\u00e4in- ja taaksep\u00e4in-sy\u00f6tt\u00f6, sek\u00e4 optimointivaihe.</p>"},{"location":"siirtovaikutus/transferlearning/#partial-fine-tuning","title":"Partial Fine-Tuning","text":"<p>Jos haluaisimme suorittaa osittaista hienos\u00e4\u00e4t\u00f6\u00e4, voisimme lukita vain osan verkon kerroksista. Esimerkiksi voisimme lukita kaikki kerrokset ennen <code>layer4</code>-kerrosta:</p> <pre><code>for name, parameter in conv_base.named_parameters():\n    parameter.requires_grad = False\n    if 'layer3.5.bn3.bias' in name:\n        break\n</code></pre> <p>On my\u00f6s mahdollista tehd\u00e4 t\u00e4m\u00e4 vaiheittain, eli kouluttaa \\(n\\) epookin ajan vain luokittelijaa, ja sen j\u00e4lkeen avata lis\u00e4\u00e4 kerroksia hienos\u00e4\u00e4t\u00f6\u00e4 varten.</p>"},{"location":"siirtovaikutus/transferlearning/#toolkit","title":"Toolkit","text":"<p>Ajoittain l\u00f6yd\u00e4t my\u00f6s valmiita ty\u00f6kaluja, jotka helpottavat siirtovaikutuksen hy\u00f6dynt\u00e4mist\u00e4. Esimerkiksi hf:ResembleAI/chatterbox-turbo on esikoulutettu Text-to-Speech-malli, jonka voi ladata ja hienos\u00e4\u00e4t\u00e4\u00e4 helposti Hugging Facen <code>transformers</code>-kirjaston avulla. Online-yhteis\u00f6, tai tarkemmin kehitt\u00e4j\u00e4 Gokhan Eraslan, on julkaissut ty\u00f6kalun, jolla hienos\u00e4\u00e4t\u00f6 onnistuu helposti omalla datalla k\u00e4ytt\u00f6ohjeineen: gh:gokhaneraslan/chatterbox-finetuning.</p>"},{"location":"siirtovaikutus/transferlearning/#tehtavat","title":"Teht\u00e4v\u00e4t","text":"<p>Teht\u00e4v\u00e4: Dogs vs. Cats siirtovaikutus</p> <p>Aja <code>610_dogs_vs_cats.py</code> Marimo Notebook.</p> <p>Kuinka korkealle sijoittautuisit alkuper\u00e4isess\u00e4 Kaggle: Dogs vs. Cats -kilpailussa? Adrian Rosebrock esitteli muinoin kirjassaan, kuinka AlexNet:n kouluttamalla kokonaan ko. datasetill\u00e4 saavutti noin 93 % tarkkuuden, mutta k\u00e4ytt\u00e4m\u00e4ll\u00e4 piirrepohjaista siirtovaikutusta (feature-based transfer learning) h\u00e4n saavutti 98.69 % tarkkuuden, jolla olisi p\u00e4\u00e4ssyt kilpailussa hopeasijalle! Mallina h\u00e4nell\u00e4 oli ResNet50, jolla h\u00e4n generoi piirrevektorit, joita h\u00e4n k\u00e4ytti Logistic Regression -luokittelijan sy\u00f6tteen\u00e4. <sup>6</sup></p> <p>Malli kouluttautui opettajan Macbookilla noin 8 minuuttia (5 epookkia).</p> <p>Teht\u00e4v\u00e4: RPS-datasetin luonti webcamilla</p> <p>Laurence Monorey, joka on mm. kirjan AI and ML for Coders in PyTorch kirjoittaja, jakaa verkkosivuillaan datasetti\u00e4 Rock Paper Scissors, joka sis\u00e4lt\u00e4\u00e4 kuvia k\u00e4simerkeist\u00e4 kivi, paperi ja sakset. Linkit ovat vanhoja, mutta alkuper\u00e4inen datasetti on yh\u00e4 ladattavissa storage.googleapis.com/learning-datasets/rps.zip-osoitteesta. Setiss\u00e4 on 840 kuvaa per luokka.</p> <p>Voisimme k\u00e4ytt\u00e4\u00e4 t\u00e4t\u00e4 CGI-generoitua datasetti\u00e4, mutta on paljon parmepaa oppimista kasata oma datasetti! Meill\u00e4 kaikilla on jokin webcam, joten k\u00e4ytt\u00e4k\u00e4\u00e4mme sit\u00e4. T\u00e4h\u00e4n l\u00f6ytyy valmis toteutus skriptist\u00e4 <code>611_rps_generator.py</code>, joka perustuu <code>wigglystuff</code>-kirjaston Marimo-widgettiin <code>WebcamCapture</code>. Skripti tallentaa kuvat <code>data/{label}/filename.jpg</code>-polkuun, jossa <code>{label}</code> on vakiona <code>rock</code>, <code>paper</code> tai <code>scissors</code> \u2014 on t\u00e4ysin sallittua k\u00e4ytt\u00e4\u00e4 muitakin luokkia, kuten <code>pehmolelu|kaukos\u00e4\u00e4din|k\u00e4nnykk\u00e4</code> tai <code>lasit|lippis|pipo</code>.</p> <p>Teht\u00e4v\u00e4: RPS ja Transfer Learning</p> <p>Aja <code>612_rps_transfer_learning.py</code> Marimo Notebook. Skriptiss\u00e4 k\u00e4ytet\u00e4\u00e4n edellisess\u00e4 teht\u00e4v\u00e4ss\u00e4 tallennettua datasetti\u00e4 ja koulutetaan GoogleNet Inception-v3 -mallia hy\u00f6dynt\u00e4en loppuun liitetty\u00e4 luokittelijaa. Malli on esikoulutettu ImageNet-datasetill\u00e4, joka sis\u00e4lt\u00e4\u00e4 1000 luokkaa, mutta sinulla on vain 3 luokkaa (tai mink\u00e4 verran niit\u00e4 p\u00e4\u00e4titk\u00e4\u00e4n tehd\u00e4).</p> <p>T\u00e4m\u00e4n koulutus kest\u00e4\u00e4 vain joitakin sekunteja, olettaen ett\u00e4 et kasaa valtavaa datasetti\u00e4.</p>"},{"location":"siirtovaikutus/transferlearning/#lahteet","title":"L\u00e4hteet","text":"<ol> <li> <p>Thorndike, E. L. &amp; Woodworth, R. S.. The influence of improvement in one mental function upon the efficiency of other functions. Psychological Review*,1901. https://doi.org/10.1037/h0074898\u00a0\u21a9</p> </li> <li> <p>UKK-instituutti. Siirtovaikutus. Terve koululainen. https://tervekoululainen.fi/ylakoulu/liikuntataidot/siirtovaikutus/\u00a0\u21a9</p> </li> <li> <p>Bozinovski, S. Reminder of the First Paper on Transfer Learning in Neural Networks, 1976. 2020. https://doi.org/10.31449/inf.v44i3.2828\u00a0\u21a9\u21a9</p> </li> <li> <p>Huyen, C. AI Engineering. O'reilly. 2024.\u00a0\u21a9\u21a9\u21a9</p> </li> <li> <p>Watson, M &amp; Chollet, F. Deep Learning with Python, Third Edition. Manning. 2025.\u00a0\u21a9</p> </li> <li> <p>Rosebrock, A. Deep Learning for Computer Vision with Python. Starter Bundle. 3rd Edition. PyImageSearch. 2019.\u00a0\u21a9</p> </li> </ol>"},{"location":"tensorit/pytorch/","title":"PyTorch","text":""},{"location":"tensorit/pytorch/#ai-sovelluskehysten-lyhyt-historia","title":"AI-sovelluskehysten lyhyt historia","text":"<p>Modernien syv\u00e4oppimiskehysten historia koostuu nopeasta innovaatiosta ja suurten teknologiayritysten sek\u00e4 avoimen l\u00e4hdekoodin yhteis\u00f6n kehittyvist\u00e4 suhteista.</p> <p></p> <p>Kuva 1: Syv\u00e4oppimiskehysten aikajana. Kuvaaja on koostettu alla olevan tekstin l\u00e4hteiden pohjalta ja Githubin release-historiasta. Toisiinsa liittyv\u00e4t kirjastot on yhdistetty v\u00e4reill\u00e4: esimerkiksi JAX on sininen, kuten my\u00f6s sen kirjastot Flax ja Rlax. Torch7 kattaa kaikki versiot alkuper\u00e4isest\u00e4 Torchista alkaen.</p>"},{"location":"tensorit/pytorch/#varhainen-perusta-2009-2014","title":"Varhainen perusta (2009-2014)","text":"<p>Matka alkaa Theanosta, joka kehitettiin noin vuonna 2009 \u2013 tai ehk\u00e4 olisi mainittava, ett\u00e4 Nvidian CUDA syntyi 2006. Ennen t\u00e4t\u00e4 neuroverkot kirjoitettiin k\u00e4sin esimerkiksi C++:lla. Fran\u00e7ois Chollet kuvailee Theanoa: \"the conceptual ancestor of all modern deep learning tools\". Theano oli ensimm\u00e4inen kehys, joka mahdollisti automaattisen differentioinnin ja GPU-laskennan syv\u00e4oppimismallien kouluttamiseen. Se sai merkitt\u00e4v\u00e4\u00e4 jalansijaa vuosina 2013\u20132014, kun ImageNet 2012 -kilpailu her\u00e4tti laajan kiinnostuksen syv\u00e4oppimiseen. <sup>1</sup></p> <p>N\u00e4ihin aikoihin my\u00f6s Lua-pohjainen Torch 7 ja C++-pohjainen Caffe olivat kovaa huutoa. Kyseist\u00e4 kirjastoa ei ole p\u00e4ivitetty sitten 2017, jolloin versio 1.0 julkaistiin <sup>1</sup>. Caffe:ta hy\u00f6dynsi esimerkiksi bat-country kirjastossa, joka on Deep Dream -tyylinen kuvageneraattori. Kirjastolla voi generoida unenomaisia kuvia tavallisten valokuvien pohjalta. Milt\u00e4 n\u00e4ytt\u00e4\u00e4 Pelkoa ja Inhoa Las Vegasissa\u2013elokuva, jos katsoja n\u00e4kee silmi\u00e4 ja kasvoja siell\u00e4kin, miss\u00e4 niit\u00e4 ei ole? K\u00e4y toki katsomassa repositoriosta esimerkkej\u00e4! Caffe2 julkaistiin Facebookin toimesta vuonna 2017, mutta se yhdistettiin my\u00f6hemmin PyTorchiin <sup>2</sup>. </p>"},{"location":"tensorit/pytorch/#keras-korkean-tason-pioneeri-2015","title":"Keras: Korkean tason pioneeri (2015)","text":"<p>Keras lanseerattiin maaliskuussa 2015 uudenlaisena l\u00e4hestymistapana syv\u00e4oppimiseen. Se oli Fran\u00e7ois Cholletin \u2013 eli l\u00e4hteiss\u00e4 olevan kirjan Deep Learning with Python (3rd ed.) toisen kirjoittajan \u2013 kehitt\u00e4m\u00e4. Kuten Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 3rd Edition -kirjassa kerrotaan, Chollet kehitti alkuper\u00e4isen Keras-kirjaston osana tutkimusprojektia, ja se \"quickly gained popularity, owing to its ease of use, flexibility, and beautiful design\". <sup>3</sup></p> <p>Alun perin Keras suunniteltiin korkean tason rajapinnaksi Theanon p\u00e4\u00e4lle, ja se oli suunnattu niille muutamalle tuhannelle ihmiselle, jotka tuolloin ty\u00f6skenteliv\u00e4t syv\u00e4oppimisen parissa. Filosofia oli yksinkertainen: tehd\u00e4 syv\u00e4oppimisesta saavutettavaa intuitiivisen ja k\u00e4ytt\u00e4j\u00e4yst\u00e4v\u00e4llisen API:n avulla. <sup>1</sup> Kerasin kilpailijaina toimi tuolloin Lasagne, joka oli my\u00f6s Theano-pohjainen korkean tason kirjasto <sup>4</sup>.</p>"},{"location":"tensorit/pytorch/#tensorflown-lapimurto","title":"TensorFlow:n l\u00e4pimurto","text":"<p>Googlen julkaisema TensorFlow, 2015, oli k\u00e4\u00e4nteentekev\u00e4 hetki, joka toi syv\u00e4oppimisen valtavirran kehitt\u00e4jien tietoisuuteen. Chollet ja Watson kuvailevat, ett\u00e4 julkaisu oli: \"watershed moment that precipitated deep learning in the mainstream developer zeitgeist\". TensorFlow otti keskeisi\u00e4 ideoita Theanosta ja lis\u00e4si kriittisen tuen laajamittaiselle hajautetulle laskennalle. Vuoden 2016 puoliv\u00e4liin menness\u00e4 puolet TensorFlow-k\u00e4ytt\u00e4jist\u00e4 k\u00e4yttiv\u00e4t sit\u00e4 nimenomaan Kerasin avulla. <sup>1</sup></p>"},{"location":"tensorit/pytorch/#pytorch-astuu-nayttamolle-2016","title":"PyTorch astuu n\u00e4ytt\u00e4m\u00f6lle (2016)","text":"<p>Meta (silloinen Facebook) julkaisi PyTorchin syyskuussa 2016 suorana vastauksena TensorFlow'n menestykselle <sup>5</sup>. PyTorch peri ohjelmointityylins\u00e4 Chainer-kehykselt\u00e4 ja torch-autogradilta. Jos PyTorchin suunnittelun tausta kiinnostaa, suosittelen tutustumaan PyTorch's design origins-kirjoitukseen. Sen on kirjoittanut Soumith Chintala, PyTorchin co-founder ja Torch 7:n p\u00e4\u00e4kehitt\u00e4j\u00e4.</p> <p>\"In contrast, PyTorch was designed from the ground up to provide a more flexible, Pythonic approach to building neural networks\". <sup>5</sup></p>"},{"location":"tensorit/pytorch/#suuri-integraatio-keras-osaksi-tensorflowta-2017-2019","title":"Suuri integraatio: Keras osaksi TensorFlow'ta (2017-2019)","text":"<p>Suuri muutos tapahtui, kun Google integroi Kerasin TensorFlow'n korkean tason rajapinnaksi. Keras valittiin virallisesti suositelluksi korkean tason rajapinnaksi, kun TensorFlow 2 julkaistiin. <sup>3</sup></p> <p>Ennen t\u00e4t\u00e4 Keras ja TF tulivat toki jo toimeen kesken\u00e4\u00e4n. Tensorflow 1.1.0 julkaisun my\u00f6t\u00e4 (elo 2018) Keras ladattiin <code>tf.keras</code>-moduulina, mutta se piti yh\u00e4 asentaa erikseen. Jo vuonna 2019 Adrian Rosebrock totesi blogissaan: \"As you can tell, the history between Keras and TensorFlow is long, complicated, and intertwined\". <sup>6</sup></p> <p>TensorFlow 2.0:n julkaisuun menness\u00e4 vuonna 2019 integraatio oli valmis. Aur\u00e9lien G\u00e9ron toteaa:</p> <p>\"Installing TensorFlow will automatically install Keras as well, and Keras will not work without TensorFlow installed. In short, Keras and TensorFlow fell in love and got married\". <sup>3</sup></p> <p>Alunperin Keras tuki useita taustaj\u00e4rjestelmi\u00e4 (PlaidML, Theano, Microsoft Cognitive Toolkit), mutta versiosta 2.4 alkaen vain TensorFlow oli tuettu. <sup>3</sup> T\u00e4ll\u00f6in, 2020, min\u00e4kin olin yh\u00e4 aktiivinen Kerasin ja Tensorflow:n k\u00e4ytt\u00e4j\u00e4. PyTorchin suosio oli kasvussa, mutta en l\u00f6yt\u00e4nyt aikaa kokeilla sit\u00e4.</p>"},{"location":"tensorit/pytorch/#keras-itsenaistyy-jalleen","title":"Keras itsen\u00e4istyy j\u00e4lleen","text":"<p>Viimeisin kehitys edustaa paluuta Kerasin monen taustaj\u00e4rjestelm\u00e4n juurille. Kuten Machine Learning \u2013 Modern Computer Vision &amp; Generative AI -kirjassa kuvataan:</p> <p>\"Keras will support multiple backends including TensorFlow, JAX, and PyTorch. This is much like the original iteration of Keras which supported the backends which were popular at the time\".</p> <p>T\u00e4m\u00e4 kehitys tarkoittaa, ett\u00e4 Keras on kulkenut t\u00e4yden ympyr\u00e4n \u2013 monen taustaj\u00e4rjestelm\u00e4n kirjastosta osaksi TensorFlow'ta ja nyt takaisin tukemaan useita kehyksi\u00e4, mukaan lukien PyTorch, JAX ja TensorFlow.</p>"},{"location":"tensorit/pytorch/#nykytilanne-2024-","title":"Nykytilanne (2024-)","text":"<p>Keras on itsen\u00e4inen ja vapaa, taas. Watson ja Chollet tiivist\u00e4v\u00e4t, ett\u00e4 Python on voittanut kielikilvan seuraavaksi 15 vuodeksi. V\u00e4hint\u00e4\u00e4n nykyiset nelj\u00e4 kehyst\u00e4 (ks. lainaus alta) tulevat pysym\u00e4\u00e4n relevantteina \u2013 joskin uusia voi l\u00f6yty\u00e4, kuten Applen MLX. <sup>1</sup></p> <p>\"Today, Keras, TensorFlow, PyTorch, and JAX are the top frameworks in the deep learning world.\" <sup>1</sup></p> <p>T\u00e4st\u00e4 nelikosta Keras on ainut, joka ei ole t\u00e4ysin itsen\u00e4inen kehys. Se on korkean tason rajapinta, joka k\u00e4ytt\u00e4\u00e4 taustaj\u00e4rjestelm\u00e4n\u00e4 TensorFlow'ta, PyTorchia tai JAX:ia. Sill\u00e4 voi siis kirjoittaa helppolukuista koodia, jossa on k\u00e4yt\u00f6ss\u00e4 esim. Layerit n\u00e4in: <code>dense = layers.Dense(64, activation=\"relu\")</code>, mutta taustalla voi olla mik\u00e4 tahansa tuettu kehys. N\u00e4it\u00e4 taustakehyksi\u00e4 yhdist\u00e4\u00e4 se, ett\u00e4 ne kaikki toteuttavat samankaltaisia matalamman tason toiminnallisuuksia, kuten tensoreita, automaattista differentiointia, GPU-kiihdytyst\u00e4 ja vastavirtausta (backpropagation).</p> <p>Voi hyvin olla, ett\u00e4 jos k\u00e4visit t\u00e4m\u00e4n kurssin vuoden p\u00e4\u00e4st\u00e4, me k\u00e4ytt\u00e4isimme Kerasia ja vuorottellisimme backendien suhteen. T\u00e4ll\u00e4 hetkell\u00e4 t\u00e4m\u00e4 kurssi on kuitenkin vahvasti PyTorch-painotteinen. Saat toki kurssin aikana kokeilla kirjoittaa jonkin teht\u00e4v\u00e4n Keras edell\u00e4. Kenties haluat my\u00f6s kokeilla, miten jokin alkup\u00e4\u00e4n low level -teht\u00e4v\u00e4 onnistuisi TensorFlow:n tai JAX:n avulla. Jos kysyt kielimallilta, se kyll\u00e4 k\u00e4\u00e4nt\u00e4\u00e4 (ainakin yksinkertaisen) koodin kehyksest\u00e4 toiseen. Miksi vuorottelisimme? Kuten Watson ja Chollet kirjoittavat <sup>1</sup>, PyTorch on kiva debugata ja sill\u00e4 on erityisesti Hugging Facen ajamana loistava ekosysteemi, mutta se h\u00e4vi\u00e4\u00e4 suorituskyvyss\u00e4 kilpailijoille. JAX on suorituskyvylt\u00e4\u00e4n erinomainen, mutta sen ekosysteemi on viel\u00e4 pieni. TensorFlow on suorituskyvylt\u00e4\u00e4n hyv\u00e4 ja sill\u00e4 on hyv\u00e4t tuotantoon soveltuvat ty\u00f6kalut. Keras tarjoaa helppok\u00e4ytt\u00f6isen API:n, mutta se ei ole itsen\u00e4inen kehys. Jokaisella on siis omat vahvuutensa ja heikkoutensa. Erikoistunut rauta, kuten TPU:t, saattavat my\u00f6s vaikuttaa valintaan.</p> <p></p> <p>Kuva 2: TensorFlow, PyTorch ja JAX:n GitHub-t\u00e4htien kehitys. Kuva kaapattu joulukuussa 2025. Jos haluat n\u00e4hd\u00e4 ajantasaisen version, k\u00e4y Star History Chart-sivulla.</p>"},{"location":"tensorit/pytorch/#tehtavat","title":"Teht\u00e4v\u00e4t","text":"<p>Muokkaa ja kokeile vapaasti!</p> <p>Ennen teht\u00e4vien alustamista haluan v\u00e4liss\u00e4 haluan huomauttaa, ett\u00e4 on t\u00e4ysin sallittua muokata olemassaolevia Notebookeja ja/tai luoda omia Marimo-kirjoja, joissa kokeilet PyTorchin toiminnallisuuksia.</p> <p>Ole rohkea! Kokeile, tutki ja muokkaa. Riko ja korjaa.</p> <p>Dokumentoi l\u00f6yd\u00f6ksesi oppimisp\u00e4iv\u00e4kirjaan.</p> <p>Teht\u00e4v\u00e4: From NumPy to PyTorch (PyTorchNN)</p> <p>Avaa <code>210_numpy_to_pytorch.py</code>-tiedosto ja tutustu <code>PyTorchNN</code>-malliin. Malli on sama 2-2-1 kun aiempi <code>NumpyNNwithBCE</code>-malli, mutta toteutettu PyTorchilla. </p> <p>Aja koodi ja tutki mit\u00e4 tapahtuu. Varmista, ett\u00e4 ymm\u00e4rr\u00e4t, kuinka mik\u00e4kin rivi koodia liittyy t\u00e4h\u00e4n menness\u00e4 kurssilla opittuun.</p> <p>Keskity erityisesti PyTorch-kirjaston tensori- ja mallitoiminnallisuuksiin, joita Marimo-notebookissa k\u00e4ytet\u00e4\u00e4n.</p> <p>Teht\u00e4v\u00e4: PyTorch Learn the Basics: Tensors</p> <p>Avaa <code>211_pytorch_tensors.py</code>. Huomaa, ett\u00e4 kyseess\u00e4 on PyTorchin virallinen Learn The Basics: Tensors -opas, joka on k\u00e4\u00e4nnetty Marimo-muotoon. </p> <p>Jos k\u00e4yt\u00e4t Google Colabia, voit avata alkuper\u00e4isen ohjeen.</p> <p>Teht\u00e4v\u00e4: PyTorch Introduction to Pytorch Tensors</p> <p>Avaa <code>212_tensors.py</code>. Huomaa, ett\u00e4 kyseess\u00e4 on PyTorchin virallinen Introduction to PyTorch - YouTube Series: Introduction to PyTorch Tensors -opas, joka on k\u00e4\u00e4nnetty Marimo-muotoon.</p> <p>My\u00f6s t\u00e4ss\u00e4 voit k\u00e4ytt\u00e4\u00e4 Google Colabia alkuper\u00e4isen ohjeen avaamiseen tai noudattaa kurssin Marimo-versiota.</p> <p>Teht\u00e4v\u00e4: Auto MPG</p> <p>Avaa <code>213_auto_mpg.py</code>. Notebookissa on matalan kynnyksen k\u00e4ytt\u00f6\u00f6notto PyTorch-mallille. Data on loppumetreille asti aiemmin tutussa Pandas DataFramessa. Seuraavilla viikoilla tutustumme paremmin esimerkiksi Dataset ja DataLoader -toiminnallisuuksiin. Keskityt\u00e4\u00e4n toistaiseksi mallin kouluttamiseen ja tulosten validointiin yksinkertaisella MAE-metriikalla.</p> <p>Teht\u00e4v\u00e4: Kyberviha PyTorch-mallilla</p> <p>Johdatus Koneoppimiseen -kurssin logistisen regression teht\u00e4v\u00e4n\u00e4 oli tunnistaa, onko henkil\u00f6 kokenut kybervihaa viimeisen vuoden aikana.</p> <p>Alkuper\u00e4inen datasetti l\u00f6ytyy Data in Brief Digital skills among youth: A dataset from a three-wave longitudinal survey in six European countries-data-artikkelista. K\u00e4yt\u00e4mme kuitenkin vertailun vuoksi edelliselt\u00e4 kurssilta tuttua, esik\u00e4sitelty\u00e4 datasetti\u00e4. Se on ladattavissa hf:sourander/yskills-reposta.</p> <p>Muistanet, ett\u00e4 tulos oli kohtalaisen heikko. T\u00e4m\u00e4n harjoituksen motiviina on tutkia, ovatko neuroverkot hopealuoti, joka parantaa tuloksia merkitt\u00e4v\u00e4sti \u2013 vai k\u00e4yk\u00f6 kenties niin, ett\u00e4 joudut taistella hyperparametrien kanssa saadaksesi edes jossain m\u00e4\u00e4rin vertailukelpoisen tuloksen.</p> <p>Teht\u00e4v\u00e4\u00e4n l\u00f6ytyy <code>214_cyberhate.py</code> -notebook, jota voit k\u00e4ytt\u00e4\u00e4 pohjana. Vaihtoehtoisesti voit kirjoittaa koodin alusta asti itse. T\u00e4rkeint\u00e4 on, ett\u00e4 dokumentoit oppimisp\u00e4iv\u00e4kirjaasi, mit\u00e4 teit ja mit\u00e4 opit.</p> <p>Warning</p> <p>\u00c4l\u00e4 sukella liian syv\u00e4lle hyperparametrien viritt\u00e4miseen. T\u00e4ss\u00e4 voisi k\u00e4ytt\u00e4\u00e4 uskomattoman m\u00e4\u00e4r\u00e4n aikaa. Jos vibe-koodaat ratkaisua, joka alkaa sis\u00e4lt\u00e4\u00e4 termej\u00e4 kuten Dropout, Early Stopping, Optuna, kannattaa huomioida, ett\u00e4 n\u00e4m\u00e4 tulevat tutuksi kurssin Mallinnus-osiossa my\u00f6hemmin.</p> <p>Teht\u00e4v\u00e4: ONNX JAX:ia n\u00e4kynyt?</p> <p>Yll\u00e4 olevasta historiasta puuttuu ONNX tyystin ja Jax on vain sivuhuomio. Tutustu Jaxiin ja ONNX:\u00e4\u00e4n itsen\u00e4isesti ja kirjoita lyhyt yhteenveto oppimisp\u00e4iv\u00e4kirjaasi. ONNX:iin tutustutaan kenties tarkemmin my\u00f6hemmin kurssilla \u2013 ehk\u00e4p\u00e4 vaikka Syv\u00e4oppiminen II:ssa.</p> <p>On \u00e4\u00e4rimm\u00e4isen suositeltavaa lis\u00e4ksi k\u00e4ytt\u00e4\u00e4 Google Trendsi\u00e4 ja vertailla, miten Worldwide-tasolla kehykset PyTorch, TensorFlow, Keras ja JAX ovat kehittyneet viimeisen viiden vuoden aikana. Huomaa, ett\u00e4 t\u00e4ss\u00e4 on kuitenkin kyse vain hakuhistoriasta. Se ei v\u00e4ltt\u00e4m\u00e4tt\u00e4 suoraan heijasta todellista k\u00e4ytt\u00f6\u00e4 tuotantoymp\u00e4rist\u00f6iss\u00e4 tai tutkimuksessa.</p> <p>\ud83d\udcaa Jos oikein rohkea olet, ota JAX lyhyelle Hello World -tason koeajolle.</p>"},{"location":"tensorit/pytorch/#lahteet","title":"L\u00e4hteet","text":"<ol> <li> <p>Watson, M &amp; Chollet, F. Deep Learning with Python, Third Edition. Manning. 2025.\u00a0\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9</p> </li> <li> <p>TensorGym. The Complete History and Evolution of PyTorch | Deep Learning Framework Timeline. n.d. https://tensorgym.com/blog/pytorch-history\u00a0\u21a9</p> </li> <li> <p>G\u00e9ron, A. Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 3rd Edition. O'Reilly. 2022.\u00a0\u21a9\u21a9\u21a9\u21a9</p> </li> <li> <p>Stevens, E, Antiga, L &amp; Viehmann, T. Deep Learning with PyTorch. Manning. 2020.\u00a0\u21a9</p> </li> <li> <p>G\u00e9ron, A. Hands-On Machine Learning with Scikit-Learn and PyTorch. O'Reilly. 2025.\u00a0\u21a9\u21a9</p> </li> <li> <p>Rosebrock, J. Keras vs. tf.keras: What\u2019s the difference in TensorFlow 2.0? PyImageSearch Blog. https://pyimagesearch.com/2019/10/21/keras-vs-tf-keras-whats-the-difference-in-tensorflow-2-0/\u00a0\u21a9</p> </li> </ol>"},{"location":"tensorit/vektorointi/","title":"Vektorointi","text":"<p>Ennen kuin hypp\u00e4\u00e4mme PyTochin k\u00e4ytt\u00f6\u00f6n, varmistetaan viel\u00e4, ett\u00e4 ymm\u00e4rr\u00e4mme, miksi vektorointi on t\u00e4rke\u00e4\u00e4 syv\u00e4oppimisessa. Neuroverkkojen opetus vaatii valtavia m\u00e4\u00e4ri\u00e4 laskentatehoa. T\u00e4ten ei ole aivan sama, kuinka data esitet\u00e4\u00e4n ja kuinka laskenta toteutetaan. Ennen kuin nyrpist\u00e4t nen\u00e4\u00e4si, ett\u00e4 miksi syv\u00e4oppimiskurssilla on k\u00e4yt\u00f6ss\u00e4 Numpy, niin mainittaakoon heti alkuun: PyTorchin Tensor on hyvinkin samankaltainen kuin Numpyn ndarray. Jotta osaamme my\u00f6hemmin arvostaa PyTorchin Tensoreita, kurkataan pintapuolisesti, kuinka neuroverkkoja voisi toteuttaa Numpyll\u00e4. Itse asiassa aivan ensimm\u00e4isen\u00e4 unohdetaan jopa Numpy ja kurkataan Python-only -toteutusta. T\u00e4m\u00e4 heti lyhyen osuuden j\u00e4lkeen, jossa selitet\u00e4\u00e4n mik\u00e4 on Tensor.</p> <p>Tip</p> <p>Termi vektorointi viittaa historiallisesti 70\u201390-lukujen vektoriprosessoreihin, jotka olivat sen ajan supertietokoneiden arkkitehtuurin perusta.</p>"},{"location":"tensorit/vektorointi/#mika-on-tensor","title":"Mik\u00e4 on Tensor?","text":"<p>Tensor on yleistetty k\u00e4site vektoreista, matriiseista ja yh\u00e4 moniulotteisemmista rakenteista. Kun k\u00e4yt\u00e4t koneoppimisviitekehyksi\u00e4 kuten PyTorch tai TensorFlow, k\u00e4yt\u00e4t tensoreita. Tensorilla on jokin aste (engl. rank), joka kuvaa sen ulottuvuuksien m\u00e4\u00e4r\u00e4\u00e4. Elimerkiksi 2-ulotteisen v\u00e4rikuvan aste on 3, joten se on 3D-tensor muotoa <code>(height, width, channels)</code> (riippuen viitekehyksest\u00e4). L\u00e4hes kaikki, mit\u00e4 k\u00e4sittelet PyTorchissa, on N-ulotteisia Tensor-olioita: sy\u00f6tedata, mallin painot, biasit ja v\u00e4litulokset. Vektoroinnin yksi idea on se, ett\u00e4 data k\u00e4sittell\u00e4\u00e4n <code>n_samples</code> kerrallaan, jolloin data on muotoa <code>(n_samples, *data_dims)</code>.</p> <p></p> <p>Kuva 1: Eri mallisia tensoreita. Skaalarilla ei ole ulottuvuuksia, vektorilla on yksi, matriisilla kaksi ja korkeamman asteen tensoreilla kolme tai enemm\u00e4n ulottuvuuksia.</p> <p>Alla yleisi\u00e4 Tensoreista muodostettuja datasettej\u00e4 jaoteltuna sen mukaan, mit\u00e4 reaalimaailman dataa se kuvastaa. Luettelo on pohjimmiltaan kirjasta  Deep Learning with Python, Third Edition <sup>1</sup>:</p> <ul> <li>Vektori: <ul> <li>muotoa: <code>(samples, features)</code></li> <li>esimerkiksi 5 tietoa 100 ihmisest\u00e4: <code>(100, 5)</code> </li> <li>tyypillinen tabulaarimuotoinen data, jossa kukin rivi on n\u00e4yte ja kukin sarake ominaisuus.</li> </ul> </li> <li>Aikasarja tai muu sekvenssi: <ul> <li>muotoa <code>(samples, timesteps, features)</code>, tai</li> <li>muotoa <code>(samples, sequence_length, features)</code></li> <li>kukin n\u00e4yte on sekvenssi, jossa on useita aikapisteit\u00e4 ja jokaisessa aikapisteess\u00e4 useita ominaisuuksia.</li> </ul> </li> <li>Kuvat:<ul> <li>muotoa <code>(samples, c, h, w)</code> (PyTorch) tai,</li> <li>muotoa <code>(samples, h, w, c)</code> (esim. TensorFlow, Matplotlib, OpenCV).</li> <li>kukin n\u00e4yte on kuva, jossa on korkeus, leveys ja v\u00e4rikanavat (esim. RGB).</li> </ul> </li> <li>Videot: <ul> <li>muotoa: <code>(samples, frames, c, h, w)</code> (PyTorch), tai</li> <li>muotoa: <code>(samples, frames, h, w, c)</code> (esim. TensorFlow).</li> <li>esim. 60 sekunnin klippi\u00e4 Full HD -elokuvasta (24p):<ul> <li><code>(60, 24, 3, 1080, 1920)</code> </li> </ul> </li> </ul> </li> </ul> <p>Neuroverkon painot yksitt\u00e4isess\u00e4 kerroksessa, <code>W</code>, ovat Rank-2 Tensor muotoa <code>(output_features, input_features)</code>, ja biasit, <code>b</code>, ovat Rank-1 Tensor muotoa <code>(output_features)</code>. N\u00e4m\u00e4kin ovat k\u00e4yt\u00e4nn\u00f6n forward-passissa jaettu eriin (engl. batches), jolloin painot ja biasit laajennetaan muotoon <code>(batch_size, output_features, input_features)</code> ja <code>(batch_size, output_features)</code>.</p>"},{"location":"tensorit/vektorointi/#nn-ilman-vektorointia","title":"NN ilman vektorointia","text":""},{"location":"tensorit/vektorointi/#verkon-rakenne","title":"Verkon rakenne","text":"<p>K\u00e4yt\u00e4mme t\u00e4m\u00e4n luvun esimerkkin\u00e4 verkkoa, joka tunnetaan nimell\u00e4 <code>NumpyNNwithBCE</code>. L\u00f6yd\u00e4t sen tiedostosta <code>200_numpy_nn.ipynb</code>. Verkko on juuri sen verran pelkk\u00e4\u00e4 Perceptronia monimutkaisempi, ett\u00e4 se kykenee yhden piilotetun kerroksen ansiosta ratkaisemaan XOR-ongelman. Selvyyden vuoksi verkon arkkitehtuuri on esitetty alla olevassa kuvassa</p> <p></p> <p>Kuva 2: Kuvassa on 2-2-1 arkkitehtuuria edustava verkko, <code>NumpyNNwithBCE</code>, jota k\u00e4yt\u00e4mme t\u00e4m\u00e4n luvun aikana esimerkkin\u00e4. Toteutuksesta l\u00f6ytyy Jupyter Notebook, jossa verkko on toteuttuna NumPy:lla.</p>"},{"location":"tensorit/vektorointi/#toteutus-ilman-vektorointia","title":"Toteutus ilman vektorointia","text":"<p>Tutustumme ensin siihen, milt\u00e4 malli n\u00e4ytt\u00e4isi, jos emme k\u00e4ytt\u00e4isi Numpy-kirjaston mahdollistamaa vektori- tai matriisilaskentaa. T\u00e4t\u00e4 mallia ei l\u00f6ydy mist\u00e4\u00e4n kokonaisuuteena, mutta saat toki koodata sen itse jos haluat. Olkoon sen nimi: <code>PythonNN</code>. Tutustu alla olevassa kuvassa esitettyyn koodiin. Koodi on v\u00e4rikoodattu siten, ett\u00e4 v\u00e4rit t\u00e4sm\u00e4\u00e4v\u00e4t Kuvan 1 painojen v\u00e4reihin.</p> <p></p> <p>Kuva 3: Kuvassa on <code>PythonNN</code>-verkon <code>__init__</code>- ja <code>forward</code>-metodit ilman vektorointia. Koodissa on paljon rautakoodattua toistoa. Huomaa, ett\u00e4 t\u00e4t\u00e4 mallia ei ole meid\u00e4n kurssillamme toteutettuna miss\u00e4\u00e4n Notebookissa. Kaikki sinun ajamasi koodi sis\u00e4lt\u00e4\u00e4 jossain m\u00e4\u00e4rin vektoroidun toteutuksen. Huomaa, ett\u00e4 NumPyll\u00e4 initialisoidut parametrit ovat liukulukuja, jotka voisi yht\u00e4 hyvin generoida Pythonin random-kirjastolla.</p> <p>Esimerkki on tarkoituksella j\u00e4tetty t\u00e4ysin rautakoodatuksi. Ongelmaa voisi koodin yll\u00e4pidett\u00e4vyyden ja uudelleenk\u00e4ytett\u00e4vyyden kannalta parantaa k\u00e4ytt\u00e4m\u00e4ll\u00e4 silmukoita ja listoja. Koodista tulisi rakenteeltaan dynaamisempaa, mutta se suoritettaisiin yh\u00e4 yksi kerta per sy\u00f6te, yksi paino kerrallaan - eli siis sekventiaalisesti.</p>"},{"location":"tensorit/vektorointi/#silmukka-toisen-peraan","title":"Silmukka toisen per\u00e4\u00e4n","text":"<p>Jos k\u00e4yt\u00f6ss\u00e4 ei ole mink\u00e4\u00e4n sortin vektorointia, koodia loopataan n\u00e4in:</p> <pre><code>EPOCHS = 10_000\ndataset = [(1, 0), (0, 1), (1, 1), (0, 0)]  # XOR dataset\nmodel = PythonNN()\n\nfor epoch in range(EPOCHS):\n    for x1, x2 in dataset:\n        model.forward(x1, x2)\n        model.backward(x1, x2)\n        model.update_weights(lr=0.1)\n</code></pre>"},{"location":"tensorit/vektorointi/#numpy-to-the-rescue","title":"Numpy to the rescue","text":"<p>K\u00e4yt\u00e4nteet</p> <p>Lineaarialgebran teoriassa k\u00e4ytet\u00e4\u00e4n yleens\u00e4 sarakevektoreita \\((n, 1)\\), jolloin operaatio on \\(y = Wx + b\\). Ohjelmistokehykset (PyTorch, NumPy) k\u00e4sittelev\u00e4t dataa kuitenkin rivein\u00e4 (yleens\u00e4 muodossa \\((batch\\_size, n)\\)).</p> <p>T\u00e4st\u00e4 syyst\u00e4 koodissa operaatio toteutetaan muodossa: \\(y = xW^\\intercal + b\\)</p> <p>T\u00e4m\u00e4 transpoosi sallii painomatriisin \\(W\\) kertomisen tehokkaasti kokonaisella databatchilla, jossa kukin n\u00e4yte on omana rivin\u00e4\u00e4n.</p> <p>Huomaa, ett\u00e4 Numpy-vektorointi tiivist\u00e4\u00e4 saman koodin hyvinkin lyhyeksi. Jos j\u00e4tet\u00e4\u00e4n pari yksityiskohtaa pois, <code>forward()</code>-metodin koodi n\u00e4ytt\u00e4\u00e4 t\u00e4lt\u00e4:</p> <pre><code>def forward(self, x):\n\n    # Layer 1 (hidden layer)\n    Z1 = self.A0.dot(self.W1.T) + self.b1\n    self.A1 = self.sigmoid(Z1)\n\n    # Layer 2 (output layer)\n    Z2 = self.A1.dot(self.W2.T) + self.b2\n    self.A2 = self.sigmoid(Z2)\n    return self.A2\n</code></pre> <p>Numpy ei kuitenkaan pelk\u00e4st\u00e4\u00e4n typist\u00e4 syntaksia lyhyemm\u00e4ksi. Se my\u00f6s suorittaa laskennan paljon tehokkaammin. T\u00e4m\u00e4 johtuu siit\u00e4, ett\u00e4 Numpy on ohjelmoitu C-kielell\u00e4, mik\u00e4 mahdollistaa C array-rakenteen k\u00e4yt\u00f6n ep\u00e4tehokkaan Python listan sijasta <sup>2</sup>. Lis\u00e4ksi Numpy hy\u00f6dynt\u00e4\u00e4 SIMD (Single Instruction, Multiple Data) -laskentaa, joka mahdollistaa useiden arvojen k\u00e4sittelyn yhdell\u00e4 k\u00e4skyll\u00e4 <sup>3</sup>. Eli siis yksitt\u00e4inen k\u00e4sky (single instruction) voidaan suorittaa yht\u00e4aikaisesti rinnakkaisesti usealle datalle (multiple data).</p> <p>My\u00f6hemmin kurssilla k\u00e4ytett\u00e4v\u00e4t TensorFlow ja PyTorch viev\u00e4t t\u00e4m\u00e4n viel\u00e4 askeleen pidemm\u00e4lle hy\u00f6dynt\u00e4m\u00e4ll\u00e4 GPU:ita, jotka on suunniteltu erityisesti rinnakkaislaskentaan. Esimerkiksi CUDA on SIMT (Single Instruction, Multiple Threads) -arkkitehtuuri, joka mahdollistaa tuhansien s\u00e4ikeiden samanaikaisen suorittamisen. Jos k\u00e4sitteet SISD, MDSI, SIMD ja MIMD eiv\u00e4t ole entuudestaan tuttuja, kannattaa pikaisesti tutustus Flynnin luokittelu-Wiki-artikkeliin. SIMT on lis\u00e4ys t\u00e4h\u00e4n luokitteluun.</p> <p>Neuroverkkojen kanssa s\u00e4\u00e4st\u00f6 on suuri, koska verkon koulutuksessa tehd\u00e4\u00e4n useita kertoja \\(W \\cdot X + b\\) -tyyppisi\u00e4 laskuja. N\u00e4m\u00e4 ovat juuri niit\u00e4 laskuja, jotka hy\u00f6tyv\u00e4t vektoroinnista ja rinnakkaislaskennasta. Pelk\u00e4ss\u00e4 <code>forward()</code>-metodissa on yksi t\u00e4llainen operaatio per kerros. Ilman SIMD-laskentaa t\u00e4m\u00e4 pistetulo suoritettaisiin yksi parametri kerrallaan. Kuinka monta kertaa siis? T\u00e4ss\u00e4 meid\u00e4n 2-2-1 verkossamme koulutettavia parametreja on yhteens\u00e4 9 (6 painoa ja 3 biasia). Muistellaan vertailun vuoksi meid\u00e4n aiempaa MNIST-malliamme, jossa oli 784 sy\u00f6tett\u00e4, kahdessa piilotetussa kerroksessa 256 ja 128 piilotettua solmua ja 10 ulostuloa. Yhteens\u00e4 parametreja on:</p> Layer item Shape Count fc1.weight (256, 784) 200,704 fc1.bias (256,) 256 fc2.weight (128, 256) 32,768 fc2.bias (128,) 128 fc3.weight (10, 128) 1,280 fc3.bias (10,) 10 Total 235,146"},{"location":"tensorit/vektorointi/#lyhyet-opit","title":"Lyhyet opit","text":"<p>\u00c4l\u00e4 koskaan sekoita <code>for</code>-silmukoita ja Python-natiiveja ei-vektoroituja funktioita hajautetun tai vektoroidun koodin kanssa sekaisin. Pythonin <code>for</code>-silmukkaa voi k\u00e4ytt\u00e4\u00e4 ajurina (engl. driver), kuten vaikkapa epookkien tai erien (engl. batch) l\u00e4pik\u00e4ymiseen, mutta \u00e4l\u00e4 koskaan k\u00e4yt\u00e4 sit\u00e4 datan l\u00e4pik\u00e4ymiseen. K\u00e4yt\u00e4 sen sijaan vektoroituja funktioita ja operaatioita.</p> <p>Seuraavassa osassa t\u00e4t\u00e4 kurssia opit PyTorchin ja siihen liittyvien aputy\u00f6kalujen kuten Datasetin ja Dataloaderin k\u00e4yt\u00f6n. N\u00e4m\u00e4 ovat tehokkaita ty\u00f6kaluja: k\u00e4yt\u00e4 niit\u00e4 hyv\u00e4ksesi.</p>"},{"location":"tensorit/vektorointi/#tehtavat","title":"Teht\u00e4v\u00e4t","text":"<p>Teht\u00e4v\u00e4: Tutustu vektorointiin</p> <p>Katso Vectorization in PYTHON by Prof. Andrew NG -video. Videolla AI-kontekstissa hyvinkin tunnettu tekij\u00e4 selitt\u00e4\u00e4 vektoroinnin perusteet ja havainnollistaa, miten vektorointi nopeuttaa laskentaa. Kaikki 8 minuutissa.</p> <p>Jos aihe j\u00e4i yht\u00e4\u00e4n ep\u00e4selv\u00e4ksi, katso my\u00f6s toinen 8-minuuttinen video samalta tekij\u00e4lt\u00e4: Explanation For Vectorized Implementation (C1W3L05).</p> <p>Teht\u00e4v\u00e4: NumPy Neural Network (NumpyNNwithBCE)</p> <p>Avaa <code>200_numpy_nn.py</code>-tiedosto ja tutustu <code>NumpyNNwithBCE</code>-malliin. Kyseess\u00e4 on neuroverkko, joka on toteutettu NumPy-kirjastolla (eli ilman PyTorchia). Aja koodi ja tutki mit\u00e4 tapahtuu. Varmista, ett\u00e4 ymm\u00e4rr\u00e4t, kuinka mik\u00e4kin rivi koodia liittyy t\u00e4h\u00e4n menness\u00e4 kurssilla opittuun.</p> <p>P.S. Voit j\u00e4tt\u00e4\u00e4 <code>backward()</code>-metodin pienemm\u00e4lle huomiolle. Tutustumme my\u00f6hemm\u00e4ll\u00e4 luennolla vastavirta-algoritmiin (engl. backpropagation), joka on <code>backward()</code>-metodin ydin.</p>"},{"location":"tensorit/vektorointi/#lahteet","title":"L\u00e4hteet","text":"<ol> <li> <p>Watson, M &amp; Chollet, F. Deep Learning with Python, Third Edition. Manning. 2025.\u00a0\u21a9</p> </li> <li> <p>VanderPlas, J. Why is Python slow? https://jakevdp.github.io/blog/2014/05/09/why-python-is-slow/\u00a0\u21a9</p> </li> <li> <p>Numpy. Why is NumPy fast? https://numpy.org/doc/stable/user/whatisnumpy.html#why-is-numpy-fast\u00a0\u21a9</p> </li> </ol>"},{"location":"vastavirta/backpropagation/","title":"Vastavirta (Backprop)","text":""},{"location":"vastavirta/backpropagation/#motivaatio","title":"Motivaatio","text":"<p>T\u00e4m\u00e4 on kenties kurssin teoreettisin osuus, mutta sis\u00e4lt\u00e4\u00e4 yleistietoa, joka on k\u00e4yt\u00e4nn\u00f6ss\u00e4 pakko olla hallussa. Vertaa mieless\u00e4si n\u00e4it\u00e4 kahta keskustelua:</p> <p>\"Mit\u00e4 osaat kertoa bin\u00e4\u00e4rij\u00e4rjestelm\u00e4st\u00e4?\"  \u2014 \"\u00d6\u00f6\u00f6h, taisin k\u00e4ytt\u00e4\u00e4 sit\u00e4 yhdess\u00e4 projektissa, vissiin.\"</p> <p>\"Mit\u00e4 osaat kertoa algoritmista nimelt\u00e4\u00e4n backpropagation?\"  \u2014 \"\u00d6\u00f6\u00f6h, taisin k\u00e4ytt\u00e4\u00e4 sit\u00e4 yhdess\u00e4 projektissa, vissiin.\"</p> <p>Vastavirta-algoritmi (engl. backpropagation) on keskeinen menetelm\u00e4 neuroverkkojen kouluttamisessa. Se mahdollistaa virheen tehokkaan laskemisen ja painojen p\u00e4ivitt\u00e4misen verkon eri kerroksissa. Heti alkuun t\u00e4ytyy sanoa, ett\u00e4 backpropagation ei ole sama asia kuin gradient descent, vaikka n\u00e4m\u00e4 kaksi usein mainitaankin yhdess\u00e4. Backpropagation on menetelm\u00e4, jolla lasketaan virheiden gradientit verkon painoille, kun taas gradient descent on optimointialgoritmi, joka k\u00e4ytt\u00e4\u00e4 n\u00e4it\u00e4 gradientteja painojen p\u00e4ivitt\u00e4miseen. Optimointialgoritmeja on muitakin, kuten esimerkiksi Adam ja RMSprop.</p> <p>Tip</p> <p>Jos et osaa yhdist\u00e4\u00e4 termi\u00e4 <code>optimizer</code> tai <code>Adam</code> mihink\u00e4\u00e4n aiemmin n\u00e4kem\u00e4\u00e4si, avaa jokin aiempien viikkojen marimo Notebook. Yksi monista esimerkeist\u00e4 on Notebook, jossa koulutettiin Auto MPG -ennustin. Etsi rivej\u00e4, jotka n\u00e4ytt\u00e4v\u00e4t t\u00e4lt\u00e4:</p> <pre><code>optimizer = xxxxx.xxxxx.Adam(xxxxxxxxxx, xx=xxx)\n</code></pre> <p>Huomaa kuitenkin, ett\u00e4 optimointialgoritmit eiv\u00e4t ole t\u00e4m\u00e4n viikon aihe. Niihin tutustutaan hieman ensi viikolla. T\u00e4ll\u00e4 viikolla oletetaan, ett\u00e4 meill\u00e4 on jokin optimointialgoritmi, joka tarvitsee gradientit painojen p\u00e4ivitt\u00e4miseen.</p> <p>Loppupeleiss\u00e4 backpropagation on vain ketjus\u00e4\u00e4nn\u00f6n soveltamista laskentaverkkoon. Er\u00e4s Anthropicin perustajista, Christopher Olah, pohtii blogissaan seuraavasti:</p> <p>\"When I first understood what backpropagation was, my reaction was: \u201cOh, that\u2019s just the chain rule! How did it take us so long to figure out?\u201d I\u2019m not the only one who\u2019s had that reaction.\" <sup>1</sup></p> <p>\u2014 Christopher Olah</p> <p>Ja n\u00e4inh\u00e4n se j\u00e4lkiviisaana on. Olah nostaa kuitenkin esiin, ett\u00e4 asia ei ollut lainkaan niin ilmeinen silloin, kun vastavirta-algoritmi (backpropagation) alun perin keksittiin. Tuohon aikaan ei ollut selv\u00e4\u00e4, ett\u00e4 juuri derivaattojen laskeminen olisi oikea tapa opettaa neuroverkkoja. T\u00e4m\u00e4kin ajatus tulee luontevaksi vasta sitten, kun ymm\u00e4rt\u00e4\u00e4, ett\u00e4 derivaatat voidaan laskea tehokkaasti. Syntyy er\u00e4\u00e4nlainen keh\u00e4p\u00e4\u00e4telm\u00e4: jotta ymm\u00e4rt\u00e4isimme, miksi derivaatat ovat hy\u00f6dyllisi\u00e4, meid\u00e4n t\u00e4ytyy jo tiet\u00e4\u00e4, ett\u00e4 niiden laskeminen on mahdollista ja tehokasta. <sup>1</sup></p> <p>Lis\u00e4ksi Olah huomauttaa, ett\u00e4 olisi ollut helppoa tyrm\u00e4t\u00e4 koko l\u00e4hestymistapa nopealla j\u00e4rkeilyll\u00e4. Ajatus neuroverkkojen opettamisesta gradienttipohjaisilla menetelmill\u00e4 saattoi vaikuttaa tuomittuna ep\u00e4onnistumaan: eik\u00f6 optimointi j\u00e4isi jumiin lokaaleihin minimeihin? <sup>1</sup> </p>"},{"location":"vastavirta/backpropagation/#kertaus-mika-on-gradientti","title":"Kertaus: Mik\u00e4 on gradientti?","text":"<p>T\u00e4t\u00e4 aihetta on k\u00e4sitelty Johdatus koneoppimiseen -kurssissa Hill Climbing ja Gradient Descent -osioissa. Jos et muista aiheesta mit\u00e4\u00e4n, on \u00e4\u00e4rimm\u00e4isen suositeltavaa kurkata omaa oppimisp\u00e4iv\u00e4kirjaasi ja kerrata lyhyesti. Tarkasti ottaen meid\u00e4n tulee selvitt\u00e4\u00e4 kaksi termi\u00e4: </p> <ul> <li>osittaisderivaatta (engl. partial derivative)</li> <li>gradientti (engl. gradient)</li> </ul>"},{"location":"vastavirta/backpropagation/#osittaisderivaatta","title":"Osittaisderivaatta","text":"<p>Osittaisderivaatta on yksitt\u00e4isen muuttujan vaikutus funktion lopputulokseen. Kun lasket osittaisderivaatan, pid\u00e4t muut muuttujat vakioina ja tarkastelet vain yhden muuttujan vaikutusta <sup>2</sup>. Esimerkiksi, jos meill\u00e4 on funktio \\(f(x, y) = x^2 + 3y^2\\), osittaisderivaatat \\(x\\) ja \\(y\\) suhteen ovat:</p> \\[ \\frac{\\partial f}{\\partial x} = 2x \\] \\[ \\frac{\\partial f}{\\partial y} = 6y \\] <p>Eli, jos \\(x\\):\u00e4\u00e4 kasvatetaan yhdell\u00e4 yksik\u00f6ll\u00e4, \\(f\\):n arvo kasvaa kahden yksik\u00f6n verran, kun taas \\(y\\):n kasvattaminen yhdell\u00e4 yksik\u00f6ll\u00e4 kasvattaa \\(f\\):n arvoa kuudella yksik\u00f6ll\u00e4.</p>"},{"location":"vastavirta/backpropagation/#gradientti","title":"Gradientti","text":"<p>Gradientti on hyvin yksinkertainen k\u00e4site: se on kokoelma kaikista osittaisderivaattoista. Toisin sanoen, gradientti kertoo, kuinka paljon funktion arvo muuttuu, kun kukin muuttuja muuttuu hieman <sup>2</sup>. Edellisen esimerkin funktiolle \\(f(x, y) = x^2 + 3y^2\\), gradientti on:</p> \\[ \\nabla f = \\left( \\frac{\\partial f}{\\partial x}, \\frac {\\partial f}{\\partial y} \\right) = (2x, 6y) \\] <p>K\u00e4yt\u00e4nn\u00f6ss\u00e4 gradientti voi olla siis muotoa:</p> <pre><code># Gradient of Loss w.r.t. W\ngrad_W = torch.tensor(\n#   [[   w00,    w01,   w02 ],\n#    [   w10,    w11,   w12 ]]\n    [[0.0980, 0.1960, 0.2940],\n     [0.1078, 0.2156, 0.3234]]\n)\n</code></pre> <p>T\u00e4ss\u00e4 esimerkiss\u00e4 gradientti on 2x3-matriisi, jossa jokainen alkio edustaa osittaisderivaattaa vastaavalle painolle neuroverkossa. Selvyyden vuoksi n\u00e4ytet\u00e4\u00e4n t\u00e4m\u00e4 <code>3-2-?-...-?</code> arkkitehtuuri Mermaid-kaaviona:</p> <pre><code>graph LR\n    subgraph Input Layer\n        x1((x1))\n        x2((x2))\n        x3((x3))\n    end\n    subgraph Hidden Layer\n        h1((h1))\n        h2((h2))\n    end\n    rest[... rest of the network]\n    x1 --&gt;|w00| h1\n    x2 --&gt;|w01| h1\n    x3 --&gt;|w02| h1\n    x1 --&gt;|w10| h2\n    x2 --&gt;|w11| h2\n    x3 --&gt;|w12| h2\n    h1 --&gt; rest\n    h2 --&gt; rest</code></pre>"},{"location":"vastavirta/backpropagation/#backpropagation","title":"Backpropagation","text":""},{"location":"vastavirta/backpropagation/#paperilla","title":"Paperilla","text":"<p>Johdatus koneoppimiseen -kurssilla gradientin laskeminen oli kovin helppoa, koska logistinen regressio on yksinkertainen lineaarinen malli (jolla on logistinen funktio per\u00e4ss\u00e4). Neuroverkoissa meill\u00e4 on monta funktiota. Jos pelk\u00e4st\u00e4\u00e4n yll\u00e4 olevan Mermaid-kaavion verkon osalta meill\u00e4 on seuraavanlainen laskukaava:</p> \\[ \\begin{aligned} z_1 &amp;= w_{00} \\cdot x_1 + w_{01} \\cdot x_2 + w_{02} \\cdot x_3 + b_0 \\\\ z_2 &amp;= w_{10} \\cdot x_1 + w_{11} \\cdot x_2 + w_{12} \\cdot x_3 + b_1 \\\\ h_1 &amp;= \\sigma(z_1) \\\\ h_2 &amp;= \\sigma(z_2) \\end{aligned} \\] <p>Yll\u00e4 olevassa kaavassa \\(\\sigma\\) on aktivointifunktio, esimerkiksi sigmoid tai ReLU. T\u00e4ll\u00f6in, kun haluamme laskea gradientin \\(w_{00}\\) suhteen, meid\u00e4n t\u00e4ytyy k\u00e4ytt\u00e4\u00e4 ketjus\u00e4\u00e4nt\u00f6\u00e4, koska \\(w_{00}\\) vaikuttaa lopulliseen h\u00e4vi\u00f6\u00f6n (loss) monen v\u00e4likerroksen kautta. Watson ja Chollet kirjoittavatkin, ett\u00e4: </p> <p>\"Backpropagation is simply the application of the chain rule to a computation graph. There\u2019s nothing more to it.\" <sup>3</sup></p> <p>Ketjus\u00e4\u00e4nn\u00f6n avulla voimme purkaa monimutkaisen funktion osittaisderivaatat yksinkertaisemmiksi osittaisderivaattojen kertolaskuiksi. Jos meill\u00e4 on funktio \\(f(g(x))\\), ketjus\u00e4\u00e4nn\u00f6n mukaan sen derivaatta on: \\(\\frac{df}{dx} = \\frac{df}{dg} \\cdot \\frac{dg}{dx}\\). Mik\u00e4li et muista matematiikan tunneista mit\u00e4\u00e4n, kannattaa kerrata ketjus\u00e4\u00e4nt\u00f6 kun kirjoitat oppimisp\u00e4iv\u00e4kirjaasi. Teht\u00e4viss\u00e4 on annettu hy\u00f6dyllisi\u00e4 l\u00e4hteit\u00e4, joista l\u00f6yd\u00e4t lis\u00e4tietoa.</p> <p>T\u00e4m\u00e4n viikon j\u00e4lkeen sinulle pit\u00e4isi olla vahva ymm\u00e4rrys siit\u00e4, mit\u00e4 tapahtuu seuraavissa riveiss\u00e4:</p> <pre><code>for epoch in range(epochs):\n    # ...\n    loss = some_loss_function(y_true, y_pred)\n    loss.backward()  # &lt;-- T\u00e4ss\u00e4 tapahtuu backpropagation\n    # ...\n</code></pre> <p>Jos/kun lasket backpropagationin oppimissyist\u00e4 k\u00e4sin, ainakin kerran el\u00e4m\u00e4ss\u00e4si, ymm\u00e4rr\u00e4t paremmin, mit\u00e4 <code>loss.backward()</code> tekee. K\u00e4yt\u00e4nn\u00f6ss\u00e4 t\u00e4h\u00e4n l\u00f6ytyy ainakin kaksi erilaista keinoa. Esittelen ne lyhyesti alla, ja my\u00f6hemmin tutustut n\u00e4ihin teht\u00e4vien kautta.</p>"},{"location":"vastavirta/backpropagation/#keino-1-ensin-lokaalit-ja-sitten-kertolasku","title":"Keino 1: Ensin lokaalit ja sitten kertolasku","text":"<p>T\u00e4m\u00e4 on se keino, johon t\u00f6rm\u00e4\u00e4t esimerkiksi Tamer Elsayedin videolla: Lecture 12 | Backpropagation I | CMPS 497 Deep Learning | Fall 2024 (alkaen ajasta 24:56). Toimintatapa on seuraava:</p> <ol> <li>Tee ensin forward pass ja tallenna kaikki v\u00e4liarvot.</li> <li>Laske kunkin muuttujan lokaali derivaatta sen sy\u00f6tteiden suhteen (esim. tulos\u00e4\u00e4nt\u00f6\u00e4 hy\u00f6dynt\u00e4en).</li> <li>Kun t\u00e4m\u00e4 on valmis, ja haluat tiet\u00e4\u00e4 vaikkapa painon \\(w_{00}\\) vaikutuksen lopulliseen h\u00e4vi\u00f6\u00f6n (loss), etsi kaikki polut, jotka yhdist\u00e4v\u00e4t \\(w_{00}\\) lopulliseen h\u00e4vi\u00f6\u00f6n. Kerro ne yhteen.</li> </ol> <p>Huomaa, ett\u00e4 kohdan 2 voi tehd\u00e4 k\u00e4yt\u00e4nn\u00f6ss\u00e4 miss\u00e4 tahansa j\u00e4rjestyksess\u00e4, kunhan kaikki tarvittavat lokaalit derivaatit on laskettu.</p>"},{"location":"vastavirta/backpropagation/#keino-2-lopusta-vaiheittain-alkuun","title":"Keino 2: Lopusta vaiheittain alkuun","text":"<p>T\u00e4m\u00e4 on se keino, kuinka backpropagation esitell\u00e4\u00e4n usein ohjelmoinnin yhteydess\u00e4 kirjallisuudessa. Esimerkiksi Matt Mazurin blogissa: A Step by Step Backpropagation Example. T\u00e4m\u00e4 on loogista, koska virhe propagoituu verkossa taaksep\u00e4in. V\u00e4livaiheissa tallennetut layerin gradientteja voidaan nimitt\u00e4\u00e4 deltoiksi. Toteutuksemme laskee kunkin kerroksen virheen eli \"deltan\" (\\(dZ\\)). T\u00e4t\u00e4 virhett\u00e4 k\u00e4ytet\u00e4\u00e4n laskemaan painojen gradientit (\\(dW\\) ja \\(db\\)).</p> <ol> <li>Tee ensin forward pass ja tallenna kaikki v\u00e4liarvot (aktivoinnit \\(A\\))</li> <li>K\u00e4sittele l\u00e4ht\u00f6tason virhe (\\(dZ_{out}\\)) virhe.</li> <li>Laske t\u00e4m\u00e4n kerroksen painojen gradientit (\\(dW\\)) (hy\u00f6dynt\u00e4en virhett\u00e4 ja edellisen tason sy\u00f6tett\u00e4)</li> <li>Laske edellisen kerroksen virhe siirt\u00e4m\u00e4ll\u00e4 nykyinen virhe painojen l\u00e4pi taaksep\u00e4in (\\(dZ_{prev}\\))</li> <li>Toista vaiheet 3 ja 4, kunnes kaikki kerrokset on k\u00e4sitelty.</li> </ol> <p>Huomaa, ett\u00e4 t\u00e4m\u00e4 on pakko tehd\u00e4 j\u00e4rjestyksess\u00e4 lopusta alkuun, koska jokainen kerros tarvitsee edellisen kerroksen gradientin.</p> <p>Itse operaatio n\u00e4ytt\u00e4\u00e4 meid\u00e4n viime viikon <code>NumpyNNwithBCE</code>-mallissamme t\u00e4lt\u00e4:</p> <pre><code>def backward(self, target):\n    # === L\u00e4ht\u00f6kerros (Layer 2) ===\n    # 1. Laske virhe (dZ2)\n    self.dZ2 = self.A2 - target  # (1)!\n\n    # 2. Laske gradientit painoille (dW2, db2)\n    # N\u00e4m\u00e4 tallennetaan, jotta optimize() voi k\u00e4ytt\u00e4\u00e4 niit\u00e4\n    self.dW2 = self.A1.T.dot(self.dZ2)  # (2)!\n    self.db2 = self.dZ2  # (3)!\n\n    # === Piilotettu kerros (Layer 1) ===\n    # 3. Propagoi virhe taaksep\u00e4in (dZ1)\n    dA1 = self.dZ2.dot(self.W2.T)  # (4)!\n    self.dZ1 = dA1 * self.sigmoid_derivative(self.A1)  # (5)!\n\n    # 4. Laske gradientit painoille (dW1, db1)\n    self.dW1 = self.A0.T.dot(self.dZ1)  # (6)!\n    self.db1 = self.dZ1  # (7)!\n</code></pre> <ol> <li> <p>dZ2 eli delta (\u03b4\u00b2) on l\u00e4ht\u00f6kerroksen derivaatta. Binary cross-entropy + sigmoid -yhdistelm\u00e4ll\u00e4 t\u00e4m\u00e4 yksinkertaistuu muotoon <code>ennuste - todellinen</code>. T\u00e4m\u00e4 on gradientti h\u00e4vi\u00f6n suhteen pre-aktivaatioon Z\u00b2.</p> </li> <li> <p>dW2 on gradientti l\u00e4ht\u00f6kerroksen painoille W\u00b2. Lasketaan kertomalla edellisen kerroksen aktivaatiot (A\u00b9) nykyisen kerroksen virheell\u00e4 (dZ\u00b2). K\u00e4yt\u00e4nn\u00f6ss\u00e4 t\u00e4ss\u00e4 on tulos\u00e4\u00e4nt\u00f6.</p> </li> <li> <p>db2 on gradientti l\u00e4ht\u00f6kerroksen biaseille b\u00b2. Bias-gradientti on yksinkertaisesti sama kuin virhe (dZ\u00b2), koska biasin derivaatta on 1.</p> </li> <li> <p>dA1 on gradientti piilotetun kerroksen aktivaatioiden suhteen. Propagoidaan virhe taaksep\u00e4in kertomalla nykyisen kerroksen virhe (dZ\u00b2) nykyisen kerroksen painojen (W\u00b2.T) kanssa. T\u00e4m\u00e4 on tulos\u00e4\u00e4nn\u00f6n toinen puolisko (vrt. dW\u00b2 lasku yll\u00e4).</p> </li> <li> <p>dZ1 eli delta (\u03b4\u00b9) on piilotetun kerroksen virhe. Lasketaan kertomalla propagoitu aktivaatiovirhe (dA\u00b9) sigmoidin derivaatalla pisteess\u00e4 A\u00b9. T\u00e4m\u00e4 on ketjus\u00e4\u00e4nn\u00f6n sovellus!</p> </li> <li> <p>dW1 on gradientti piilotetun kerroksen painoille W\u00b9. Lasketaan samalla tavalla kuin dW2.</p> </li> <li> <p>db1 on gradientti piilotetun kerroksen biaseille b\u00b9. Lasketaan samalla tavalla kuin db2.</p> </li> </ol> <p></p> <p>Kuva 1: Malli <code>NumpyNNwithBCE</code> Excalidraw-piirroksena. Ylemm\u00e4ss\u00e4 kuvion puoliskossa on avattuna piilotetut kerrokset siten, ett\u00e4 neuroni on purettu Z- ja A-osiin eli esiaktivoituun ja sigmoid-muunnettuun. Alemmassa kuviossa on tuttu esitys 2-2-1 verkosta siten, ett\u00e4 biasit on piilotettu. Huomaa, ett\u00e4 <code>X == A0</code>.</p> <p>Note</p> <p>Yll\u00e4 olevassa koodiesimerkiss\u00e4, kuten muutenkin NumpyNN:n suhteen, on oletus, ett\u00e4 meill\u00e4 on stokastinen gradientti, jossa batch size on tasan 1. Muuten dB2 ja dB1 pit\u00e4isi laskea ottamalla keskiarvo rivien yli (esim. <code>np.sum(self.dZ2, axis=0) / m</code>, miss\u00e4 m on batch size).</p> <p>Tutustu yll\u00e4 olevan koodiblokin annotointeihin; tunnistat ne pienest\u00e4 plussamerkist\u00e4, josta aukeaa lis\u00e4tietoa. Huomaa, ett\u00e4 jos piilotettuja kerroksia olisi useita, prosessi alkaisi n\u00e4ytt\u00e4\u00e4 t\u00e4lt\u00e4:</p> <pre><code>def backward(self, target):\n        # === L\u00e4ht\u00f6kerros ===\n        self.dZ5 = self.A5 - target\n        self.dW5 = self.A4.T.dot(self.dZ5) # Gradientti W5:lle\n\n        # === Piilotetut kerrokset ===\n        # Layer 4\n        dA4 = self.dZ5.dot(self.W5.T)\n        self.dZ4 = dA4 * self.sigmoid_derivative(self.A4)\n        self.dW4 = self.A3.T.dot(self.dZ4) # Gradientti W4:lle\n\n        # Layer 3\n        dA3 = self.dZ4.dot(self.W4.T)\n        self.dZ3 = dA3 * self.sigmoid_derivative(self.A3)\n        self.dW3 = self.A2.T.dot(self.dZ3) # Gradientti W3:lle\n\n        # Layer 2\n        dA2 = self.dZ3.dot(self.W3.T)\n        self.dZ2 = dA2 * self.sigmoid_derivative(self.A2)\n        self.dW2 = self.A1.T.dot(self.dZ2) # Gradientti W2:lle\n\n        # Layer 1\n        dA1 = self.dZ2.dot(self.W2.T)\n        self.dZ1 = dA1 * self.sigmoid_derivative(self.A1)\n        self.dW1 = self.A0.T.dot(self.dZ1) # Gradientti W1:lle\n</code></pre> <p>Jos t\u00e4m\u00e4n haluaa kirjoittaa dynaamisesti useammalle piilotetulle kerrokselle, t\u00e4ytyy k\u00e4ytt\u00e4\u00e4 silmukkaa. T\u00e4ll\u00f6in eri kerrokset, kuten my\u00f6s aktivoinnit, kannattaisi tallentaa listoiksi. Seuraava koodiblokki mukailee Adrian Rosebrockin kirjan luvun 10 esimerkki\u00e4 <sup>4</sup>. Esimerkiss\u00e4 k\u00e4ytet\u00e4\u00e4n yleist\u00e4 ketjus\u00e4\u00e4nt\u00f6\u00e4, joka lasketaan my\u00f6s l\u00e4ht\u00f6kerrokselle (output layer). Huomaa, ett\u00e4 <code>output_delta</code> sis\u00e4lt\u00e4\u00e4 my\u00f6s aktivaatiofunktion derivaatan. T\u00e4m\u00e4 tarvitaan, koska k\u00e4yt\u00f6ss\u00e4 on MSE-virhefunktio \u2013 aiemmassa BCE-esimerkiss\u00e4 t\u00e4t\u00e4 vaihetta ei tarvittu Sigmoid+BCE-yhdistelm\u00e4n vuoksi. Termill\u00e4 delta viitataan esiaktivaation virheeseen, joka on siis \\(dZ^n\\)-termi.</p> <pre><code>    def backprop(self, X, y):\n        # Tee forward pass ja tallenna kaikki aktivoinnit\n        activations = self.forward(X)\n\n        # 1. Laske l\u00e4ht\u00f6tason virhe (output layer)\n        output_error = activations[-1] - y\n        output_delta = output_error * self.sigmoid_deriv(activations[-1])\n\n        # Deltat tulevat pinoutumaan t\u00e4h\u00e4n listaan\n        deltas = [output_delta]\n\n        # 2. Propagoi gradientti taaksep\u00e4in kerros kerrokselta\n        for layer_idx in np.arange(len(activations) - 2, 0, -1):\n\n            # hy\u00f6dynnet\u00e4\u00e4n edellisen kerroksen deltaa (pinon p\u00e4\u00e4lt\u00e4)\n            this_delta = deltas[-1].dot(self.W[layer_idx].T)\n\n            # sigmoid ketjus\u00e4\u00e4nn\u00f6ll\u00e4 mukaan\n            this_delta = this_delta * self.sigmoid_deriv(activations[layer_idx])\n\n            # lis\u00e4\u00e4 t\u00e4m\u00e4 delta pinon p\u00e4\u00e4lle\n            deltas.append(this_delta)\n\n        # 3. K\u00e4\u00e4nn\u00e4 deltalista oikeaan j\u00e4rjestykseen. \n        # Nyt niit\u00e4 voi k\u00e4ytt\u00e4\u00e4 painojen p\u00e4ivitt\u00e4miseen optimointialgoritmissa\n        self.deltas = deltas[::-1]\n</code></pre> <p>Huomaa, ett\u00e4 Rosebrockin koodi poikkeaa meid\u00e4n esimerkist\u00e4 siten, ett\u00e4 se laskee t\u00e4ss\u00e4 vaiheessa ainoastaan kerrosten virhetermit eli deltat (\\(dZ^n\\)), mutta ei viel\u00e4 varsinaisia painojen gradientteja (\\(dW^n\\)).</p> <p>Meid\u00e4n NumpyNNwithBCE-toteutuksessamme laskimme backward-metodissa valmiiksi my\u00f6s gradientit (esim. self.dW2 = ...), jotta rakenne vastaisi t\u00e4ysin PyTorchin tapaa tallentaa gradientit .grad-muuttujaan. Rosebrockin esimerkiss\u00e4 gradienttien laskeminen (eli aktivaatioiden ja deltojen v\u00e4linen matriisitulo) on j\u00e4tetty teht\u00e4v\u00e4ksi vasta my\u00f6hemmin, varsinaisen painojen p\u00e4ivityksen yhteyteen.</p> <p>Bias?</p> <p>Ent\u00e4p\u00e4 bias-termit? Kun meill\u00e4 on selke\u00e4 Dense-verkko (fully connected), bias-termit voidaan k\u00e4sitell\u00e4 muiden painojen joukossa. T\u00e4m\u00e4 onnistuu yksinkertaisesti lis\u00e4\u00e4m\u00e4ll\u00e4 sy\u00f6tevektoriin ylim\u00e4\u00e4r\u00e4inen arvo, joka on aina 1. Olet tehnyt t\u00e4m\u00e4n jo aiemmin Johdatus koneoppimiseen -kurssilla. Rosebrock kutsuu t\u00e4t\u00e4 bias trick-menetelm\u00e4ksi, ja hoitaa sen n\u00e4in <code>fit()</code>-metodissaan <sup>4</sup>:</p> <pre><code>X = np.c_[X, np.ones((X.shape[0]))]\n</code></pre> <p>Minun koodiesimerkeiss\u00e4ni bias-termit on k\u00e4sitelty erikseen, jotta koodi olisi selke\u00e4mp\u00e4\u00e4 oppimisen kannalta, ja kenties t\u00e4sm\u00e4isi paremmin PyTorchin tapaan.</p>"},{"location":"vastavirta/backpropagation/#pytorchissa","title":"PyTorchissa","text":"<p>T\u00e4t\u00e4 kannattaa harjoitella itsen\u00e4isesti PyTorchin avulla. Alla on kuitenkin yksinkertainen esimerkki siit\u00e4, kuinka simppeli funktio ja sen derivointi onnistuu. Tavoitteenamme on funktio:</p> \\[ f = \\frac{1}{n} \\sum_{i,j} x_{ij}^2 \\] <p>T\u00e4m\u00e4n voi derivoida muotoon <code>1/n * 2x</code>. Kun <code>n = 4</code>, niin saamme:</p> \\[ \\nabla f = \\frac{X}{2} \\] <p>Tehd\u00e4\u00e4n sama PyTorchissa.</p> <pre><code>x = torch.tensor([\n    [0.1, 0.2],\n    [0.3, 0.4]\n], requires_grad=True) # &lt;- hox!\n\n# Pow\ny = x ** 2\n\n# 1/n * y\nf = y.mean()\n</code></pre> <p>T\u00e4ss\u00e4 vaiheessa <code>f</code> on skaalari arvolstaan <code>0.0750</code>. Jos t\u00e4ss\u00e4 vaiheessa tulostat eri arvoja, tulet huomaamaan, ett\u00e4 <code>x.grad==None</code>, koska emme ole viel\u00e4 tehneet takaisinvirtausta. Sen sijaan <code>y.grad_fn</code> ja <code>f.grad_fn</code> kertovat, miten n\u00e4m\u00e4 arvot on laskettu: ne sis\u00e4lt\u00e4v\u00e4t arvot <code>&lt;PowBackward0&gt;</code> ja <code>&lt;MeanBackward0&gt;</code>, jotka viittaavat <code>y</code>- ja <code>f</code>-muuttujien laskentaan. Nyt voimme kutsua takaisinvirtausta, mik\u00e4 antaa <code>x.grad</code>-muuttujaan halutun gradientin:</p> <pre><code>f.backward()\n</code></pre> <p>Jatkossa <code>x.grad</code> sis\u00e4lt\u00e4\u00e4 gradientin <code>f</code> suhteen <code>x</code>:\u00e4\u00e4n. Tulostamalla <code>x.grad</code> saamme:</p> <pre><code>tensor([[0.0500, 0.1000],\n        [0.1500, 0.2000]])\n</code></pre>"},{"location":"vastavirta/backpropagation/#autograd","title":"Autograd","text":"<p>K\u00e4yt\u00e4nn\u00f6ss\u00e4 backpropagation on toteutettu syv\u00e4oppimiskirjastoissa siten, ett\u00e4 sinun ei tarvitse kirjoittaa backpropagation-koodia itse muuta kuin opiskelusyist\u00e4. Kukin Tensor huolehtii itseens\u00e4 kohdistuneista operaatioista. PyTorch:n oma dokumentaatio esittelee sit\u00e4 kattavasti, joten kannattaa tutustua, jos aihe kiinnostaa: Automatic differentiation package - torch.autograd. Etsi sivulta sanaa <code>grad_fn</code>. Kun esimerkiksi teet tensorioperaation <code>y = a * b</code>, PyTorch kiinnitt\u00e4\u00e4 tensoriin <code>grad_fn=&lt;MulBackward0&gt;</code>:n. Kun my\u00f6hemmin kutsut <code>y.backward()</code>, PyTorch k\u00e4ytt\u00e4\u00e4 t\u00e4t\u00e4 tietoa laskeakseen gradientit <code>a</code> ja <code>b</code> suhteen. T\u00e4ss\u00e4 tapauksessa kyseess\u00e4 olisi kertolaskuun p\u00e4tev\u00e4 s\u00e4\u00e4nt\u00f6 eli \\(\\frac{d}{da}(a \\cdot b) = b\\) ja \\(\\frac{d}{db}(a \\cdot b) = a\\).</p> <p>Kun t\u00e4m\u00e4 tehd\u00e4\u00e4n koko <code>loss.backward()</code>-kutsun yhteydess\u00e4, PyTorch k\u00e4velee taaksep\u00e4in koko laskentaverkon l\u00e4pi, k\u00e4ytt\u00e4en ketjus\u00e4\u00e4nt\u00f6\u00e4 laskeakseen gradientit kaikille verkon parametreille. T\u00e4m\u00e4 on siis juuri se, mit\u00e4 backpropagation tekee.</p> <p>Jotta takaisinvirtaus (backpropagation) on mahdollista, verkon t\u00e4ytyy t\u00e4ytt\u00e4\u00e4 joitakin kriteereit\u00e4:</p> <ol> <li> <p>Derivoitavuus. Verkon kaikkien osien tulee olla derivoituvia. ReLU ei ole derivoitava pisteess\u00e4 0, mutta siit\u00e4 k\u00e4yt\u00e4nn\u00f6ss\u00e4 tehd\u00e4\u00e4n sellainen subgradientin avulla (lue: fancy tapa sanoa, ett\u00e4 <code>if (x == 0): return 0</code>). Alkuper\u00e4isen Perceptronin askelfunktio ei ole derivoituva, joten se ei sovellu vastavirta-algoritmin k\u00e4ytt\u00f6\u00f6n. <sup>5</sup> Diskeetit ehtolauseet ja satunnaisuus eiv\u00e4t ole my\u00f6sk\u00e4\u00e4n derivoitavia.</p> </li> <li> <p>Asyklinen laskentagraafi (DAG). Laskennan t\u00e4ytyy muodostaa suunnattu asyklinen verkko. Jos verkossa on silmukoita (esim. RNN), ne \"avataan auki\" (unrolling), jotta backpropagation voidaan toteuttaa <sup>5</sup>.</p> </li> </ol> <p>Monimutkaisemmat arkkitehtuurit</p> <p>Yll\u00e4 esitelty delta-s\u00e4\u00e4nt\u00f6 ja backward-metodin toteutus toimii suoraviivaisesti tavallisissa, eteenp\u00e4in suunnatuissa neuroverkoissa (engl. feedforward, fully connected, dense), joissa jokainen neuroni on yhteydess\u00e4 jokaiseen edellisen kerroksen neuroniin. Monimutkaisemmissa arkkitehtuureissa, kuten konvoluutioverkoissa (CNN), gradienttien laskeminen on huomattavasti monimutkaisempaa.</p> <p>Onneksi autograd hoitaa kaiken t\u00e4m\u00e4n puolestamme!</p>"},{"location":"vastavirta/backpropagation/#tehtavat","title":"Teht\u00e4v\u00e4t","text":"<p>\u00c4l\u00e4 panikoi!</p> <p>Teht\u00e4v\u00e4t ovat t\u00e4m\u00e4n kurssin teoreettisin ja mahdollisesti eniten p\u00e4\u00e4nvaivaa aiheuttava osio. Suhteuta aiheeseen sukeltaminen omiin voimavaroihisi: jos opettajan kirjoittamat Marimo Notebookit osoittautuvat voittamattomiksi, keskity esimerkiksi StatQuestin videoihin ja intuitiotasoon.</p> <p>Lopulta t\u00e4rkeint\u00e4 on, ett\u00e4 ymm\u00e4rr\u00e4t perusidean backpropagationista ja osaat k\u00e4ytt\u00e4\u00e4 sit\u00e4 syv\u00e4oppimiskirjastoissa, kuten PyTorchissa. Muista, ett\u00e4 haluat v\u00e4ltell\u00e4 olemasta t\u00e4m\u00e4 henkil\u00f6:</p> <p>\"Mit\u00e4 osaat kertoa algoritmista nimelt\u00e4\u00e4n backpropagation?\"  \u2014 \"\u00d6\u00f6\u00f6h, taisin k\u00e4ytt\u00e4\u00e4 sit\u00e4 yhdess\u00e4 projektissa, vissiin.\"</p> <p>Teht\u00e4v\u00e4: Takaisinvirtaus intuition tasolla</p> <p>Aloita tutustumalla sek\u00e4 minun materiaaliin ett\u00e4 internetist\u00e4 l\u00f6ytyv\u00e4\u00e4n, intuitiotasoa korostavaan sis\u00e4lt\u00f6\u00f6n. Hyvi\u00e4 l\u00e4hteit\u00e4 ovat ainakin:</p> <ul> <li>3Blue1Brown video: Backpropagation, intuitively | Deep Learning Chapter 3 (12 min)</li> <li>StatQuest: Neural Networks Pt. 2: Backpropagation Main Ideas (17 min)</li> <li>Jos sinulla on p\u00e4\u00e4sy Manningin kirjaan Deep Learning with Python, Third Edition (2025), tutustu lukuun 2.4 \"The engine of neural networks: Gradient-based optimization\" <sup>3</sup>.</li> <li>Karpathy: CS231n Winter 2016: Lecture 4: Backpropagation, Neural Networks 1. OpenAI:n yksi perustaja, alalla hyvinkin tunnettu Andrej Karpathy k\u00e4y Stanfordin luennolla l\u00e4pi vastavirta-algoritmin. (1 h 20 min)</li> </ul> <p>Teht\u00e4v\u00e4: Lopusta vaiheittain alkuun</p> <p>Olet aiemmin n\u00e4hnyt backpropagation-algoritmin tehdyn k\u00e4sin <code>NumpyNNwithBCE</code>-mallissamme, ja t\u00e4h\u00e4n viitattiin my\u00f6s t\u00e4ss\u00e4 luentomateriaalissa. Tutustu nyt <code>300_numpy_to_pytorch_pt2.py</code>-Notebookiin, jossa tehd\u00e4\u00e4n syv\u00e4luotausta aiemmin n\u00e4hdyn koodin <code>backward</code>-metodin toiminnasta. T\u00e4ss\u00e4 Notebookissa k\u00e4ytet\u00e4\u00e4n \"Lopusta vaiheittain alkuun\" -menetelm\u00e4\u00e4.</p> <p>Notebookin rinnalla on hyv\u00e4 tutustua my\u00f6s Matt Mazurin versioon: A Step by Step Backpropagation Example. Jos haluat todellisen syv\u00e4luotauksen aiheeseen, katso University of Michiganin Justin Johnsonin luento: Lecture 6: Backpropagation. Aihetta k\u00e4sitell\u00e4\u00e4n my\u00f6s kurssilla aiemmin mainitussa Understanding Deep Learning e-kirjassa.</p> <p>Voit hy\u00f6dynt\u00e4\u00e4 sit\u00e4 muistiinpanojen tekemiseen oppimisp\u00e4iv\u00e4kirjaasi.</p> <p>Teht\u00e4v\u00e4: PyTorch Learn the Basics: Automatic Differentiation with torch.autograd</p> <p>Tutustu <code>301_autogradqs_tutorial.py</code>-tiedostossa olevaan, Marimo-formaattiin k\u00e4\u00e4nnettyyn PyTorchin tutoriaaliin. Alkuper\u00e4inen l\u00f6ytyy t\u00e4st\u00e4 osoitteesta: Automatic Differentiation with torch.autograd</p> <p>Teht\u00e4v\u00e4: Ensin lokaalit ja sitten kertolasku</p> <p>Tutustu <code>302_backpropagation.py</code>-Notebookiin, jossa tehd\u00e4\u00e4n syv\u00e4luotausta backpropagationin toiminnasta \"Ensin lokaalit ja sitten kertolasku\" -menetelm\u00e4ll\u00e4. Notebookin rinnalla on hyv\u00e4 tutustua my\u00f6s Tamer Elsayedin luentoon: Lecture 12 | Backpropagation I | CMPS 497 Deep Learning | Fall 2024 (alkaen ajasta 24:56), jossa h\u00e4n k\u00e4y l\u00e4pi Understanding Deep Learning -kirjan luvun 7 asioita nimenomaan t\u00e4ll\u00e4 menetelm\u00e4ll\u00e4. My\u00f6s seuraava video, Lecture 13 | Backpropagation II | CMPS 497 Deep Learning | Fall 2024, jatkaa vastavirran parissa.</p> <p>Teht\u00e4v\u00e4: Laskentaketju PyTorchissa</p> <p>Tee yll\u00e4 olevan <code>f = (1/n) * sum(x)</code> -esimerkin kaltainen laskentaketju PyTorchissa, jossa selvit\u00e4t muuttujien \\(x\\), \\(y\\) ja \\(z\\) gradientit. Funktion \\(f\\) tulee noudattaa seuraavaa matemaattista funktioiden ketjua:</p> \\[ \\begin{aligned} a &amp;= x^3 \\\\ b &amp;= y^2 \\\\ c &amp;= a \\odot b \\quad \\text{(elementwise-tulo)} \\\\ d &amp;= |\\sin(\\frac{c}{b})| \\quad \\text{(itseisarvo)} \\\\ e &amp;= \\sqrt{\\frac{d}{z}} \\\\ f &amp;= \\frac{1}{n}\\sum_i e_i \\quad \\text{(keskiarvo)} \\end{aligned} \\] <p>Voit joko aloittaa tyhj\u00e4st\u00e4 tai hy\u00f6dynt\u00e4\u00e4 <code>303_chained_funcs.py</code>-Notebookin runkoa. K\u00e4yt\u00e4 n\u00e4it\u00e4 alkuarvoja, jotta voit tarkistaa laskelmat alla olevia tuloksia vasten:</p> <ul> <li>\\(x = [1.0, 2.0, 3.0]\\)</li> <li>\\(y = [0.5, 1.0, 1.5]\\)</li> <li>\\(z = 0.5\\)</li> </ul> <p>Tunnistat oikeat tulokset seuraavista arvoista:</p> <pre><code>f = 1.362325\nx.grad = tensor([ 0.4165, -0.4137, -1.9011])\ny.grad = tensor([0.0000e+00, 0.0000e+00, 1.7881e-07])\nz.grad = -1.362325\n</code></pre> <p>Note</p> <p>Muista pohtia, mit\u00e4 gradientti oikeastaan tarkoittaa. Jos k\u00e4\u00e4rit toteutuksesi funktioon, joka ottaa <code>x</code>:n parametrina, niin voit laskea kaksi arvoa seuraavasti:</p> <pre><code>f1 = compute([1.0, 2.0, 3.0])\nf2 = compute([1.0, 2.0, 3.00001])\n</code></pre> <p>Tulet huomaamaan, ett\u00e4 <code>f2 - f1</code> on hyvin l\u00e4hell\u00e4 <code>x.grad[2] * 0.00001</code>. Eli jos kasvatat <code>x[2]</code>:ta pikkiriikkisen verran, niin <code>f</code>:n arvo muuttuu suunnilleen <code>x.grad[2]</code> kertaa tuo pieni muutos. Huomaa kuitenkin, ett\u00e4 lukema ei tule olemaan niin sama, ett\u00e4 voisit verrata sit\u00e4 <code>==</code>-operaattorilla.</p>"},{"location":"vastavirta/backpropagation/#lahteet","title":"L\u00e4hteet","text":"<ol> <li> <p>Olah, C. Calculus on Computational Graphs: Backpropagation. 2015. https://colah.github.io/posts/2015-08-Backprop/\u00a0\u21a9\u21a9\u21a9</p> </li> <li> <p>Nield, T. Essential Math for Data Science. O'Reilly. 2021.\u00a0\u21a9\u21a9</p> </li> <li> <p>Watson, M &amp; Chollet, F. Deep Learning with Python, Third Edition. Manning. 2025.\u00a0\u21a9\u21a9</p> </li> <li> <p>Rosebrock, A. Deep Learning for Computer Vision with Python. Starter Bundle. 3rd Edition. PyImageSearch. 2019.\u00a0\u21a9\u21a9</p> </li> <li> <p>G\u00e9ron, A. Hands-On Machine Learning with Scikit-Learn and PyTorch. O'Reilly. 2025.\u00a0\u21a9\u21a9</p> </li> </ol>"}]}