
<!doctype html>
<html lang="fi" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../../tensorit/pytorch/">
      
      
        <link rel="next" href="../../mallinnus/yleiskatsaus/">
      
      
        
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.2">
    
    
      
        <title>Vastavirta (Backprop) - Syväoppiminen I</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#vastavirta-backprop" class="md-skip">
          Hyppää sisältöön
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Ylätunniste">
    <a href="../.." title="Syväoppiminen I" class="md-header__button md-logo" aria-label="Syväoppiminen I" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Syväoppiminen I
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Vastavirta (Backprop)
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Hae" placeholder="Hae" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Haku">
        
        <button type="reset" class="md-search__icon md-icon" title="Tyhjää" aria-label="Tyhjää" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Aloitetaan hakua
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigaatio" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Syväoppiminen I" class="md-nav__button md-logo" aria-label="Syväoppiminen I" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Syväoppiminen I
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Tervetuloa kurssille
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    1. Neuroverkot
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    1. Neuroverkot
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../neuroverkot/neuroverkot_101/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Neuroverkot
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../neuroverkot/syvaoppiminen_FC/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Syvät neuroverkot
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    2. Tensorit
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    2. Tensorit
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tensorit/vektorointi/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Vektorointi
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tensorit/pytorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    PyTorch
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    3. Vastavirta
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    3. Vastavirta
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    Vastavirta (Backprop)
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    Vastavirta (Backprop)
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Sisällysluettelo">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Sisällysluettelo
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#motivaatio" class="md-nav__link">
    <span class="md-ellipsis">
      
        Motivaatio
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#kertaus-mika-on-gradientti" class="md-nav__link">
    <span class="md-ellipsis">
      
        Kertaus: Mikä on gradientti?
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Kertaus: Mikä on gradientti?">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#osittaisderivaatta" class="md-nav__link">
    <span class="md-ellipsis">
      
        Osittaisderivaatta
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gradientti" class="md-nav__link">
    <span class="md-ellipsis">
      
        Gradientti
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#backpropagation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Backpropagation
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Backpropagation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#paperilla" class="md-nav__link">
    <span class="md-ellipsis">
      
        Paperilla
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Paperilla">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#keino-1-ensin-lokaalit-ja-sitten-kertolasku" class="md-nav__link">
    <span class="md-ellipsis">
      
        Keino 1: Ensin lokaalit ja sitten kertolasku
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#keino-2-lopusta-vaiheittain-alkuun" class="md-nav__link">
    <span class="md-ellipsis">
      
        Keino 2: Lopusta vaiheittain alkuun
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pytorchissa" class="md-nav__link">
    <span class="md-ellipsis">
      
        PyTorchissa
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autograd" class="md-nav__link">
    <span class="md-ellipsis">
      
        Autograd
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tehtavat" class="md-nav__link">
    <span class="md-ellipsis">
      
        Tehtävät
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lahteet" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lähteet
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    4. Mallinnus
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    4. Mallinnus
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../mallinnus/yleiskatsaus/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Yleiskatsaus
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../mallinnus/datanlataus/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Datan lataus
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../mallinnus/kaytannot/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Kouluttamisen käytännöt
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    5. Konvoluutio
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            
  
    5. Konvoluutio
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../konvoluutio/cnn/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Konvoluutioverkot
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    6. Siirtovaikutus
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            
  
    6. Siirtovaikutus
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../siirtovaikutus/pretrained/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Koulutetun mallin käyttö
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../siirtovaikutus/transferlearning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Siirtovaikutus
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8" >
        
          
          <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    7. Kieli
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8">
            <span class="md-nav__icon md-icon"></span>
            
  
    7. Kieli
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../kieli/nlp/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Luonnollinen kieli
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../kieli/rnn/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    RNN ja jälkeläiset
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../kieli/transformers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Transformers
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_9" >
        
          
          <label class="md-nav__link" for="__nav_9" id="__nav_9_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    8. Aikasarjat
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_9">
            <span class="md-nav__icon md-icon"></span>
            
  
    8. Aikasarjat
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../aikasarjat/ideat/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Aikasarjat
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../exercises/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Tehtäväkooste
  

    
  </span>
  
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Sisällysluettelo">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Sisällysluettelo
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#motivaatio" class="md-nav__link">
    <span class="md-ellipsis">
      
        Motivaatio
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#kertaus-mika-on-gradientti" class="md-nav__link">
    <span class="md-ellipsis">
      
        Kertaus: Mikä on gradientti?
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Kertaus: Mikä on gradientti?">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#osittaisderivaatta" class="md-nav__link">
    <span class="md-ellipsis">
      
        Osittaisderivaatta
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gradientti" class="md-nav__link">
    <span class="md-ellipsis">
      
        Gradientti
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#backpropagation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Backpropagation
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Backpropagation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#paperilla" class="md-nav__link">
    <span class="md-ellipsis">
      
        Paperilla
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Paperilla">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#keino-1-ensin-lokaalit-ja-sitten-kertolasku" class="md-nav__link">
    <span class="md-ellipsis">
      
        Keino 1: Ensin lokaalit ja sitten kertolasku
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#keino-2-lopusta-vaiheittain-alkuun" class="md-nav__link">
    <span class="md-ellipsis">
      
        Keino 2: Lopusta vaiheittain alkuun
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pytorchissa" class="md-nav__link">
    <span class="md-ellipsis">
      
        PyTorchissa
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autograd" class="md-nav__link">
    <span class="md-ellipsis">
      
        Autograd
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tehtavat" class="md-nav__link">
    <span class="md-ellipsis">
      
        Tehtävät
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lahteet" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lähteet
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="vastavirta-backprop">Vastavirta (Backprop)</h1>
<h2 id="motivaatio">Motivaatio</h2>
<p>Tämä on kenties kurssin teoreettisin osuus, mutta sisältää yleistietoa, joka on käytännössä pakko olla hallussa. Vertaa mielessäsi näitä kahta keskustelua:</p>
<blockquote>
<p>"Mitä osaat kertoa binäärijärjestelmästä?" <br>
— "Öööh, taisin käyttää sitä yhdessä projektissa, vissiin."</p>
<p>"Mitä osaat kertoa algoritmista nimeltään <em>backpropagation</em>?" <br>
— "Öööh, taisin käyttää sitä yhdessä projektissa, vissiin."</p>
</blockquote>
<p>Vastavirta-algoritmi (engl. backpropagation) on keskeinen menetelmä neuroverkkojen kouluttamisessa. Se mahdollistaa virheen tehokkaan laskemisen ja painojen päivittämisen verkon eri kerroksissa. Heti alkuun täytyy sanoa, että backpropagation ei ole sama asia kuin gradient descent, vaikka nämä kaksi usein mainitaankin yhdessä. Backpropagation on menetelmä, jolla lasketaan virheiden gradientit verkon painoille, kun taas gradient descent on optimointialgoritmi, joka käyttää näitä gradientteja painojen päivittämiseen. Optimointialgoritmeja on muitakin, kuten esimerkiksi Adam ja RMSprop.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Jos et osaa yhdistää termiä <code>optimizer</code> tai <code>Adam</code> mihinkään aiemmin näkemääsi, avaa jokin aiempien viikkojen marimo Notebook. Yksi monista esimerkeistä on Notebook, jossa koulutettiin Auto MPG -ennustin. Etsi rivejä, jotka näyttävät tältä:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">optimizer</span> <span class="o">=</span> <span class="n">xxxxx</span><span class="o">.</span><span class="n">xxxxx</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">xxxxxxxxxx</span><span class="p">,</span> <span class="n">xx</span><span class="o">=</span><span class="n">xxx</span><span class="p">)</span>
</span></code></pre></div>
<p>Huomaa kuitenkin, että optimointialgoritmit eivät ole tämän viikon aihe. Niihin tutustutaan hieman ensi viikolla. Tällä viikolla oletetaan, että meillä on jokin optimointialgoritmi, joka tarvitsee gradientit painojen päivittämiseen.</p>
</div>
<p>Loppupeleissä backpropagation on vain ketjusäännön soveltamista laskentaverkkoon. Eräs Anthropicin perustajista, Christopher Olah, pohtii blogissaan seuraavasti:</p>
<blockquote>
<p>"When I first understood what backpropagation was, my reaction was: “Oh, that’s just the chain rule! How did it take us so long to figure out?” I’m not the only one who’s had that reaction." <sup id="fnref3:colahblog"><a class="footnote-ref" href="#fn:colahblog">1</a></sup></p>
<p>— Christopher Olah</p>
</blockquote>
<p>Ja näinhän se jälkiviisaana on. Olah nostaa kuitenkin esiin, että asia ei ollut lainkaan niin ilmeinen silloin, kun vastavirta-algoritmi (backpropagation) alun perin keksittiin. Tuohon aikaan ei ollut selvää, että juuri derivaattojen laskeminen olisi oikea tapa opettaa neuroverkkoja. Tämäkin ajatus tulee luontevaksi vasta sitten, kun ymmärtää, että derivaatat voidaan laskea tehokkaasti. Syntyy eräänlainen kehäpäätelmä: jotta ymmärtäisimme, miksi derivaatat ovat hyödyllisiä, meidän täytyy jo tietää, että niiden laskeminen on mahdollista ja tehokasta. <sup id="fnref:colahblog"><a class="footnote-ref" href="#fn:colahblog">1</a></sup></p>
<p>Lisäksi Olah huomauttaa, että olisi ollut helppoa tyrmätä koko lähestymistapa nopealla järkeilyllä. Ajatus neuroverkkojen opettamisesta gradienttipohjaisilla menetelmillä saattoi vaikuttaa tuomittuna epäonnistumaan: eikö optimointi jäisi jumiin lokaaleihin minimeihin? <sup id="fnref2:colahblog"><a class="footnote-ref" href="#fn:colahblog">1</a></sup> </p>
<h2 id="kertaus-mika-on-gradientti">Kertaus: Mikä on gradientti?</h2>
<p>Tätä aihetta on käsitelty Johdatus koneoppimiseen -kurssissa Hill Climbing ja Gradient Descent -osioissa. Jos et muista aiheesta mitään, on äärimmäisen suositeltavaa kurkata omaa oppimispäiväkirjaasi ja kerrata lyhyesti. Tarkasti ottaen meidän tulee selvittää kaksi termiä: </p>
<ul>
<li>osittaisderivaatta (engl. <em>partial derivative</em>)</li>
<li>gradientti (engl. <em>gradient</em>)</li>
</ul>
<h3 id="osittaisderivaatta">Osittaisderivaatta</h3>
<p>Osittaisderivaatta on yksittäisen muuttujan vaikutus funktion lopputulokseen. Kun lasket osittaisderivaatan, pidät muut muuttujat vakioina ja tarkastelet vain yhden muuttujan vaikutusta <sup id="fnref:essentialmath"><a class="footnote-ref" href="#fn:essentialmath">2</a></sup>. Esimerkiksi, jos meillä on funktio <span class="arithmatex">\(f(x, y) = x^2 + 3y^2\)</span>, osittaisderivaatat <span class="arithmatex">\(x\)</span> ja <span class="arithmatex">\(y\)</span> suhteen ovat:</p>
<div class="arithmatex">\[
\frac{\partial f}{\partial x} = 2x
\]</div>
<div class="arithmatex">\[
\frac{\partial f}{\partial y} = 6y
\]</div>
<p>Eli, jos <span class="arithmatex">\(x\)</span>:ää kasvatetaan yhdellä yksiköllä, <span class="arithmatex">\(f\)</span>:n arvo kasvaa kahden yksikön verran, kun taas <span class="arithmatex">\(y\)</span>:n kasvattaminen yhdellä yksiköllä kasvattaa <span class="arithmatex">\(f\)</span>:n arvoa kuudella yksiköllä.</p>
<h3 id="gradientti">Gradientti</h3>
<p>Gradientti on hyvin yksinkertainen käsite: se on kokoelma kaikista osittaisderivaattoista. Toisin sanoen, gradientti kertoo, kuinka paljon funktion arvo muuttuu, kun kukin muuttuja muuttuu hieman <sup id="fnref2:essentialmath"><a class="footnote-ref" href="#fn:essentialmath">2</a></sup>. Edellisen esimerkin funktiolle <span class="arithmatex">\(f(x, y) = x^2 + 3y^2\)</span>, gradientti on:</p>
<div class="arithmatex">\[
\nabla f = \left( \frac{\partial f}{\partial x}, \frac
{\partial f}{\partial y} \right) = (2x, 6y)
\]</div>
<p>Käytännössä gradientti voi olla siis muotoa:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="c1"># Gradient of Loss w.r.t. W</span>
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a><span class="n">grad_W</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a><span class="c1">#   [[   w00,    w01,   w02 ],</span>
</span><span id="__span-1-4"><a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a><span class="c1">#    [   w10,    w11,   w12 ]]</span>
</span><span id="__span-1-5"><a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a>    <span class="p">[[</span><span class="mf">0.0980</span><span class="p">,</span> <span class="mf">0.1960</span><span class="p">,</span> <span class="mf">0.2940</span><span class="p">],</span>
</span><span id="__span-1-6"><a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a>     <span class="p">[</span><span class="mf">0.1078</span><span class="p">,</span> <span class="mf">0.2156</span><span class="p">,</span> <span class="mf">0.3234</span><span class="p">]]</span>
</span><span id="__span-1-7"><a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a><span class="p">)</span>
</span></code></pre></div>
<p>Tässä esimerkissä gradientti on 2x3-matriisi, jossa jokainen alkio edustaa osittaisderivaattaa vastaavalle painolle neuroverkossa. Selvyyden vuoksi näytetään tämä <code>3-2-?-...-?</code> arkkitehtuuri Mermaid-kaaviona:</p>
<pre class="mermaid"><code>graph LR
    subgraph Input Layer
        x1((x1))
        x2((x2))
        x3((x3))
    end
    subgraph Hidden Layer
        h1((h1))
        h2((h2))
    end
    rest[... rest of the network]
    x1 --&gt;|w00| h1
    x2 --&gt;|w01| h1
    x3 --&gt;|w02| h1
    x1 --&gt;|w10| h2
    x2 --&gt;|w11| h2
    x3 --&gt;|w12| h2
    h1 --&gt; rest
    h2 --&gt; rest</code></pre>
<h2 id="backpropagation">Backpropagation</h2>
<h3 id="paperilla">Paperilla</h3>
<p>Johdatus koneoppimiseen -kurssilla gradientin laskeminen oli kovin helppoa, koska logistinen regressio on yksinkertainen lineaarinen malli (jolla on logistinen funktio perässä). Neuroverkoissa meillä on monta funktiota. Jos pelkästään yllä olevan Mermaid-kaavion verkon osalta meillä on seuraavanlainen laskukaava:</p>
<div class="arithmatex">\[
\begin{aligned}
z_1 &amp;= w_{00} \cdot x_1 + w_{01} \cdot x_2 + w_{02} \cdot x_3 + b_0 \\
z_2 &amp;= w_{10} \cdot x_1 + w_{11} \cdot x_2 + w_{12} \cdot x_3 + b_1 \\
h_1 &amp;= \sigma(z_1) \\
h_2 &amp;= \sigma(z_2)
\end{aligned}
\]</div>
<p>Yllä olevassa kaavassa <span class="arithmatex">\(\sigma\)</span> on aktivointifunktio, esimerkiksi sigmoid tai ReLU. Tällöin, kun haluamme laskea gradientin <span class="arithmatex">\(w_{00}\)</span> suhteen, meidän täytyy käyttää ketjusääntöä, koska <span class="arithmatex">\(w_{00}\)</span> vaikuttaa lopulliseen häviöön (loss) monen välikerroksen kautta. Watson ja Chollet kirjoittavatkin, että: </p>
<blockquote>
<p>"Backpropagation is simply the application of the chain rule to a computation graph. There’s nothing more to it." <sup id="fnref:dlwithpython"><a class="footnote-ref" href="#fn:dlwithpython">3</a></sup></p>
</blockquote>
<p>Ketjusäännön avulla voimme purkaa monimutkaisen funktion osittaisderivaatat yksinkertaisemmiksi osittaisderivaattojen kertolaskuiksi. Jos meillä on funktio <span class="arithmatex">\(f(g(x))\)</span>, ketjusäännön mukaan sen derivaatta on: <span class="arithmatex">\(\frac{df}{dx} = \frac{df}{dg} \cdot \frac{dg}{dx}\)</span>. Mikäli et muista matematiikan tunneista mitään, kannattaa kerrata ketjusääntö kun kirjoitat oppimispäiväkirjaasi. Tehtävissä on annettu hyödyllisiä lähteitä, joista löydät lisätietoa.</p>
<p>Tämän viikon jälkeen sinulle pitäisi olla vahva ymmärrys siitä, mitä tapahtuu seuraavissa riveissä:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a>    <span class="c1"># ...</span>
</span><span id="__span-2-3"><a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a>    <span class="n">loss</span> <span class="o">=</span> <span class="n">some_loss_function</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</span><span id="__span-2-4"><a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a>    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>  <span class="c1"># &lt;-- Tässä tapahtuu backpropagation</span>
</span><span id="__span-2-5"><a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a>    <span class="c1"># ...</span>
</span></code></pre></div>
<p>Jos/kun lasket backpropagationin oppimissyistä käsin, ainakin kerran elämässäsi, ymmärrät paremmin, mitä <code>loss.backward()</code> tekee. Käytännössä tähän löytyy ainakin kaksi erilaista keinoa. Esittelen ne lyhyesti alla, ja myöhemmin tutustut näihin tehtävien kautta.</p>
<h4 id="keino-1-ensin-lokaalit-ja-sitten-kertolasku">Keino 1: Ensin lokaalit ja sitten kertolasku</h4>
<p>Tämä on se keino, johon törmäät esimerkiksi Tamer Elsayedin videolla: <a href="https://youtu.be/NHWP339RnAs?si=Wy8Uh25-MuWNyWOT&amp;t=1496">Lecture 12 | Backpropagation I | CMPS 497 Deep Learning | Fall 2024 (alkaen ajasta 24:56)</a>. Toimintatapa on seuraava:</p>
<ol>
<li>Tee ensin forward pass ja tallenna kaikki väliarvot.</li>
<li>Laske kunkin muuttujan lokaali derivaatta sen syötteiden suhteen (esim. tulosääntöä hyödyntäen).</li>
<li>Kun tämä on valmis, ja haluat tietää vaikkapa painon <span class="arithmatex">\(w_{00}\)</span> vaikutuksen lopulliseen häviöön (loss), etsi kaikki polut, jotka yhdistävät <span class="arithmatex">\(w_{00}\)</span> lopulliseen häviöön. Kerro ne yhteen.</li>
</ol>
<p>Huomaa, että kohdan 2 voi tehdä käytännössä <mark>missä tahansa järjestyksessä</mark>, kunhan kaikki tarvittavat lokaalit derivaatit on laskettu.</p>
<h4 id="keino-2-lopusta-vaiheittain-alkuun">Keino 2: Lopusta vaiheittain alkuun</h4>
<p>Tämä on se keino, kuinka backpropagation esitellään usein ohjelmoinnin yhteydessä kirjallisuudessa. Esimerkiksi Matt Mazurin blogissa: <a href="https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/">A Step by Step Backpropagation Example</a>. Tämä on loogista, koska virhe <em>propagoituu</em> verkossa taaksepäin. Välivaiheissa tallennetut layerin gradientteja voidaan nimittää <em>deltoiksi</em>. Toteutuksemme laskee kunkin kerroksen virheen eli "deltan" (<span class="arithmatex">\(dZ\)</span>). Tätä virhettä käytetään laskemaan painojen gradientit (<span class="arithmatex">\(dW\)</span> ja <span class="arithmatex">\(db\)</span>).</p>
<ol>
<li>Tee ensin forward pass ja tallenna kaikki väliarvot (aktivoinnit <span class="arithmatex">\(A\)</span>)</li>
<li>Käsittele lähtötason virhe (<span class="arithmatex">\(dZ_{out}\)</span>) virhe.</li>
<li>Laske tämän kerroksen <strong>painojen gradientit</strong> (<span class="arithmatex">\(dW\)</span>) <em>(hyödyntäen virhettä ja edellisen tason syötettä)</em></li>
<li>Laske <strong>edellisen kerroksen virhe</strong> siirtämällä nykyinen virhe painojen läpi taaksepäin (<span class="arithmatex">\(dZ_{prev}\)</span>)</li>
<li>Toista vaiheet 3 ja 4, kunnes kaikki kerrokset on käsitelty.</li>
</ol>
<p>Huomaa, että tämä on pakko tehdä <mark>järjestyksessä lopusta alkuun</mark>, koska jokainen kerros tarvitsee edellisen kerroksen gradientin.</p>
<p>Itse operaatio näyttää meidän viime viikon <code>NumpyNNwithBCE</code>-mallissamme tältä:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a>    <span class="c1"># === Lähtökerros (Layer 2) ===</span>
</span><span id="__span-3-3"><a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a>    <span class="c1"># 1. Laske virhe (dZ2)</span>
</span><span id="__span-3-4"><a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">dZ2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">A2</span> <span class="o">-</span> <span class="n">target</span>  <span class="c1"># (1)!</span>
</span><span id="__span-3-5"><a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a>
</span><span id="__span-3-6"><a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a>    <span class="c1"># 2. Laske gradientit painoille (dW2, db2)</span>
</span><span id="__span-3-7"><a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a>    <span class="c1"># Nämä tallennetaan, jotta optimize() voi käyttää niitä</span>
</span><span id="__span-3-8"><a id="__codelineno-3-8" name="__codelineno-3-8" href="#__codelineno-3-8"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">dW2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">A1</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dZ2</span><span class="p">)</span>  <span class="c1"># (2)!</span>
</span><span id="__span-3-9"><a id="__codelineno-3-9" name="__codelineno-3-9" href="#__codelineno-3-9"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">db2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dZ2</span>  <span class="c1"># (3)!</span>
</span><span id="__span-3-10"><a id="__codelineno-3-10" name="__codelineno-3-10" href="#__codelineno-3-10"></a>
</span><span id="__span-3-11"><a id="__codelineno-3-11" name="__codelineno-3-11" href="#__codelineno-3-11"></a>    <span class="c1"># === Piilotettu kerros (Layer 1) ===</span>
</span><span id="__span-3-12"><a id="__codelineno-3-12" name="__codelineno-3-12" href="#__codelineno-3-12"></a>    <span class="c1"># 3. Propagoi virhe taaksepäin (dZ1)</span>
</span><span id="__span-3-13"><a id="__codelineno-3-13" name="__codelineno-3-13" href="#__codelineno-3-13"></a>    <span class="n">dA1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dZ2</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W2</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>  <span class="c1"># (4)!</span>
</span><span id="__span-3-14"><a id="__codelineno-3-14" name="__codelineno-3-14" href="#__codelineno-3-14"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">dZ1</span> <span class="o">=</span> <span class="n">dA1</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid_derivative</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A1</span><span class="p">)</span>  <span class="c1"># (5)!</span>
</span><span id="__span-3-15"><a id="__codelineno-3-15" name="__codelineno-3-15" href="#__codelineno-3-15"></a>
</span><span id="__span-3-16"><a id="__codelineno-3-16" name="__codelineno-3-16" href="#__codelineno-3-16"></a>    <span class="c1"># 4. Laske gradientit painoille (dW1, db1)</span>
</span><span id="__span-3-17"><a id="__codelineno-3-17" name="__codelineno-3-17" href="#__codelineno-3-17"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">dW1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">A0</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dZ1</span><span class="p">)</span>  <span class="c1"># (6)!</span>
</span><span id="__span-3-18"><a id="__codelineno-3-18" name="__codelineno-3-18" href="#__codelineno-3-18"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">db1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dZ1</span>  <span class="c1"># (7)!</span>
</span></code></pre></div>
<ol>
<li>
<p><strong>dZ2</strong> eli <strong>delta</strong> (δ²) on lähtökerroksen derivaatta. Binary cross-entropy + sigmoid -yhdistelmällä tämä yksinkertaistuu muotoon <code>ennuste - todellinen</code>. Tämä on gradientti häviön suhteen pre-aktivaatioon Z².</p>
</li>
<li>
<p><strong>dW2</strong> on gradientti lähtökerroksen painoille W². Lasketaan kertomalla edellisen kerroksen aktivaatiot (A¹) nykyisen kerroksen virheellä (dZ²). Käytännössä tässä on tulosääntö.</p>
</li>
<li>
<p><strong>db2</strong> on gradientti lähtökerroksen biaseille b². Bias-gradientti on yksinkertaisesti sama kuin virhe (dZ²), koska biasin derivaatta on 1.</p>
</li>
<li>
<p><strong>dA1</strong> on gradientti piilotetun kerroksen aktivaatioiden suhteen. Propagoidaan virhe taaksepäin kertomalla nykyisen kerroksen virhe (dZ²) nykyisen kerroksen painojen (W².T) kanssa. Tämä on tulosäännön toinen puolisko (vrt. dW² lasku yllä).</p>
</li>
<li>
<p><strong>dZ1</strong> eli <strong>delta</strong> (δ¹) on piilotetun kerroksen virhe. Lasketaan kertomalla propagoitu aktivaatiovirhe (dA¹) sigmoidin derivaatalla pisteessä A¹. Tämä on ketjusäännön sovellus!</p>
</li>
<li>
<p><strong>dW1</strong> on gradientti piilotetun kerroksen painoille W¹. Lasketaan samalla tavalla kuin dW2.</p>
</li>
<li>
<p><strong>db1</strong> on gradientti piilotetun kerroksen biaseille b¹. Lasketaan samalla tavalla kuin db2.</p>
</li>
</ol>
<p><img alt="" src="../../images/300_NumpyNNwithBCE.png" /></p>
<p><strong>Kuva 1</strong>: <em>Malli <code>NumpyNNwithBCE</code> Excalidraw-piirroksena. Ylemmässä kuvion puoliskossa on avattuna piilotetut kerrokset siten, että neuroni on purettu Z- ja A-osiin eli esiaktivoituun ja sigmoid-muunnettuun. Alemmassa kuviossa on tuttu esitys 2-2-1 verkosta siten, että biasit on piilotettu. Huomaa, että <code>X == A0</code>.</em></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Yllä olevassa koodiesimerkissä, kuten muutenkin NumpyNN:n suhteen, on oletus, että meillä on stokastinen gradientti, jossa batch size on tasan 1. Muuten dB2 ja dB1 pitäisi laskea ottamalla keskiarvo rivien yli (esim. <code>np.sum(self.dZ2, axis=0) / m</code>, missä m on batch size).</p>
</div>
<p>Tutustu yllä olevan koodiblokin annotointeihin; tunnistat ne pienestä plussamerkistä, josta aukeaa lisätietoa. Huomaa, että jos piilotettuja kerroksia olisi useita, prosessi alkaisi näyttää tältä:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
</span><span id="__span-4-2"><a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a>        <span class="c1"># === Lähtökerros ===</span>
</span><span id="__span-4-3"><a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dZ5</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">A5</span> <span class="o">-</span> <span class="n">target</span>
</span><span id="__span-4-4"><a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dW5</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">A4</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dZ5</span><span class="p">)</span> <span class="c1"># Gradientti W5:lle</span>
</span><span id="__span-4-5"><a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a>
</span><span id="__span-4-6"><a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a>        <span class="c1"># === Piilotetut kerrokset ===</span>
</span><span id="__span-4-7"><a id="__codelineno-4-7" name="__codelineno-4-7" href="#__codelineno-4-7"></a>        <span class="c1"># Layer 4</span>
</span><span id="__span-4-8"><a id="__codelineno-4-8" name="__codelineno-4-8" href="#__codelineno-4-8"></a>        <span class="n">dA4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dZ5</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W5</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</span><span id="__span-4-9"><a id="__codelineno-4-9" name="__codelineno-4-9" href="#__codelineno-4-9"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dZ4</span> <span class="o">=</span> <span class="n">dA4</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid_derivative</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A4</span><span class="p">)</span>
</span><span id="__span-4-10"><a id="__codelineno-4-10" name="__codelineno-4-10" href="#__codelineno-4-10"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dW4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">A3</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dZ4</span><span class="p">)</span> <span class="c1"># Gradientti W4:lle</span>
</span><span id="__span-4-11"><a id="__codelineno-4-11" name="__codelineno-4-11" href="#__codelineno-4-11"></a>
</span><span id="__span-4-12"><a id="__codelineno-4-12" name="__codelineno-4-12" href="#__codelineno-4-12"></a>        <span class="c1"># Layer 3</span>
</span><span id="__span-4-13"><a id="__codelineno-4-13" name="__codelineno-4-13" href="#__codelineno-4-13"></a>        <span class="n">dA3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dZ4</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W4</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</span><span id="__span-4-14"><a id="__codelineno-4-14" name="__codelineno-4-14" href="#__codelineno-4-14"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dZ3</span> <span class="o">=</span> <span class="n">dA3</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid_derivative</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A3</span><span class="p">)</span>
</span><span id="__span-4-15"><a id="__codelineno-4-15" name="__codelineno-4-15" href="#__codelineno-4-15"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dW3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">A2</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dZ3</span><span class="p">)</span> <span class="c1"># Gradientti W3:lle</span>
</span><span id="__span-4-16"><a id="__codelineno-4-16" name="__codelineno-4-16" href="#__codelineno-4-16"></a>
</span><span id="__span-4-17"><a id="__codelineno-4-17" name="__codelineno-4-17" href="#__codelineno-4-17"></a>        <span class="c1"># Layer 2</span>
</span><span id="__span-4-18"><a id="__codelineno-4-18" name="__codelineno-4-18" href="#__codelineno-4-18"></a>        <span class="n">dA2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dZ3</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W3</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</span><span id="__span-4-19"><a id="__codelineno-4-19" name="__codelineno-4-19" href="#__codelineno-4-19"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dZ2</span> <span class="o">=</span> <span class="n">dA2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid_derivative</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A2</span><span class="p">)</span>
</span><span id="__span-4-20"><a id="__codelineno-4-20" name="__codelineno-4-20" href="#__codelineno-4-20"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dW2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">A1</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dZ2</span><span class="p">)</span> <span class="c1"># Gradientti W2:lle</span>
</span><span id="__span-4-21"><a id="__codelineno-4-21" name="__codelineno-4-21" href="#__codelineno-4-21"></a>
</span><span id="__span-4-22"><a id="__codelineno-4-22" name="__codelineno-4-22" href="#__codelineno-4-22"></a>        <span class="c1"># Layer 1</span>
</span><span id="__span-4-23"><a id="__codelineno-4-23" name="__codelineno-4-23" href="#__codelineno-4-23"></a>        <span class="n">dA1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dZ2</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W2</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</span><span id="__span-4-24"><a id="__codelineno-4-24" name="__codelineno-4-24" href="#__codelineno-4-24"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dZ1</span> <span class="o">=</span> <span class="n">dA1</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid_derivative</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A1</span><span class="p">)</span>
</span><span id="__span-4-25"><a id="__codelineno-4-25" name="__codelineno-4-25" href="#__codelineno-4-25"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dW1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">A0</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dZ1</span><span class="p">)</span> <span class="c1"># Gradientti W1:lle</span>
</span></code></pre></div>
<p>Jos tämän haluaa kirjoittaa dynaamisesti useammalle piilotetulle kerrokselle, täytyy käyttää silmukkaa. Tällöin eri kerrokset, kuten myös aktivoinnit, kannattaisi tallentaa listoiksi. Seuraava koodiblokki mukailee Adrian Rosebrockin kirjan luvun 10 esimerkkiä <sup id="fnref:dl4cv"><a class="footnote-ref" href="#fn:dl4cv">4</a></sup>. Esimerkissä käytetään yleistä ketjusääntöä, joka lasketaan myös lähtökerrokselle (output layer). Huomaa, että <code>output_delta</code> sisältää myös aktivaatiofunktion derivaatan. Tämä tarvitaan, koska käytössä on MSE-virhefunktio – aiemmassa BCE-esimerkissä tätä vaihetta ei tarvittu Sigmoid+BCE-yhdistelmän vuoksi. Termillä <em>delta</em> viitataan esiaktivaation virheeseen, joka on siis <span class="arithmatex">\(dZ^n\)</span>-termi.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">backprop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a>        <span class="c1"># Tee forward pass ja tallenna kaikki aktivoinnit</span>
</span><span id="__span-5-3"><a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a>        <span class="n">activations</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="__span-5-4"><a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a>
</span><span id="__span-5-5"><a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a>        <span class="c1"># 1. Laske lähtötason virhe (output layer)</span>
</span><span id="__span-5-6"><a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a>        <span class="n">output_error</span> <span class="o">=</span> <span class="n">activations</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">y</span>
</span><span id="__span-5-7"><a id="__codelineno-5-7" name="__codelineno-5-7" href="#__codelineno-5-7"></a>        <span class="n">output_delta</span> <span class="o">=</span> <span class="n">output_error</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid_deriv</span><span class="p">(</span><span class="n">activations</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span><span id="__span-5-8"><a id="__codelineno-5-8" name="__codelineno-5-8" href="#__codelineno-5-8"></a>
</span><span id="__span-5-9"><a id="__codelineno-5-9" name="__codelineno-5-9" href="#__codelineno-5-9"></a>        <span class="c1"># Deltat tulevat pinoutumaan tähän listaan</span>
</span><span id="__span-5-10"><a id="__codelineno-5-10" name="__codelineno-5-10" href="#__codelineno-5-10"></a>        <span class="n">deltas</span> <span class="o">=</span> <span class="p">[</span><span class="n">output_delta</span><span class="p">]</span>
</span><span id="__span-5-11"><a id="__codelineno-5-11" name="__codelineno-5-11" href="#__codelineno-5-11"></a>
</span><span id="__span-5-12"><a id="__codelineno-5-12" name="__codelineno-5-12" href="#__codelineno-5-12"></a>        <span class="c1"># 2. Propagoi gradientti taaksepäin kerros kerrokselta</span>
</span><span id="__span-5-13"><a id="__codelineno-5-13" name="__codelineno-5-13" href="#__codelineno-5-13"></a>        <span class="k">for</span> <span class="n">layer_idx</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">activations</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
</span><span id="__span-5-14"><a id="__codelineno-5-14" name="__codelineno-5-14" href="#__codelineno-5-14"></a>
</span><span id="__span-5-15"><a id="__codelineno-5-15" name="__codelineno-5-15" href="#__codelineno-5-15"></a>            <span class="c1"># hyödynnetään edellisen kerroksen deltaa (pinon päältä)</span>
</span><span id="__span-5-16"><a id="__codelineno-5-16" name="__codelineno-5-16" href="#__codelineno-5-16"></a>            <span class="n">this_delta</span> <span class="o">=</span> <span class="n">deltas</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="n">layer_idx</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</span><span id="__span-5-17"><a id="__codelineno-5-17" name="__codelineno-5-17" href="#__codelineno-5-17"></a>
</span><span id="__span-5-18"><a id="__codelineno-5-18" name="__codelineno-5-18" href="#__codelineno-5-18"></a>            <span class="c1"># sigmoid ketjusäännöllä mukaan</span>
</span><span id="__span-5-19"><a id="__codelineno-5-19" name="__codelineno-5-19" href="#__codelineno-5-19"></a>            <span class="n">this_delta</span> <span class="o">=</span> <span class="n">this_delta</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid_deriv</span><span class="p">(</span><span class="n">activations</span><span class="p">[</span><span class="n">layer_idx</span><span class="p">])</span>
</span><span id="__span-5-20"><a id="__codelineno-5-20" name="__codelineno-5-20" href="#__codelineno-5-20"></a>
</span><span id="__span-5-21"><a id="__codelineno-5-21" name="__codelineno-5-21" href="#__codelineno-5-21"></a>            <span class="c1"># lisää tämä delta pinon päälle</span>
</span><span id="__span-5-22"><a id="__codelineno-5-22" name="__codelineno-5-22" href="#__codelineno-5-22"></a>            <span class="n">deltas</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">this_delta</span><span class="p">)</span>
</span><span id="__span-5-23"><a id="__codelineno-5-23" name="__codelineno-5-23" href="#__codelineno-5-23"></a>
</span><span id="__span-5-24"><a id="__codelineno-5-24" name="__codelineno-5-24" href="#__codelineno-5-24"></a>        <span class="c1"># 3. Käännä deltalista oikeaan järjestykseen. </span>
</span><span id="__span-5-25"><a id="__codelineno-5-25" name="__codelineno-5-25" href="#__codelineno-5-25"></a>        <span class="c1"># Nyt niitä voi käyttää painojen päivittämiseen optimointialgoritmissa</span>
</span><span id="__span-5-26"><a id="__codelineno-5-26" name="__codelineno-5-26" href="#__codelineno-5-26"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">deltas</span> <span class="o">=</span> <span class="n">deltas</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span></code></pre></div>
<p>Huomaa, että Rosebrockin koodi poikkeaa meidän esimerkistä siten, että se laskee tässä vaiheessa ainoastaan kerrosten virhetermit eli deltat (<span class="arithmatex">\(dZ^n\)</span>), mutta ei vielä varsinaisia painojen gradientteja (<span class="arithmatex">\(dW^n\)</span>).</p>
<p>Meidän NumpyNNwithBCE-toteutuksessamme laskimme backward-metodissa valmiiksi myös gradientit (esim. self.dW2 = ...), jotta rakenne vastaisi täysin PyTorchin tapaa tallentaa gradientit .grad-muuttujaan. Rosebrockin esimerkissä gradienttien laskeminen (eli aktivaatioiden ja deltojen välinen matriisitulo) on jätetty tehtäväksi vasta myöhemmin, varsinaisen painojen päivityksen yhteyteen.</p>
<div class="admonition note">
<p class="admonition-title">Bias?</p>
<p>Entäpä bias-termit? Kun meillä on selkeä Dense-verkko (fully connected), bias-termit voidaan käsitellä muiden painojen joukossa. Tämä onnistuu yksinkertaisesti lisäämällä syötevektoriin ylimääräinen arvo, joka on aina 1. Olet tehnyt tämän jo aiemmin Johdatus koneoppimiseen -kurssilla. Rosebrock kutsuu tätä <em>bias trick</em>-menetelmäksi, ja hoitaa sen näin <code>fit()</code>-metodissaan <sup id="fnref2:dl4cv"><a class="footnote-ref" href="#fn:dl4cv">4</a></sup>:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">X</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))]</span>
</span></code></pre></div>
<p>Minun koodiesimerkeissäni bias-termit on käsitelty erikseen, jotta koodi olisi selkeämpää oppimisen kannalta, ja kenties täsmäisi paremmin PyTorchin tapaan.</p>
</div>
<h3 id="pytorchissa">PyTorchissa</h3>
<p>Tätä kannattaa harjoitella itsenäisesti PyTorchin avulla. Alla on kuitenkin yksinkertainen esimerkki siitä, kuinka simppeli funktio ja sen derivointi onnistuu. Tavoitteenamme on funktio:</p>
<div class="arithmatex">\[
f = \frac{1}{n} \sum_{i,j} x_{ij}^2
\]</div>
<p>Tämän voi derivoida muotoon <code>1/n * 2x</code>. Kun <code>n = 4</code>, niin saamme:</p>
<div class="arithmatex">\[
\nabla f = \frac{X}{2}
\]</div>
<p>Tehdään sama PyTorchissa.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span>
</span><span id="__span-7-2"><a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a>    <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
</span><span id="__span-7-3"><a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a>    <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">]</span>
</span><span id="__span-7-4"><a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># &lt;- hox!</span>
</span><span id="__span-7-5"><a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a>
</span><span id="__span-7-6"><a id="__codelineno-7-6" name="__codelineno-7-6" href="#__codelineno-7-6"></a><span class="c1"># Pow</span>
</span><span id="__span-7-7"><a id="__codelineno-7-7" name="__codelineno-7-7" href="#__codelineno-7-7"></a><span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span>
</span><span id="__span-7-8"><a id="__codelineno-7-8" name="__codelineno-7-8" href="#__codelineno-7-8"></a>
</span><span id="__span-7-9"><a id="__codelineno-7-9" name="__codelineno-7-9" href="#__codelineno-7-9"></a><span class="c1"># 1/n * y</span>
</span><span id="__span-7-10"><a id="__codelineno-7-10" name="__codelineno-7-10" href="#__codelineno-7-10"></a><span class="n">f</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</span></code></pre></div>
<p>Tässä vaiheessa <code>f</code> on skaalari arvolstaan <code>0.0750</code>. Jos tässä vaiheessa tulostat eri arvoja, tulet huomaamaan, että <code>x.grad==None</code>, koska emme ole vielä tehneet takaisinvirtausta. Sen sijaan <code>y.grad_fn</code> ja <code>f.grad_fn</code> kertovat, miten nämä arvot on laskettu: ne sisältävät arvot <code>&lt;PowBackward0&gt;</code> ja <code>&lt;MeanBackward0&gt;</code>, jotka viittaavat <code>y</code>- ja <code>f</code>-muuttujien laskentaan. Nyt voimme kutsua takaisinvirtausta, mikä antaa <code>x.grad</code>-muuttujaan halutun gradientin:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-8-1"><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a><span class="n">f</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</span></code></pre></div>
<p>Jatkossa <code>x.grad</code> sisältää gradientin <code>f</code> suhteen <code>x</code>:ään. Tulostamalla <code>x.grad</code> saamme:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-9-1"><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a>tensor([[0.0500, 0.1000],
</span><span id="__span-9-2"><a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a>        [0.1500, 0.2000]])
</span></code></pre></div>
<h3 id="autograd">Autograd</h3>
<p>Käytännössä backpropagation on toteutettu syväoppimiskirjastoissa siten, että sinun ei tarvitse kirjoittaa backpropagation-koodia itse muuta kuin opiskelusyistä. Kukin Tensor huolehtii itseensä kohdistuneista operaatioista. PyTorch:n oma dokumentaatio esittelee sitä kattavasti, joten kannattaa tutustua, jos aihe kiinnostaa: <a href="https://docs.pytorch.org/docs/stable/autograd.html">Automatic differentiation package - torch.autograd</a>. Etsi sivulta sanaa <code>grad_fn</code>. Kun esimerkiksi teet tensorioperaation <code>y = a * b</code>, PyTorch kiinnittää tensoriin <code>grad_fn=&lt;MulBackward0&gt;</code>:n. Kun myöhemmin kutsut <code>y.backward()</code>, PyTorch käyttää tätä tietoa laskeakseen gradientit <code>a</code> ja <code>b</code> suhteen. Tässä tapauksessa kyseessä olisi kertolaskuun pätevä sääntö eli <span class="arithmatex">\(\frac{d}{da}(a \cdot b) = b\)</span> ja <span class="arithmatex">\(\frac{d}{db}(a \cdot b) = a\)</span>.</p>
<p>Kun tämä tehdään koko <code>loss.backward()</code>-kutsun yhteydessä, PyTorch kävelee taaksepäin koko laskentaverkon läpi, käyttäen ketjusääntöä laskeakseen gradientit kaikille verkon parametreille. Tämä on siis juuri se, mitä backpropagation tekee.</p>
<p>Jotta takaisinvirtaus (backpropagation) on mahdollista, verkon täytyy täyttää joitakin kriteereitä:</p>
<ol>
<li>
<p><strong>Derivoitavuus</strong>. Verkon kaikkien osien tulee olla derivoituvia. ReLU ei ole derivoitava pisteessä 0, mutta siitä käytännössä tehdään sellainen subgradientin avulla (lue: fancy tapa sanoa, että <code>if (x == 0): return 0</code>). Alkuperäisen Perceptronin askelfunktio ei ole derivoituva, joten se ei sovellu vastavirta-algoritmin käyttöön. <sup id="fnref:geronpytorch"><a class="footnote-ref" href="#fn:geronpytorch">5</a></sup> Diskeetit ehtolauseet ja satunnaisuus eivät ole myöskään derivoitavia.</p>
</li>
<li>
<p><strong>Asyklinen laskentagraafi (DAG)</strong>. Laskennan täytyy muodostaa suunnattu asyklinen verkko. Jos verkossa on silmukoita (esim. RNN), ne "avataan auki" (unrolling), jotta backpropagation voidaan toteuttaa <sup id="fnref2:geronpytorch"><a class="footnote-ref" href="#fn:geronpytorch">5</a></sup>.</p>
</li>
</ol>
<div class="admonition info">
<p class="admonition-title">Monimutkaisemmat arkkitehtuurit</p>
<p>Yllä esitelty delta-sääntö ja backward-metodin toteutus toimii suoraviivaisesti tavallisissa, eteenpäin suunnatuissa neuroverkoissa (engl. feedforward, fully connected, dense), joissa jokainen neuroni on yhteydessä jokaiseen edellisen kerroksen neuroniin. Monimutkaisemmissa arkkitehtuureissa, kuten <strong>konvoluutioverkoissa (CNN)</strong>, gradienttien laskeminen on huomattavasti monimutkaisempaa.</p>
<p>Onneksi autograd hoitaa kaiken tämän puolestamme!</p>
</div>
<h2 id="tehtavat">Tehtävät</h2>
<div class="admonition warning">
<p class="admonition-title">Älä panikoi!</p>
<p>Tehtävät ovat tämän kurssin teoreettisin ja mahdollisesti eniten päänvaivaa aiheuttava osio. Suhteuta aiheeseen sukeltaminen omiin voimavaroihisi: jos opettajan kirjoittamat Marimo Notebookit osoittautuvat voittamattomiksi, keskity esimerkiksi StatQuestin videoihin ja intuitiotasoon.</p>
<p>Lopulta tärkeintä on, että ymmärrät perusidean backpropagationista ja osaat käyttää sitä syväoppimiskirjastoissa, kuten PyTorchissa. Muista, että haluat vältellä olemasta tämä henkilö:</p>
<blockquote>
<p>"Mitä osaat kertoa algoritmista nimeltään <em>backpropagation</em>?" <br>
— "Öööh, taisin käyttää sitä yhdessä projektissa, vissiin."</p>
</blockquote>
</div>
<div class="admonition question">
<p class="admonition-title">Tehtävä: Takaisinvirtaus intuition tasolla</p>
<p>Aloita tutustumalla sekä minun materiaaliin että internetistä löytyvään, intuitiotasoa korostavaan sisältöön. Hyviä lähteitä ovat ainakin:</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=Ilg3gGewQ5U">3Blue1Brown video: Backpropagation, intuitively | Deep Learning Chapter 3</a> (12 min)</li>
<li><a href="https://youtu.be/IN2XmBhILt4">StatQuest: Neural Networks Pt. 2: Backpropagation Main Ideas</a> (17 min)</li>
<li>Jos sinulla on pääsy Manningin kirjaan <em>Deep Learning with Python, Third Edition</em> (2025), tutustu lukuun 2.4 <em>"The engine of neural networks: Gradient-based optimization"</em> <sup id="fnref2:dlwithpython"><a class="footnote-ref" href="#fn:dlwithpython">3</a></sup>.</li>
<li><a href="https://youtu.be/i94OvYb6noo">Karpathy: CS231n Winter 2016: Lecture 4: Backpropagation, Neural Networks 1</a>. OpenAI:n yksi perustaja, alalla hyvinkin tunnettu Andrej Karpathy käy Stanfordin luennolla läpi vastavirta-algoritmin. (1 h 20 min)</li>
</ul>
</div>
<div class="admonition question">
<p class="admonition-title">Tehtävä: Lopusta vaiheittain alkuun</p>
<p>Olet aiemmin nähnyt backpropagation-algoritmin tehdyn käsin <code>NumpyNNwithBCE</code>-mallissamme, ja tähän viitattiin myös tässä luentomateriaalissa. Tutustu nyt <code>300_numpy_to_pytorch_pt2.py</code>-Notebookiin, jossa tehdään syväluotausta aiemmin nähdyn koodin <code>backward</code>-metodin toiminnasta. Tässä Notebookissa käytetään <strong>"Lopusta vaiheittain alkuun" -menetelmää</strong>.</p>
<p>Notebookin rinnalla on hyvä tutustua myös Matt Mazurin versioon: <a href="https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/">A Step by Step Backpropagation Example</a>. Jos haluat todellisen syväluotauksen aiheeseen, katso University of Michiganin Justin Johnsonin luento: <a href="https://youtu.be/dB-u77Y5a6A?si=O2s-NbdM2HnKA2UT">Lecture 6: Backpropagation</a>. Aihetta käsitellään myös kurssilla aiemmin mainitussa <a href="https://udlbook.github.io/udlbook/">Understanding Deep Learning e-kirjassa</a>.</p>
<p>Voit hyödyntää sitä muistiinpanojen tekemiseen oppimispäiväkirjaasi.</p>
</div>
<div class="admonition question">
<p class="admonition-title">Tehtävä: PyTorch Learn the Basics: Automatic Differentiation with torch.autograd</p>
<p>Tutustu <code>301_autogradqs_tutorial.py</code>-tiedostossa olevaan, Marimo-formaattiin käännettyyn PyTorchin tutoriaaliin. Alkuperäinen löytyy tästä osoitteesta: <a href="https://docs.pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html">Automatic Differentiation with torch.autograd</a></p>
</div>
<div class="admonition question">
<p class="admonition-title">Tehtävä: Ensin lokaalit ja sitten kertolasku</p>
<p>Tutustu <code>302_backpropagation.py</code>-Notebookiin, jossa tehdään syväluotausta backpropagationin toiminnasta <strong>"Ensin lokaalit ja sitten kertolasku" -menetelmällä</strong>. Notebookin rinnalla on hyvä tutustua myös Tamer Elsayedin luentoon: <a href="https://youtu.be/NHWP339RnAs?t=1496">Lecture 12 | Backpropagation I | CMPS 497 Deep Learning | Fall 2024 (alkaen ajasta 24:56)</a>, jossa hän käy läpi Understanding Deep Learning -kirjan luvun 7 asioita nimenomaan tällä menetelmällä. Myös seuraava video, <a href="https://youtu.be/3pVRMPmqwhc?si=6wwVVLqQonQLjT-c">Lecture 13 | Backpropagation II | CMPS 497 Deep Learning | Fall 2024</a>, jatkaa vastavirran parissa.</p>
</div>
<div class="admonition question">
<p class="admonition-title">Tehtävä: Laskentaketju PyTorchissa</p>
<p>Tee yllä olevan <code>f = (1/n) * sum(x)</code> -esimerkin kaltainen laskentaketju PyTorchissa, jossa selvität muuttujien <span class="arithmatex">\(x\)</span>, <span class="arithmatex">\(y\)</span> ja <span class="arithmatex">\(z\)</span> gradientit. Funktion <span class="arithmatex">\(f\)</span> tulee noudattaa seuraavaa matemaattista funktioiden ketjua:</p>
<div class="arithmatex">\[
\begin{aligned}
a &amp;= x^3 \\
b &amp;= y^2 \\
c &amp;= a \odot b \quad \text{(elementwise-tulo)} \\
d &amp;= |\sin(\frac{c}{b})| \quad \text{(itseisarvo)} \\
e &amp;= \sqrt{\frac{d}{z}} \\
f &amp;= \frac{1}{n}\sum_i e_i \quad \text{(keskiarvo)}
\end{aligned}
\]</div>
<p>Voit joko aloittaa tyhjästä tai hyödyntää <code>303_chained_funcs.py</code>-Notebookin runkoa. Käytä näitä alkuarvoja, jotta voit tarkistaa laskelmat alla olevia tuloksia vasten:</p>
<ul>
<li><span class="arithmatex">\(x = [1.0, 2.0, 3.0]\)</span></li>
<li><span class="arithmatex">\(y = [0.5, 1.0, 1.5]\)</span></li>
<li><span class="arithmatex">\(z = 0.5\)</span></li>
</ul>
<p>Tunnistat oikeat tulokset seuraavista arvoista:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-10-1"><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a>f = 1.362325
</span><span id="__span-10-2"><a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a>x.grad = tensor([ 0.4165, -0.4137, -1.9011])
</span><span id="__span-10-3"><a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a>y.grad = tensor([0.0000e+00, 0.0000e+00, 1.7881e-07])
</span><span id="__span-10-4"><a id="__codelineno-10-4" name="__codelineno-10-4" href="#__codelineno-10-4"></a>z.grad = -1.362325
</span></code></pre></div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Muista pohtia, mitä gradientti oikeastaan tarkoittaa. Jos käärit toteutuksesi funktioon, joka ottaa <code>x</code>:n parametrina, niin voit laskea kaksi arvoa seuraavasti:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-11-1"><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a><span class="n">f1</span> <span class="o">=</span> <span class="n">compute</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">])</span>
</span><span id="__span-11-2"><a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a><span class="n">f2</span> <span class="o">=</span> <span class="n">compute</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.00001</span><span class="p">])</span>
</span></code></pre></div>
<p>Tulet huomaamaan, että <code>f2 - f1</code> on hyvin lähellä <code>x.grad[2] * 0.00001</code>. Eli jos kasvatat <code>x[2]</code>:ta pikkiriikkisen verran, niin <code>f</code>:n arvo muuttuu suunnilleen <code>x.grad[2]</code> kertaa tuo pieni muutos. Huomaa kuitenkin, että lukema ei tule olemaan niin sama, että voisit verrata sitä <code>==</code>-operaattorilla.</p>
</div>
</div>
<h2 id="lahteet">Lähteet</h2>
<div class="footnote">
<hr />
<ol>
<li id="fn:colahblog">
<p>Olah, C. <em>Calculus on Computational Graphs: Backpropagation</em>. 2015. https://colah.github.io/posts/2015-08-Backprop/&#160;<a class="footnote-backref" href="#fnref:colahblog" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:colahblog" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:colahblog" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:essentialmath">
<p>Nield, T. <em>Essential Math for Data Science</em>. O'Reilly. 2021.&#160;<a class="footnote-backref" href="#fnref:essentialmath" title="Jump back to footnote 2 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:essentialmath" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
<li id="fn:dlwithpython">
<p>Watson, M &amp; Chollet, F. <em>Deep Learning with Python, Third Edition</em>. Manning. 2025.&#160;<a class="footnote-backref" href="#fnref:dlwithpython" title="Jump back to footnote 3 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:dlwithpython" title="Jump back to footnote 3 in the text">&#8617;</a></p>
</li>
<li id="fn:dl4cv">
<p>Rosebrock, A. <em>Deep Learning for Computer Vision with Python. Starter Bundle. 3rd Edition</em>. PyImageSearch. 2019.&#160;<a class="footnote-backref" href="#fnref:dl4cv" title="Jump back to footnote 4 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:dl4cv" title="Jump back to footnote 4 in the text">&#8617;</a></p>
</li>
<li id="fn:geronpytorch">
<p>Géron, A. <em>Hands-On Machine Learning with Scikit-Learn and PyTorch</em>. O'Reilly. 2025.&#160;<a class="footnote-backref" href="#fnref:geronpytorch" title="Jump back to footnote 5 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:geronpytorch" title="Jump back to footnote 5 in the text">&#8617;</a></p>
</li>
</ol>
</div>







  
  






                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2026 <a href="https://www.kamk.fi">Kajaanin Ammattikorkeakoulu Oy</a>. 
Licenced under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">BY-NC-SA 4.0</a>
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../..", "features": ["content.code.copy", "content.code.annotate", "content.tabs.link"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Kopioitu leikep\u00f6yd\u00e4lle", "clipboard.copy": "Kopioi leikep\u00f6yd\u00e4lle", "search.result.more.one": "1 lis\u00e4\u00e4 t\u00e4ll\u00e4 sivulla", "search.result.more.other": "# lis\u00e4\u00e4 t\u00e4ll\u00e4 sivulla", "search.result.none": "Ei t\u00e4sm\u00e4\u00e4vi\u00e4 dokumentteja", "search.result.one": "1 t\u00e4sm\u00e4\u00e4v\u00e4 dokumentti", "search.result.other": "# t\u00e4sm\u00e4\u00e4v\u00e4\u00e4 dokumenttia", "search.result.placeholder": "Kirjoita aloittaaksesi haun", "search.result.term.missing": "Puuttuu", "select.version": "Valitse versio"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
        <script src="../../javascripts/mathjax.js"></script>
      
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>