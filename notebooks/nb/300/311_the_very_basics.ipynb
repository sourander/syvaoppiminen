{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2613e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99600738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# A similar simple case would be y = x + z\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "z = torch.tensor(3.0, requires_grad=True)\n",
    "\n",
    "y = x + z\n",
    "y.backward()\n",
    "\n",
    "print(x.grad)  # dy/dx = 1.0\n",
    "print(z.grad)  # dy/dz = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c098570",
   "metadata": {},
   "source": [
    "## The Very Basics\n",
    "\n",
    "Before we go throught the full example, let's check the basics of `required_grad` parameter and `.grad` attribute in PyTorch.\n",
    "\n",
    "Let's start with a simple `y = xz` function, where we could use the product rule to compute the gradients:\n",
    "\n",
    "$$\n",
    "\\frac{dy}{dx} = z \\\\\n",
    "\\frac{dy}{dz} = x\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3598f0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.)\n",
      "tensor(2.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "z = torch.tensor(3.0, requires_grad=True)\n",
    "\n",
    "y = x * z\n",
    "y.backward()\n",
    "\n",
    "print(x.grad)  # dy/dx = z = 3.0\n",
    "print(z.grad)  # dy/dz = x = 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78c4032",
   "metadata": {},
   "source": [
    "Just for the sake of completeness, here is another example with `y = x + z`, where the gradients are simply:\n",
    "\n",
    "$$\n",
    "\\frac{dy}{dx} = 1 \\\\\n",
    "\\frac{dy}{dz} = 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f072a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# A similar simple case would be y = x + z\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "z = torch.tensor(3.0, requires_grad=True)\n",
    "\n",
    "y = x + z\n",
    "y.backward()\n",
    "\n",
    "print(x.grad)  # dy/dx = 1.0\n",
    "print(z.grad)  # dy/dz = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19858bd",
   "metadata": {},
   "source": [
    "As a more complex example, let's check the derivate of a sigmoid function. This can be verified from Wikipedia. The sigmoid function is defined as:\n",
    "\n",
    "$$\n",
    "a(x) = \\frac{1}{1 + e^{-x}}\n",
    "$$\n",
    "\n",
    "And the derivative is:\n",
    "$$\n",
    "a'(x) = a(x)(1 - a(x))\n",
    "$$\n",
    "\n",
    "Thus, if we feed in the value `x = 0.5`, we should get the same result as when we compute `S(0.5) * (1 - S(0.5))`. Let's verify this with PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f26fba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic gradient: tensor(0.2350)\n",
      "Do they equal?: True\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(0.5, requires_grad=True)\n",
    "\n",
    "# Sigmoid only\n",
    "a = torch.sigmoid(x)\n",
    "output = a.detach().clone()\n",
    "\n",
    "# Print the PyTorch computed gradient\n",
    "a.backward()\n",
    "print(\"Automatic gradient:\", x.grad)\n",
    "\n",
    "# Compare to manually computed gradient\n",
    "manual_grad = output * (1 - output)\n",
    "equals = torch.isclose(x.grad, manual_grad).item() # type: ignore\n",
    "print(\"Do they equal?:\", equals) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Syvaoppiminen I",
   "language": "python",
   "name": "nb-env"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
